{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erkin\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import geopy\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vincenty import vincenty\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "    \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/dortmund_trips.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "st_scaler = StandardScaler()\n",
    "X_scaled = st_scaler.fit_transform(df[[\"latitude_start\",\"longitude_start\"]])\n",
    "\n",
    "k_max = 10\n",
    "clusters = []\n",
    "losses = []\n",
    "\n",
    "# elbow method to specify the appropriate number of cluster\n",
    "for k in range(k_max):\n",
    "    model = KMeans(n_clusters=k+1)\n",
    "    model.fit(X_scaled)\n",
    "    clusters.append(k+1)\n",
    "    losses.append(model.inertia_)\n",
    "    \n",
    "plt.plot(clusters, losses)\n",
    "plt.title(\"Elbow method - K-means++\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEXCAYAAABYsbiOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOydeXhU1dnAf2f2mWSSyQoJISBhMYAsArKobIoiblXEtVVbW2tta221YLXutbZ+9ata28+tiktVqgW1aFEUcENBRKyAILuE7MksWWaf8/1xJ0OWGZiQHc7veebJzDnnnvveO5nz3nPe97yvkFKiUCgUCkU8dD0tgEKhUCh6L0pJKBQKhSIhSkkoFAqFIiFKSSgUCoUiIUpJKBQKhSIhSkkoFAqFIiFKSSj6PEKIU4UQ2w9RXyiEqBdC6LtTrgSyDBZCSCGEoadlaY0Q4mohxEc9LYeid6GUxDGEEOIUIcRaIYRbCFErhPhYCDEpWtfhAaKnBkAp5YdSyhHN5NgrhDi9Wf23UspUKWW4O+XqSoQQa4QQP+zG8/Va5aboWtQXfowghEgDlgM/Af4JmIBTAX8n9a/+l/oQQgh9b1WaQggBCCllpKdlUQBSSvU6Bl7ARMCVoK4Y8AFhoL6pHXA28AXgAfYDdzU7ZjAggWuAb4EPon9ltI96YGqcc90FvAosAeqAjcDYVrKsAVzAFuC8ZnXzgK3R4w4AN0fLZwIl0ffPAxHAG5VhYTNZDdE2+cAbQC2wE/hRK/n+CTwXPc8WYGKz+kXRc9cB24HTEtxTK/AgsA9wAx9Fy1rLshc4vdX5X4i+twAvADXR+/EZ0A+4L/pd+aLX+Gi0/fHAyuh1bQcubtbvYuD/gLeABuB0ICt6HzzAeuBe4KME19Pmu0Vbifht9Boro/csPcHxGWgPKVWAM/q+oFn9muh1fRz97oYC6cDfgbLoPf8doI+2LwJWRe9NNfAPwNHe70m9khg7eloA9eqmLxrSoj+oZ4GzgIxW9Ve3HiDQBt8TooPBGKAC+E60rmmwew5IiTcAJpDjLiAIXAQYgZuBPdH3RrRB+1a0mc7s6I98RPTYMuDU6PsM4MRmcpY0O8deWg68LeQC3gf+hjYIj4sOXKc1k8+HppD0wP3Ap9G6EWjKMr9Zv0UJrvOv0YFvQLSfaYA5jiytZb2Lg0rix8C/AVu0jwlAWrRuDfDDZselRGX7PtoKwYlog+eoaP1iNGV1cvT7tAAvoynEFGA02qCaSEm0+W6BH0S/ryFAKrAUeD7B8VnA/Oi12IFXgNea1a9BU0SjovIbgdeAx6Py5aIpsh9H2w8F5kTvaQ7aQ8pD7f2e1CuJsaOnBVCvbvyytaf0xUAJEEJ7iuwXrbs60QDR7PiHgD9H3zcNGkOa1bcZSOL0cRfRQTf6WUd08I++ygFds/qXiM5gooPIj5sGymZtZpKkkgAGoj2F25vV3w8sbibfu83qRgLe6PuhaE/MpwPGQ1yjDu1peGycuhb3KI6sd3FQSfwAWAuMidPPGloqiUuAD1u1eRy4M/p+MfBcszo9mrI+vlnZ7xP9D8T7boH3gOubfR4R7TPh99+s7TjA2ep67mn2uR/aUqi1WdllwOoE/X0H+KI935N6JfdShutjCCnl11LKq6WUBWhPjvloA39chBCThRCrhRBVQgg3cB2Q3arZ/iMQJXaM1NadS6Ky5AP7Zcu16H1oT+OgPYnOA/YJId4XQkw9gnPnA7VSyroE5wBNUTXRCFiEEAYp5U7gRrSBvFII8bIQIj/OObLRntR3HYF8zXkeeBt4WQhRKoR4QAhhTNB2EDBZCOFqegFXAP2btWn+XeWgKc3mZfvaKV9+q2P2Rfvs17qhEMImhHhcCLFPCOFBe/J3tPI4ay7LILTZRFmz63kcbUaBECI3ev8PRPt7gej/Zju+J0USKCVxjCKl3Ib2dDm6qShOsxfRZhsDpZTpwGOAaN1VgveHYmDTGyGEDigASqOvgdGyJgrRlkGQUn4mpTwfbaB4DW2pJB6HkqMUyBRC2OOd43BIKV+UUp6CNohJ4I9xmlWjLVkVJdFlA9oSTBOxQV1KGZRS3i2lHIm2XHUOcGVTdat+9gPvSykdzV6pUsqfNBe/2fsqtNnkwGZlhYeQM949LUW7D82PD6EtS7bmJrSZxmQpZRowPVre/P+p+Tn2o80ksptdT5qUclS0/v5o+zHR/r7bvK8kvydFEiglcYwghDheCHGTEKIg+nkg2vT902iTCqBACGFqdpgd7anbJ4Q4Cbj8MKepQjMaDzlMuwlCiAujHlE3og0GnwLr0AbNhUIIoxBiJnAu2pO0SQhxhRAiXUoZRDO2JvLOqUgkg5RyP9oSzv1CCIsQYgya8f0fh5EZIcQIIcRsIYQZTQl448kQnQk9DfyvECJfCKEXQkyNHteaTcCl0eudiGaraTrfLCHECdGnbQ/aUk7T+Vpf43JguBDie9G+jEKISUKI4gT3IYxmQ7gr+pQ/ErjqEJcf77t9CfilEOI4IUQq2nLVEillKM7xdrT75RJCZAJ3HuJcSCnLgHeAB4UQaUIInRCiSAgxo1l/9dH+BgC/bjo22e9JkRxKSRw71AGTgXVCiAa0QXkz2hMeaJ4iW4ByIUR1tOx64B4hRB1wB4mf3AGQUjYS9VCJLhFMSdD0dbQ1dCfwPeDC6FNzADgPzbBejWZcvjI66yHadm90eeE6tKfHeNwP/DYqw81x6i9DW2MvBZahrduvPNS1RTEDf4jKVo42o7k1Qdubga/QPJJq0Z5k4/3ebkebcTiBu9Fmb030R/ME8wBfoxncX4jWPQxcJIRwCiEeiS6fnQFcGr2u8ug54ymmJn6GZnAuR5tVPpOoYYLv9mm0JbEP0JwPfMDPE3TxEJpzQzXa/96KQ8jVxJVoDgxb0e7Pq0BetO5uNOO8G3gTTeE10Z7vSXEYRNTQo1B0C0KIu4ChUspEA7xCoehFqJmEQqFQKBKilIRCoVAoEqKWmxQKhUKREDWTUCgUCkVCjqqgbNnZ2XLw4ME9LYZCoVD0KT7//PNqKWVOvLqjSkkMHjyYDRs29LQYCoVC0acQQiTcba+WmxQKhUKREKUkFAqFQpEQpSQUCoVCkZCjyiahUCiOHoLBICUlJfh8vp4W5ajBYrFQUFCA0ZgomHBblJJQKBS9kpKSEux2O4MHD0bLaKroCFJKampqKCkp4bjjjkv6OLXcpFAoeiU+n4+srCylIDoJIQRZWVntnpkpJaFQKHotSkF0LkdyP5WSUCgUCkVClJJQKBSKXsimTZt466232n3c3r17efHFFw/fMEmUklAoFIojJBzuuoR3R6IkQqGQUhIKhULRXXznO99hwoQJjBo1iieeeAKA1NRU7rjjDiZPnswnn3zC559/zowZM5gwYQJnnnkmZWVlADz55JNMmjSJsWPHMn/+fBobGxOe55VXXmH06NGMHTuW6dOnEwgEuOOOO1iyZAnjxo1jyZIlrF+/nmnTpjF+/HimTZvG9u3bAVi8eDELFizg3HPP5YwzzuCWW27hww8/ZNy4cfz5z3/u+E2QUh41rwkTJkiFQnF0sHXr1p4WQdbU1EgppWxsbJSjRo2S1dXVEpBLliyRUkoZCATk1KlTZWVlpZRSypdffll+//vfl1JKWV1dHevntttuk4888kjC84wePVqWlJRIKaV0Op1SSimfeeYZ+dOf/jTWxu12y2AwKKWUcuXKlfLCCy+MtRswYEBM1tWrV8uzzz474bni3Vdgg0wwrqp9EgqFQpGARx55hGXLlgGwf/9+duzYgV6vZ/78+QBs376dzZs3M2fOHEBbfsrL09Jwb968md/+9re4XC7q6+s588wzE57n5JNP5uqrr+biiy/mwgsvjNvG7XZz1VVXsWPHDoQQBIPBWN2cOXPIzMzslGtujVISCoVCEYc1a9bw7rvv8sknn2Cz2Zg5cyY+nw+LxYJerwe0lZhRo0bxySeftDn+6quv5rXXXmPs2LEsXryYNWvWJDzXY489xrp163jzzTcZN24cmzZtatPm9ttvZ9asWSxbtoy9e/cyc+bMWF1KSkqHrzcRyiahUCgUcXC73WRkZGCz2di2bRuffvppmzYjRoygqqoqpiSCwSBbtmwBoK6ujry8PILBIP/4xz8Oea5du3YxefJk7rnnHrKzs9m/fz92u526uroW8gwYMADQ7BCJaH1cR1FKQqFQKOIwd+5cQqEQY8aM4fbbb2fKlClt2phMJl599VUWLVrE2LFjGTduHGvXrgXg3nvvZfLkycyZM4fjjz/+kOf69a9/zQknnMDo0aOZPn06Y8eOZdasWWzdujVmuF64cCG/+c1vOPnkkw/pVTVmzBgMBgNjx47tFMP1UZXjeuLEiVIlHVIojg6+/vpriouLe1qMo45491UI8bmUcmK89somoehWXH4nARlgT8NuBlgLSDGkkGHqGoObQqHoOEpJKLoNf9jPjoZveHbP35FoM9gz+p3FjNzZOEyOHpZOoeh67rvvPl555ZUWZQsWLOC2227rIYkOj1ISim6jIVzPv/YviSkIgHcr3uaUnBk9KJVC0X3cdtttvVohxEMZrhXdiKAh1HLXaYQIYRnqIXkUCsXhUEpC0W3o0TMho6VtbKC1EIMu+SxZCoWie1HLTYpuI92UzgUFF5FlzmarZwuDbIM4I28emcpwrVD0WrpUSQghRgBLmhUNAe6QUj7UrM1M4HVgT7RoqZTynmjdXqAOCAOhRC5air5DusnBnH5nMC37VMw6M6nG1J4WSaFQHIIuVRJSyu3AOAAhhB44ACyL0/RDKeU5CbqZJaWs7iIRFT2AxWDDYrD1tBgKxWH5wQ9+wPLly8nNzWXz5s09LU6P0J02idOAXVLKfd14ToVC0YkEPR6C1dUEKisJ1NT0tDhdztVXX82KFSt6WowepTttEpcCLyWomyqE+BIoBW6WUm6JlkvgHSGEBB6XUj7R+kAhxLXAtQCFhYWdL7VCoQAg6HTi+fRTqpYuRQaDWAYPpuDnP8eYldXTogGw6otann2nnCpXkByHkavO6M/s8R2zd02fPp29e/d2joB9lG6ZSQghTMB5wCtxqjcCg6SUY4G/AK81qztZSnkicBbwUyHE9NYHSymfkFJOlFJOzMnJ6QLpFQoFQMTno3LJEmQ0RLVv716qli0j1InB5I6UVV/U8siyEipdQSRQ6QryyLISVn1R29Oi9Xm6a7npLGCjlLKidYWU0iOlrI++fwswCiGyo59Lo38r0WwZJ3WTvAqFohX+0tI2Zd7du4n4fD0gTUuefaccf7BlHDp/UPLsO+U9JNHRQ3cpictIsNQkhOgvhBDR9ydFZaoRQqQIIezR8hTgDODYtBwpFL0Ay8CBoP1UY9iKi9FbrT0k0UGqXMF2lSuSp8uVhBDCBswBljYru04IcV3040XA5qhN4hHg0mg6vX7AR9Hy9cCbUspj24KkUPQgwmQi/9pr0dvtIASpY8eSfc456FN73o05xxF/Q2aickXydLnhWkrZCGS1Knus2ftHgUfjHLcbGNvV8ikUiuQwOhykjhuHbdgwJCB0OowZGT0tFgBXndGfR5aVtFhyMhsFV53Rv0P9XnbZZaxZs4bq6moKCgq4++67ueaaazoqbp9C7bhWKBRJo7dae8XyUmuavJg627vppZcSOWQeOygloVAojgpmj8/ssFJQtEUF+FMoFApFQtRMQqHoZFx+J37pZ2fdDgbYCkg3pJNhVk+4ir6JUhIKRSfiD/vZ2bCDxXueiiVXmp4zkzP6zyPD1DuMvApFe1DLTQpFJ9IQqmdpyT9bZN/7sOp9IjLcg1IpFEeOUhIKRSciEDSEGlqUSSRhpSQUfRSlJBSKTkSvMzA5c2qLsgHWAoxCberqa+zfv59Zs2ZRXFzMqFGjePjhh3tapB5B2SQUik4kzZjG2fnnkW3OYbP7vxTYCpnT/0wyVPa9PofBYODBBx/kxBNPpK6ujgkTJjBnzhxGjhzZ06J1K0pJKBSdTLrJwYzc2UzMPAmLzoLNmNLTIh0T+DevxrfmWSKeanRp2VhmXoV59Kwj7i8vL4+8vDwA7HY7xcXFHDhwQCkJhULRccx6M2a9uafFOGbwb15N41t/gZAfgIinSvsMHVIUTezdu5cvvviCyZMnd7ivvoaySSgUij6Pb82zMQURI+TXyjtIfX098+fP56GHHiItLa3D/fU1lJJQKBR9noinul3lyRIMBpk/fz5XXHEFF154YYf66qsoJaFQKPo8urTsdpUng5SSa665huLiYn71q18dcT99HaUkFAoFAEGPh0B1Nc41a6jbtIlgbd9J/WmZeRUYWtmADGat/Aj5+OOPef7551m1ahXjxo1j3LhxvPXWWx2UtO+hDNcKhQKAsMvF3nvvjeWwtgweTMENN2DM7P3uu03G6c70bjrllFPQ8p8d2ygloVAoCLpcVC1dGlMQAL69ewmUl/cJJQGaougMTyZFS9Ryk0KhQIbDhBsb25SHGxritFYcSygloVAoMGVlkXHaaS3KdDYb1iFDekgiRW9BLTcpFAoAbMOGMeDnP8e1Zg2GtDSyzzsPkZra02IpehilJBQKBQDGzEyMmZlYi4pAr8dot/e0SIpegFISCoWiBUaHo6dFUPQilE1CoVAo4uDz+TjppJMYO3Yso0aN4s477+xpkXoENZNQKBSKOJjNZlatWkVqairBYJBTTjmFs846iylTpvS0aN2KUhIKheKoYH3Np7xRugxnoJYMUybn5V/ASVlHPqALIUiNGu6DwSDBYBAhRGeJ22dQy00KhaLPs77mU17c9zzOgBZKxBmo5cV9z7O+5tMO9RsOhxk3bhy5ubnMmTNHhQpXKBSKvsgbpcsIykCLsqAM8Ebpsg71q9fr2bRpEyUlJaxfv57Nmzd3qL++iFpuUnQLTn8t/ogfvU6PQRhUOk8gWFtLyOMhWF2NZfBghNl8RG6nQZcLGQqhz8hAr9d3gaS9n6YZRLLl7cXhcDBz5kxWrFjB6NGjO6XPvoJSEoouxxmo5a87H6bMVwrAOMeJXDTwkmNaUQRra6lYsoS6desAEEYjg265pV1KItTQQMjppHrpUkIeD45Zs0gZORJjRkZXid1ryTBlxlUIHfkfq6qqwmg04nA48Hq9vPvuuyxatKgjYvZJ1HKTokvxhXysqVwVUxAAm1wbKfeW96BUPU/E54spCAAZDFLx0ksEa2ra1ce+3/2Ouo0b8e7cSdmTT9KwdSvhcLgrRO7VnJd/AUZhalFmFCbOy7/giPssKytj1qxZjBkzhkmTJjFnzhzOOeecjora5+jSmYQQYgSwpFnREOAOKeVDzdrMBF4H9kSLlkop74nWzQUeBvTAU1LKP3SlvIr24w15aQjXYxBGHKa2m7D8ET9l3gNtyg9491OcfmwllG9OuL6+TVnI7UZGIkn34d25k4jP16LMtWYNthEj0GcfebKdvkiTF1NnejeNGTOGL774orNE7LN0qZKQUm4HxgEIIfTAASCeJelDKWULFR1t/1dgDlACfCaEeENKubUrZVYkjzvg4oOq1Xzh3EiOJZcLBlxEhjETc7PkL+mmdMZnTGCLp6XBb2R6717X9QQ9AKQZuyansTE7G73dTriuLlaWPm0aunbESjKkp8ctE4ZjcxX5pKwpHVIKivh053/TacAuKeW+JNufBOyUUu4GEEK8DJwPKCXRC2gMNvBexUreq3wHgAp/OXsbdrPo+NtbKAmA4rRRzO1/Nh9Vv49ZZ+H8ARdi1Vt7QuzD4g66cQWcvF2uZSA7s/88HKYM0o1tB+SOIFJSGHTrrVS9+iqBqirSJk8mfdo0DNZD35dIIEAkEMCQmoopNxfr0KF4d+4EQGexkHPBBSqshqJT6U4lcSnwUoK6qUKIL4FS4GYp5RZgALC/WZsSoI2TshDiWuBagMLCwk4VWJEYb8TLBuf6FmX1oXo8IReZ5pbGQocpg9P6ncG07FMBid2Qhknfcv24t9AQqudP2+4ngrbs85XrS24deWenKwmD2YwhL49+3/ue5plkt6M3mw95TLC2Fufq1QTKykibMgVrUREDrr+eQGUlIY8Ha1EROoulU+VUKLpFSQghTMB5wG/iVG8EBkkp64UQ84DXgGFAvK2NbXIJSimfAJ4AmDhxoso12E0IIcgwZeIOulqU2/QpcdvbDDZsBlt3iNYhPq76MKYgACJE+KjqAxYUXtol50v2qT9YW8u3//M/BMrKAKjbsIHcyy7DMXMmKccf3yWyKRTQfd5NZwEbpZQVrSuklB4pZX30/VuAUQiRjTZzGNisaQHaTEPRC8g0ZbGg4JIWHiXTsk/FqDP2oFQdJ8XQVsmlGno+p0K4vj6mIJpwrlzZwqahUHQF3bXcdBkJlpqEEP2BCimlFEKchKa4agAXMEwIcRyawftS4PJukleRBNnmXO4YfS9l3gNkmrKw6q04TH3bR39K9sl8WPU+npAbgDRDOpOzp/WwVCDibJITpt65ZKc4uuhyJSGEsKF5KP24Wdl1AFLKx4CLgJ8IIUKAF7hUSimBkBDiZ8DbaC6wT0dtFYpeQqpRe8LOPIo2xdmFnYXFt/JN3XYAhttHkCp6PvmOzmrFVlxM49dfx8pyLrwQ/TG4ca67CYfDTJw4kQEDBrB8+fKeFqfb6XIlIaVsBLJalT3W7P2jwKMJjn0LeKtLBVR0CGegloiMIBCY9Za4yzXdiTfspTHUyOfO9QgEEzImkaJPbeNxlQij0UgGmUzOmtrFkrYPY2Ym+T/6Ed49e/CXlGCfMAG9zXbMhuHoTh5++GGKi4vxeDw9LUqPcGw6VCs6BVfAyUv7XmCL5yseHPMXGsL1+MJeHIaeiyHUGGrg91vvwRfxAvBO+X+4pfiOpJVETxJyuwk3NOBctQqd2Yxj5kx0aWkYol5PTelFmTChhyXtnbjXrqXyX/8iVFODISuL3PnzSZ/WsaXCkpIS3nzzTW677Tb+93//t5Mk7VskrSSEECdLKT8+XJni2KAx1Mh7FSvZ4vmKe0f/kS/cn7OyYgU6dMzNO5uhqcM61T5R669BCB0Zh+nzw6r3YwoCoDHcyLqatczLP7fTZOkqQnV17LnzToiG1XCuXs2Qe++Fw7jGKjQFUbZ4MTKgRYIN1dRQtngxQIcUxY033sgDDzxA3THsINAe76a/JFmmOAbwhhvZUb+d/x39KDWBal7Yt5gKXzllvlKe2fMkrlausUeKK+BkY+0Gnt7zBM/vfZpd9TvxBN0J2wcjwaTKehthn4/aFStiCgIg0tiIZ8OGHpSq71D5r3/FFEQTMhCg8l//OuI+ly9fTm5uLhOO8ZnbYWcSQoipwDQgRwjxq2ZVaWgGZcUxiEVnZUhKEXq9nnU1a9vUf1azjsEpx3X4POW+Mv6+5/HY5x3bd/DbUXeRlmBz2/TcmXxU/T4hGQLAKIxMyz6lw3J0NRJA1/aZzXCMpco8UkIJAiMmKk+Gjz/+mDfeeIO33noLn8+Hx+Phu9/9Li+88MIR99kXSWYmYQJS0RSKvdnLg+aZpDgGSTGmMKf/WQgh6G/Ja1OfZ21b1l4aQg18VPVBi7IIYTY5NyY8xqa38pviOzglezqnZs/gNyPvwKbXdiG7Ak521G1n6f5X+ML5Oa6As8MydhYGi4WsuXMRxug+k4ULGfrgg5hdLtzr1xOoqiLo7D3y9jYMWVntKk+G+++/n5KSEvbu3cvLL7/M7NmzjzkFAUnMJKSU7wshPgJOkFLe3Q0yKToZV8BJKBLCbkzDrE9+fbs+VI8/7EMgyDS3/bFlmDKo9dcyIfMk1tV+Qmk02muhbRCj08d0WG4DBhxx3GsP5XJrN6ZjN6Zz0UBth3TT5r6GUAOf1a7jtQPR5YdKGO+YwPyCi8kw9w4XXp3dzpDf/Q7X++/j6N+f6n//G9fq1VqlXs/AG2/sNbkigrW1hNxu/KWl2IYO1RIm9WDMqNz581vYJEDbR5I7f36PyXS0kJThWkoZFkL0jl+SImm8YS/OQC2vlbyKM+BkUuZkTsqaGjekd2tcARf/Kfs3Xzg/J9OcxSUDryDHnBvbG9FEU5ym64feQF2oDh06UgwpnWK0NhvMzMqdzUbnetxRO8QAawHD7CMOe2zrnd/+iD8WtK+JL1yf852C3jOIGO12sNvJvfhiAlVVBxUEQDhMxYsvYrrpJkw9HAY8WFvbUoEJQcENN6AbNQp9D23wazJOd7Z3UxMzZ85k5syZndJXX6M9LrBfCCHeAF4BGpoKpZRLO10qRafgC3t5cNsfY94+r5cuRSKZmXvaIWcUDcEGVlas4KNqbamnobGBR3Y8yO2j7k14TIYps0syzaXp0vn18bdS6j2ASWci25xzxAooItvmatD2bfYugjU1RFoZYUFzke0NyHC4pQKTkooXX6Rw0aIezWORPm1apykFxUHa492UiRYuYzZwbvR17KVp6kOUectauIMCrK/9lLrQod35vGEvX7m+bFEWiASo8lV2uoyHw2g0kmHKZFT6CQyzj0hKEbkDbtyBlt5VJmFiRs7sFmUj7MUYdL1wq5BOh95iwdhqwE2bOhVxCHfYiN9PoKqKQHV1l4onQ6E2ZeG6OoSIF5NT0ddJ+hcipfx+Vwqi6HziJcxxGDPQi0M7pRl0evpZ+lETaDnY9Pa4TK6Ai5pANW+XvYUQgrn9zybLlEmayUGqMZUZubMpTCnkS9cmBtuGMC7jxKSW3gAqnQEMeshM6/rlFGNGBsFgkMJFi6haupRAaSmp48fjmDEjYQ7soNOJ59NPcb73npZXYsECLIWFXWLD0JlMmPr3J1B+MAVt2sknHzS6dyJSSqV8OpEjmTm3ZzOdBbgGGAXEgtZLKX/Q7rMquoUUQwrjHCeyyaV5A5l1Zi4ouOiwG9IcpgzmF1zC/m/+h7pQHQLB7Nw5mETvDihXH/Lw5+0PIKMR5be6N3PryDtJQ1MEDpOD8aaJjLSfkPQO7Gp3gC931fPmuhrSbAauOqM/WekG0mxdHO22sRGsVnIvvZRIIIA+JQWDLXGo9cZt26hccjBTcMlDDzHkvvsgqiTCgQBhjweh04FO1yEjszEri8Kbb6bqjTfwHziAfdw40k89FUNa59oRSBsAACAASURBVGbxs1gs1NTUkJWVpRRFJyClpKamBks7c460Z679PLANOBO4B7gC+PqQRyh6lAxTJhcVXMLcvLNxB1zk2wowk9zgmGHMZOHxv6UhXI9Vb0OfxG7nnubDqg9iCgK0XBCfVH/EhQMvbtGuPSE6Nu9p4E+vHMx9tWlXHY//8njSOiE1RtDphEiEkMeDIS0NYTDEUpIa46QmTdiP243n009bFkpJ3ZdfYs7PJ+h04tu3j/LnnyfkcpE2cSK5l17aoVmGMTubnAULkH5/UgmTjoSCggJKSkqoqqrq9L6PVSwWCwUFBe06pj1KYqiUcoEQ4nwp5bNCiBfRIrQqejEZ5kwyyGSgrX1Z+8wGM2aDmUz6jlNbvOU1+2EyylW7A+yv8hORUJhrJif94GypyhXgP5+13IzlD0r+u7ueORM6dl+CDQ14d+yg9IknkKEQwmhkwPXXYysuRp/gSS/ocsXsAUKn0+I4obl6mvr3hy9b2pEs+fmAZkMo+ctfYru5PevWYUhPJ+v88zGkHHlAxiZvrK7CaDRy3HEd35Cp6BjtURJNsQ1cQojRQDkwuNMlUiiOkKnZp/Bx9Qcxd9kMYyYTMyclbF/tDnDLU7s4UK15EvXLMPGnHxeRHVUUJqMgI7XtslJWWseXmqTPp/n1Rwd9GQxS9swzHHfHHXGVRLC2lqrXX8f94YcgJfaJE+l3+eUYMzIwWK1knnEGdV98QbBScy5IGTUK80AtZ5e/pKRFuA+A+q++ImPOHOiAklAcG7RHSTwhhMgAfgu8gbYL+/YukUrR7bgCTjbUfkaVv4LJWdOiLq29a3nJFXASkRGCMohRZ2qzqc4u7Pz6+FvZXb8LndAxOOW4Q3pDfbTZHVMQABXOACs/d3LZ7H4ApKcYueL0fmz4xkODT3OfLS60UZirLa1UuwOUOwNs2F7HyEEpDMmzxBTMYQmHiTQ2tizyeBIaFn379uF+//3Y57rPPiNl9GgyZswANDvBoEWLCNXVoTMa0VmtsZmGqX//Nv2ZCwtV0iJFUrRHSbwnpXQCHwBDAKJZ4xR9HGeglr/ueJgyn5Yd9qPqD7jmuB+Tlj6+1+QrcPqdfFT9Pm+Xv4VEkm3K4efDf0m2OSfWpikXxITM5JaCKl1t9yJUugJEIhF00ThK2XYj//eLEWwvaSQ9xUD/TBPZ6SbqGoO8u9HJs+8c9PA5/cQMrjqjP9npJjzeID6/xB+MYDbosFv1WC0H76XQ6zEXFGhP+VEsQ4bEjd8E0LBtW5uyxm3bSJ8yBV1TKPGsLEhLg7o66jdvhkiE1BNOQGe1knXeedQsXw6RCKb+/cm96KJ22T0Uxy7tURL/Ak5sVfYqcGyHSDwKcAddMQXRxNvlbzEoZTBZ+p7d3duEP+JjRfmbsc/VgSpeK3mVBQMvIz1JN9bWzDkxk9c+rqb5w/vcSVkxBQFgtWiDe46j5VO3NyD555qW+0be+8LJd0/vT31jkB0lXu5/aR8NvgiOVAN3XTmYojwzBoOBKlcAg8lOwQ03IFNT8UUMpBAg4vViahVrKBwMEvb7ST3hBJxvtzQBpoweHVMQMTwe9txzD+Hoxju93c7gO+8kY9YsHNOnI4NBzYbRgZhGimOLZKLAHo/m9pouhLiwWVUazVxhFX2Z3u9eWO1v6+FS6i0lKI88DLjdpuf3PxjCi6sqiEi4dGYuWWnJPzeFIi2XhqSEiJQ0BuCPS76NLVG56kM8sORb7r+mCCEC3LF4D1OKUzl7Sg7vrXeyfX8jJx2fxqQRjhYpHINOJ3UbN+L+8EPyr72WrHnzqF25EhmJ4Dj1VFJGjmwjk3vt2piCAG2Tm+v991UMI8URk8wvYgTazmoH2i7rJuqAH3WFUIruJd2YTr5lAKW+A7GyuXlnk2XuHbMIgDxrPnqhJywPGmBHpo/GpjtyX9TsdG3paECOGSkh15H8Gr1JL5g7KYt/f3Jww+GE4XYMOoE/GKGusaWhuLQmgAT+9UEVeyt83H31cfzpn/txNYSYc2IGUsK6r91MHZlOht1I2OejbuNGKp5/HoDdd9xB/nXXUfSHP2gd6vVx9zqEW9k5QMtLEfZ6kTpdLMtdc4IuFzIYRJeaisFqbVtfU4OMRNCZzUnvhWja9S2gzc5xRd8imSiwrwOvCyGmSik/6QaZFN1MhimTnw77BV+4NlLlq+CkrKmkG3ouomc8jMLEdUU/55/7/4Ez4OTEjInM6XcmNmPHvXNykjU2N8NhN3LJzFyGF1hZv81DcWEK08c4yEozUukKkJ1upNp9cJYzNN+KELC7TAuTEgpL0lL0LJiRy8urK/A0hpg1LoNwdHYS9vmwFBZSuHAhdZ9/jnP1akoffZQBP/sZaRMnEvZ6CdTU0Lh1KzqLBWtREcbMTBzTp1P7zjsHvZl0OhwzZ7L/kUfIOf98ZEEBxlQtSGMwGETW1lL5yiv4S0uxjx9Pxumnx/ZPhL1egtXVlD/3HIHyclLHjyfnggsOub8i5PcTLCuj9LHHCJSXYxk0iPzrrsOc1/HQ8YqeQSS7TVsI8QDwO8ALrADGAjdKKXtNgPWJEyfKDSqT11FLKBTCHXahQ4dO6Ek39Q7Da703jNVEzMjv94c4UBPkgX9+y74KH8MLrCy8pJCcdCNvfFLD3/9TxuKFxTjrgyx8fBfB8MHf4C/nD2TWcAO1b7+Nc+VKADJPPx1Tfj5lTz3F4Ntvx1pURKCigj133x3zkDL268egRYsQej0hj4ea5cuRUpI1bx6+PXsof/ZZdBYLQ+67TzNwo80Q9t53H6Ha2tj5HbNmkXPBBRjS0gjW1LDnjjsIN8TieZJ+6qnkLliQcEYRrKlh7733EnIdjJ1lGTSIghtuiJ23qwgHAkSiHmJCp+vy8x1NCCE+l1JOjFfXHsP1GVLKhUKIC4ASYAGwGug1SkJxdGMwGMgy9L6li1RrSw8ws9nAkHwD91x90PmvaSlr1rgMKpwBTHrYW+5roSAA3vm8lgk5KdS+edBIX/PWW+T/5Cekz5iBISODkM9HzYoVLVxogxUVNGzdSuqECUi9nn5XXEHDN99QvnQpvv/+F4CIz0e4sTE2eEaCQS1MRzM869aRdfbZAITq61soCID6jRvJOf/8hPciEgy2UBCgue92dbTdYH09gZISSh9/nJDTiWXQIAZcfz2mfv269LzHAu1REk07iOYBL0kpa1U8FUVP4awL4g9GSLfpsVqS+zcOBoM4GySBYASTUYdJL3DYk98Y1+gLUe+L4PWHsZj0GPSQdYiAf/FsHGaj4PLZueh0UJjb1u+jf6aJyIFv25R7d+wg95JLMNhshOrqCNfXt2kTrquDcJiahgZyzWashYXkXXwx+quuIlBdzf4//Qm9zUYoFEInJeh05C5YgC4lhbJnniFUUxPbWwGgt9lACJq7fxn79UMe4nevMxrRp6S0UC7dMlD7/ZQ8/DARr7ac59u3j7Knnyb/2mvVjKKDtEdJ/FsIsQ1tuel6IUQO4OsasRSKxJTV+ln8dhnfVvqZUpzGOVOyDjlYN1HhCnPH4j2U1QYwGwXXnTuAk0bYk47sWu4Mcuvfd+NuCKHXwQ/n5XPqCelJnbuJBl+Y372wj52lXp67pZhJw+189o0Wuj09xcB3T+uHafuBNsdZhw2LRVmNmM1kzplD3WefxeqF0Yj9xBNp2LaN3CFDqHr1VTxrtdzjxpwcChcuJG/RItDp8G7ZQt1nn2EtKiJ17FjK//EP8n/0I/b/6U/0u+IKTNnZhOrqQK8n+7zzqH7jDZASnc1G/yuvPLT7rMlE/vXXU/q3vxFuaMDgcJD/k590eaKkiM8XUxBNNH7zjabkFB0iaZsEQHTHtSeaqS4FsEspy6N1c6SUK7tIzqRQNomjn0pXgF8/vpNK10Gj8LzJmXzv9DwcqYmfeardAR58ZT+bdh18Atfr4O83F9Mv4/CDfKUrwP0v7mPb/oNLPDodPHNzMbmHOd7jCZCSoi1J1daHsZsjXHD3dl5cWEhIpOBpDFHvjZCfZcJu0aH31lHxwgvUff45CIF90iT6XXZZzGDsXrsWW3ExgfJyalesQGexkHXOOdRt2oR91ixkRQV7722ZICp9+nRyFizAtXo11UsP5gmzjRxJ/6uuwrdrl+ZSq9Np9giXi70rVzJo9myIRAjX1WFIT0daLJgOE8ojWFeHDAQ0jymjEZGaGterqjMJ1tSw69ZbkX5/rMxSVETB9dermUQSdJZNguiO66b3DTTLUAf8EehRJaE4+vH6Iy0UBMCaTS4umXHoJY1wBHaVeduUuepDbZREjSdAOAJIsJp12G0GpIRvK1tOnCMRqPeFMTcE8fojGPQ6stONbfpq9EX450fV2G16Zo/LQEodLy4s5PIHvsVoECz+ZQF5jlRstqgclgz6XXEFuZdeihQ6Qnoj9QYLQWeAiAT9yIkYTSFM+flkzJlDxOul9KmnsAwejN5spqG05cZIgEBpKdLvp3bFihbljVu3ItD2ZBiaudTqU1JIF4JdN90EZ59N5vTpuO+6i+PuTZydsIlEOS+6FJOJAddfT9kTTxBuaMDUrx/511yjFEQn0JlpudS8TtHlmI261svkZKUZOdyE2GiAsUNS+WjzwY1mZqOODHvLn0CNJ8hjb5Sydqsbm0XPD+bmMWmEHYMBJg6388FXB49PteixW/X8471K1m/zUJhr5tqz8+mfYcBg0Pp11oW48W87NKUDvLG2mod+OgyLOZWnbz4evU4gDAJbq/wUxsxMajxBnllRxrSRaXi8dTz5ZimN/gjjilK5acFA0m1GTHl5RLxeCn72M9DrkXV12IYP16Y5kYPpWu0TJyJSUuIvvwiBfULLwAk6o5HMM85AZzbj+fRTAmVlDP7tbzs9Z8SREPZ6iTQ0IMNhhMGASEnRFFNREcfdfXesnF4g69FAe9KXHo7elyxYcdSh18O5Uw+ubxv0gp+cO4CsNO1fucoVoLzWj9cfpLzWj7tBm3Vk2k1ce3Y+Jw7T9gj0yzBx11WDMRsPDpqNvhD/XlvNR1vcRKTm2vrIshK8/ghZdhM/PDufU0anYzYKivKt3HfNELy+MP/+pJoKZ4DPttfxm7/vxlmvDc7uhhBL1lTGFARAbV2IL3fVYzFCXpaZ3AwTGXGM5/XeEK99XMUnX7sp7Gfh4aUlNPq1jjbtquelVRU0BrW1eL3ViiknB1NmJqbMTITJxMAbb8SUl4febifzrLNImzIFEYmQNW9ei/OkjBkDej26OJvoDGlpZM2bR+GiReT/6EeY+vVr4w3V3YS9Xvz797P33nvZtWgR++6/n1A08q0xNRVjdjamfv0wZmVh7IJMeccivTDBr0KRmJx0ExedmsNZkzIprfFTlGfDYJB4GiNUuRv4+3/K8DSGOeukTE4ZnY7NpNkjstNN5DhM/HL+QCISkOBI0WMyHXRfrfdG2LS7rdfQtv2NDMy1kJNu4rpz8/nRvHwQkGYVXPb7loH3hg+wkmppGkhl3BmOlBx2AGvwhtmwvY6i/lb2VbT1D9m8twGvL0L6gAFt6owZGQi7nYE33YQAdBYL+ugGuvSpU7EOGULdhg1YiopIKS4+5OY4odfHnT0Ea2sJud14d+/GNnw4+pSUFp5RXUW4sZGSRx8l7PFoclRXc+Bvf2PgzTd3uXH8WKUzlcTeTuxLoUhIjsNEDpCXoWfz5l1YrZLM/kX8+oldBEPaqPzYv0uxGHXMGqutj/t8ASwW0yFDeaen6hlflMr2/S1DWwzNP/iU3dyTqdIZINdh5NtKzVj6+C+HU9cY5tmVFQwbYGX8UDuXzsrlk6/dsZUfR6qBcUWph71Gs1HHcXkWPtvmYVC/tq6yIwelYDNryqiuMYgvIFsEITQYDBBn0DRmZmLMzCSluPiwMiQi6HLhXLVKiyobJffyy0mfNg1D6uGvrSPIYDCmIJoIlJdz2PVGxRGT9NxRCGETQtwuhHgy+nmYEOKcpnop5YVxjhkhhNjU7OURQtyYoP9JQoiwEOKiZmXhZse+0b5LUxzt7K8O8dtXAwwbNozNexpiCqKJdzc6cTZI7nx2D3WHcNaudgdYu8XNP9dUccoJ6dxwgfZ0btQLrjgtF7stfrj03AwTP/9OASaD4PbvFvLf3Q3c/PguXl9bzZ9e2c///PNbHKkG/nrDcM6dksXls3N5+KfDyEg9/M/OYTdy5Zz+3HbFILLSDCxeeHxshjJqUAqXz+5HWoqR8toAf19RzoOv7GfFZzXUuI884GHShELU/Oc/LYqqly0j4ut6j3id0djCwA5gHjBAubp2Ie2ZSTwDfA5MjX4uAV4Blic6QEq5HRgHIITQAweAZa3bRev+SNt0qF4p5bh2yKg4hjAZtUEzHA7HdUPNcRgxGQS7y3w0+sNt6gGq3AH+sqyEz7ZrexVeXFXBzQsG8sJvigmHwWAQZB5iw93AXDNP3XQ8ESn522M7W9Rt2lVPICgZ3M/K9ee3L68waPYWb0Dy6OulDBtg5bFfjkAiiUQEOQ4TVVF34GqPphi+3F3PD8/KY97kLKzmrssDIqVsk+muOxQEgEhNpeCGGzjwf/9HsKoKU16etrNaLTV1Ge1REkVSykuEEJcBSCm9on1brk8Ddkkp98Wp+zlavorEuSYVilZYzTomDrdzwd3bee6WYsYVpcb2QaSn6Pnuaf1x12kDqC7Bv2owKGMKoonnVpYz+rgi+mUc3rc/PUVTIJXOQAsDdROymT+H0xMkGJaaG6uONjkqmlPvDfHOBifPv6slNVr1hZOPN7tZeElhbCd3lTsYUxBNvLW+hpNHO7pUSQidDltxMY1ffx0rs0+ahOiGBFUGsxkKCylctAhUjKZuoT1KIiCEsBL1YhJCFAH+Qx/SgkuBl1oXCiEGABcAs2mrJCxCiA1ACPiDlPK1OMdfC1wLUFhY2A5xFH2dnHQTv7iwgL0VPkx4+dVFA3E3hKjzhinINmOzSi66aydjh6RiMcVf4glH2q5l+4MS0U6PbrtVx4Wn5PD0irJYWXGhLTbbqXIHWP5JNUs/qiYUlkwcbufG+QMT5stu9EVY9nHLHBqb9za0iPVkNbe9JrvN0OUrL8asLPKvvRbne+/h3bmTlJEjST/11EMawDuTRPYWRdfQHiVxJ1r014FCiH8AJwNXJ3OgEMIEnAf8Jk71Q8Ci6C7u1nWFUspSIcQQYJUQ4isp5a7mDaSUTwBPgLbjuh3XozgKaMoJ0USOw4TXG6CkNsSbn7q55dJCRg1OSWiwtph0FOVb2VV6cKPd+dOySbG2z9XTajEwa5yDwf0tfPBfF0X5Vk4d7SArurmuxh3kn+8fHPQ3fFPH25/VMP+UHMwJnvr1urajffOSVIueicPtbIiG9dDr4Adz85LaQd5RjBkZZM6dS8TvR9hsyMZGQqFQbH+I4ugh6W9USrlSCLERmIL2v/oLKWX1YQ5r4ixgo5SyIk7dRODlqILIBuYJIUJSyteklKXRc+8WQqwBxgO74vShUMSwWk0MG2Bi2IDDJyTKcZi468rjWPl5LbvLvEwf42DkIBspSQYNbE6TwhpflIrB0FLJbNnX0Kb9ln0NnDkxM66SSLXquGxWLo8tP7h7WtvUd1BN5DhM/OKCAg7U+DlQ7Wf8UDsWY+fuYwjU1hL2eGjYuhVbURHGnByMmZkEXS4atmyh/NlnkYEAhqwsCm+6CUN+fqeeX9HzJJO+tHVe66b5dKEQolBKuTGJ81xGnKUmACllLJ6yEGIxsFxK+Vo0TlSjlNIvhMhGm7k8kMS5FIp2kZ1u5KJTs/EHJam2jj8Jt1YQAGOGtHUNHVeUSmoCzymbxcDJo9MZOsDKx1vcjCiwxZ0RZTtMZDtMjC3q/FAYofp66tavp/Lll2NlGaefTtY550A4TPkzzyBDIa1tTQ1lzzxD/nXXqfzZRxnJ/CIejP61oD31f4k2kxgDrANOOdTBQggbMAf4cbOy6wCklI8d4tBi4HEhRATNVfcPUsqtScirUMSlxhMgGJLsr/QzMNeM0aCL2QSMRj1dtUG3ti6II8XA1Wf25+XVlQSCEU45IZ3Z4zMxGxMbe5tmJqMGd+3eg0RIn4/q119vUeZctYqsuXO1dKhRBdGEb98+hNqvcNSRTPrSWQBCiJeBa6WUX0U/jwZuTuL4RmiR3z2hcpBSXt3s/VrghMP1fzQRbnBD0Etwzyb0adnocgajT1MGus6grjHEhm/qeXjpfqTU3Op/ceFApo1Mw94Js4dEVLsDvL62muWfVnP3VUN47MYRABh0JDRa9xqEIBIItCyLRJCRCHqbDZ3F0sL1NaW4WIubojiqaM8C5vFNCgJASrmZ6B4IRecgPVV4Hr8O73/+Qv2SO2lYdj9hT7Jmn95H2FNF6MB2/FvWEHZVEKl3H/6gLsLrj/DE8gOxjblSwhPLD+ANxPFb7URKawK8+kEVvoBk0ZO7uPqBr1n3tRtHah8YTA0G0qdObVFkKy7WgueZzQz81a8w5ubGyvtfeWW3eTgpuo/2PEJ9LYR4Ci1dqQS+C3x96EMUyRKpq8b7/nMQPuj3Hj6wDemugD44mwh7qvC++xTBbR9pBToDqZf/Hl1qz+SljkgZC5DXRKM/QiSOC2xn8uWutrGgvtxVz8yxGaQdOi1Dj2NMTyfnoouwFBZS/9VXWIcOxTF9ekwRiCFDKFy4ECEECNEtsZsU3U97ZhLfB7YAvwBuBLZGyxSdgIyEkb62A0okTllPEPFUEdz9OcH9mwl7qg5/QMB3UEEAREJ433uKsLuy64Q8BHqdYNTglqPyqMEp6OK4mXYmY+PEaRpblEqKpW+EkTA6HKTPnEneNdeQOXdui5mCwWDAlJ2tRVxVCuKopT0usD7gz9GXorNJzcZ84jwaS7fHioTVjr7fkB4USiPsrqTu2ZuQ9bUA6PsNIeXiO9HbE89wpL+ty6dsdPVYILYch4lFlxTy3Mpytu5roLgwhavO6H/IXc+dQV6mifmn5vDG2mrCEckpJ6Rz8mgH+j60dq83mdCbun7vRV8i7PfHAg3qHQ70R3FY8qSVhBBiD3FyRkgpe34UOwrQ6/Vw3HhSLrgF/xcr0NmzsJx8KdLWeYlTIn4vMuhDn5r8unEk4MW//vWYggAIV+wm/O0W9KNmJDxO2LMQKRnIhlgyQ0wnnI6w9lwimByHiWvOysMXiGA16UhP7fofdo7DxPxTcjhvajaSPmKwVhySYG0t9Zs2UfOf/yB0OrLPOw9bcfFRO5tqj02ief5TC7AAODrvSg+ht2ehLz4V/YBihMGErhMVRNhdhf+z14nUlmAaPRvDwFHo7En4s4dDROraLi9FDrNsJG0Z2K98AO8HLxBxlmMqPhXTyBnozG2T23Qnjm5QDK3JUErhqMJfVkb5c8/FPpc++SSDb79dKQkpZU2rooeEEB8Bd3SuSIrOdnuNuKuo/8ctRFxasLjgzs+wnvZDjOPmoj/MoK2z2jGPm0tw28cHC4UO44ipiQ8iGl8nIx/rnB9D0Ac2Bzpj24B5EW89BBqRgDCloLP2cmuu4pgmEgrh+eSTNuXudeuwFhX1gERdT3uWm5rvvNahzSx6IOO5or1EGl0xBdGEf+ObGEdMgySe7HXZg7B9ZyH+9a8jjGYs07+LMB8+5AWA3pYOxPdoinhq8P93Jf51S0EIzFMXYBo985C2DoWiJ9EZDFr+ilZYCtofCr6v0J7lpgebvQ8Be4CLO1ccRVcgDG2XO4TRSrKBTvVpWehHzsAw4HhAhz49p1PkClXuxvfB87HPvtXPYMgbppSEoleTNmUK7k8+wf/ttwBYhw4l5YSjd99ve5TENVLK3c0LhBDHJWqs6EWYUzAMHkto75faZ6HDMusq9On92tVNe9sfjhZLWFEC2z7GOHhsp55HoehMjBkZDLzxRsINDaDTobdaj+pNhO1REq8CrYP9vQpM6DxxFF2BPi0H2zm/Ily5m0j1foxDTwJz5639h12VgETvaKfSGTAC/ruyRZkhf3inyaVQdBVNucKPBZKJAns8MApIF0I0z2OdhublpOgD6NOyNYP40JM6rc9wXQ2Ryr14P3oRIhEsUxdgGDAcXZLLRaahJxEcPI7Q3k0AGIomYTxufKfJdzTg9YdACqyWvrOvQnF0kcxMYgRwDuAAzm1WXgf8qCuEUvQNZKOb+iV30rR9pmHpfaRe+T9JKwmdPYuUc25EhqPRRPWG5NxyjwHqGoN4GiMs/bCSYEhywSk5OFIMyp1W0e0kEwX2deB1IcRUKWVb3y/FMUtg82pa768MbHobff9h6OIYy+OhS+scI/jRRoMvwk8f+QZ/UIs39d4mJ4/+bLhSEopuJ5nlpoVSygeAy4UQl7Wul1Le0CWSKXo9OkdenLL+SSuI5kTqapHhIOGyb9BlDkBY09q9XyRSr/URcZahS+8PBiP6JGYm4QYXCBF11+0drP7SFVMQAJEIvLa2mp+ck4fFrFKEKrqPZP7bmiK9buhKQRR9D9Owk/BvXE6kah+gKQjzmNOPqK9w9T5t6SoS1vqecA7WqQvQJakowkEf4dJvaFj6+2gfAusZP0YUn4IuJb7nSbiuFumuwPfpq6AzYDn5EnQpGejaEbakq4iXhtRiFOhE56YnVSgOh5BHUSapiRMnyg0blC7rTiKeaiLuCqSMoHP0R9+O5aOwp1oLjR6JgMFEwN+I76nrY/Vp1z+dtMdU6yCEABjMpP34MfTpuXGPCZXvpO7pG4ktmekMpP3ob+iz2m6W6m6qXAF+8dcdOOs1e43VpOPRG4aTn9V217pC0VGEEJ9LKSfGq2vPjut/0zbAnxtthvF4NEqs4hhDl5ad9NN+cyKearxv/x/BHZ8CoM8bTspFt+EbMBoObAZANjgJ63RJKx5Z72xZEPK3yM/R4vyhIP4Nb9LiXzoSwr95FbYZ32v39XQ2jhTBwz8dxtqtbgJByfQxDmzWvhFeXHF00Z65626gHngy+vIAaJKGWwAAE5lJREFUFcDw6GdFLyPsriTsqiDsriQU8ve0OC0IVeyMKQiAcNk3BP77LqmX3wOALr0f0lsXW346LEKHYUjLbTy6nEGgT2Af0ekRtrZRZXTW3hFpxmg0kuMwcf60HBbMyKVfhgm7RRmtFd1Peyxg46WU05t9/rcQ4gMp5XQhxJbOFkzRMcK1pVr604rd6NJzsZ33a8I5g9BbDr2JLuKrB70enbFro7WGy3a2LavYjSngwzhyBpaJ59L4n0dJmX9bUv3p07JJmXcD3vefI7Tvv+jzhmE97ZqES006nQ7ziWcT+HIl0qvlBRBpOZiOP/nIL0qhOAppj5LIEUIUSim/Bfj/9u48Sq6yzOP497nV1dV7Z+lOWLJBCGtOEpJgFBSBJKwRyCCI4ogaRXQWZdRhGDkMB4+iI6McnXGAmTMD44KyyICRUTMIE8BDMAlJiBCWYCJJMBshnXR6rXrmj3uTVLr7dnd1V3X18vucU6frvve+t5/7nu566t733vc1s0nAwesMrfHVZKClG3bS+NgdpLeHo6hk9u6g8aHbqP7k9yAmSaQbdpHZ8xYtq5cSVIwiNW8xXjWakpKer4GnG3aF3/jNIEiSqO6+4zdz4ADJafNofub+I8qTJ52FpyoJqsey/6HbCEYfCzncKRXU1FE2fwm0NkGilER190/EetUoapZ8l7ZNayFRQsnE6X26dCYynOWSJL4IPGNmGwmHhjsO+JyZVQL3FSI46RsD0lkz3AHhpZu2+EtO6Z2bafzp4VHfW19aTvWS70IP/QGZfbsP9y0kSkidcTmpuYu67UdI7whvc6246K9pevpH0N5Cas4iSiZNp33D02Te+VO4nxkLcn64LlFRC728lbWkJAU19X2+I0tkJMhlPonHzWwacDLh59CGrM7qOwsRnPSNu5MYP5X09o1AeGtq+QWfxTNtpHe9CaVlR3yIZxp2hcN1Z++jqYH0lpdJnNrNh31bC23rnzrct5Bup+W5hyidNi82uaQbG7Da8bg7wclnU33crPAMJJkiUVFLYvq5JI+fg6fKCeL6E0RkwOT6VM4cYEpUb4aZ4e7/1X0VGWiJ2nFUXvpF9j94G5l9u6m8/EYaf/5PZHZvAaBkyiwqFt1w6GE1DwKsiwmBrLSHfomWRtr++GKn4rY311My8dRO5Zl9u2n57YO0vbGSRN1kyucvoW3ryzT9/NtUL/nnQ2cA+ZyRT0T6J5dbYH8ATAXWAAdvOXFASWIQyow6hqprbgczWl/45aEEAdC+aQ3p7a8fShKJqjGUve8jtL2xCqJxlIKxEwnG9TASfHk1ySkzaN/4uyOKk5NndNo0vX8PzU/+ZzSUB2T2vEV6xxtUffSbNI8+iiCmg1lEiivXOa5P9eH09N0wlkwmoXYcmQN7Se/c1Gl9esdmmPbuQ8tBVT01191F24ZnsMoxJKfM7LETN5FIYqe+n/Ztr9K24VnKr7yVZN0EMCPT0kiQPRx5pp3Wl585on5m7w5oa6H6mm/Q+tJyaG8Jp0UtrSRRXtWv4xeR/MglSawHjgLeKlAsUgBBRS2lp51D26vPZZUapSfOO3K7qnCa0cR7rsxt/9VjqZj/aXz+p0hv3cD++2/GW5tIzVlE6cyFh8dOcieorSfz9rasMAIoKWXfvX9z6EnppuU/pGbJ90BJQmRQyOVhujrgJTP7lZk9dvBVqMAkf0omnELZeUsIauoJ6iZSecXfQyp/H8JBzVhoaaTxkdvJ7NmGN+6hefkPaN+87tA2XjmGigv/AhKHv5ekzrwKz6SPHEqjtYmW3z1Kpl13VYsMBrmcSdxaqCCksILqOlKzLzz8oFh1HYlEfiexaX1tRaeytpefpuS400lUjqKkpIRM3WRqrv83MrvfJKgdjyXLaHnxyU71vKUJ0pncb6sQkbzL5RbY/zOz8cAZUdHz7r6jMGFJvgWlFVBaUbD9J7ro5A7qJ2PJw5MXHhxdNfsp6NJT30vzs/eH4ywBWEDqXZcRpDTp4UDYubeVZCJgVJUysnSt15ebzOwq4HngSuAqYIWZfbCHOieZ2ZqsV4OZfSFm2zPMLJ29TzO71sxei17X9jZWGXgl446jZOoZh5aDukmUzb6EoLSHD/tUJTVLvkvpzPMpPe1cqj9xJ0FF8YfqHu52NbTymxf2cMcDf+TupVvZsquZAy3txQ5LBqFeDxVuZmuBhQfPHsysHvhfd5/Zy/oJYCswz903d7FuGdAM/Ie7P2RmYwhHmJ1LeKvtKmCOu3cY6vMwDRVeXJmGnXh7a3gbbaoip2HDM82N4BCUdz+2lPRfOp3miRfe4TsPH74tuqoswfc/fyL1o0qLGJkUS16GCgeCDpeXdpNbx/d8YGPHBBH5K+BhDl/KArgAWObubwOY2TLgQuD+ztVlMOjPVKRBDwMPSv7samjn8effPqJsf3Oa17c1KUlIJ7kkiV+a2a84/CH9IeDxHOpfTRcf8GZ2LLAYOI8jk8SxwJtZy1uiso71rwOuA5g0aVIO4YiMTCWJgJqKzjcu1FaqX0I66/WZgLt/GbgHmAHMBO5x9xt7U9fMSoFLgQe7WH0ncKO7d5w4oKsZVjpdG3P3e9x9rrvPra/v+zdZkZFibE2Sa88/mlTy8L/YaZMrGTdKY2VJZzl9dXD3hwkvC+XqImC1u2/vYt1c4CdmBuGzGBebWTvhmcM5WdtNAJ7qw+8WkQ7qR5dw9w0ns+6N/dTVJplQn6KuVpeapLMek4SZ7aOLb/CE3/Td3XszGtuHielLcPdD906a2b3AUnf/76jj+utmdvBWl/OBm3rxu0SkBzXlSWrKYeGc7ufcEOkxSbh7v+ZzNLMKYCHwmayy66N939XN733bzL4KHBw97raDndgiIjIwen0L7FCgW2BlsEkf2Iu1t5LevYWguq7TXB4ig0G+boEVkRz53u00/PAmaAvn5yqdfQllZ151aJh2kcEul+ccRCQH6b07OPDruw8lCIDW1b8ADV4oQ4iShEihuJPZu7NzcdO+IgQj0jdKEtJn6cZ3yOzdSXrvDjIH9hY7nEHHUuWUnvLeI8vKawiqdUeRDB3qk5A+yezbTfNvH6B1zS8hSFA27wpSp18Qds4KAEF5DWXvvgISSdpe+S3B6KOpWPApMqlKfTuTIUNJQvqkbfM6WlctDRfS7TQ/82NKJk9XkuggqB5L2XuuInX6RVgiGU7QJDKE6AuN5CzT2kzb67/rVN72um4/7kpQXkli9FFKEDIkKUlIzoLSMkomntapvGTS9CJEIyKFpCQhfVJ64rtJTpsXLlhA6YwFlIw/obhBiUjeqU9C+iSoHkv5BZ+lfMF1YIYlEgTVupwiMtwoSUifaXgJkeFPl5tERCSWkoSIiMRSkhARkVhKEiIiEktJQkREYilJiIhILCUJERGJpSQhIiKxlCRERCSWkoSIiMTSsBwy5LW3t2MH9pD+00YsWUZi7ASCGs1rIZIPShIy5Fnjbvbd+0W8cQ8AQf1kqq++TRMgieSBLjfJkJZpbaLl+UcPJQiAzM7NtG1eV8SoRIYPJQkZ2jJpMvt2dyr2hl1FCEZk+FGSkCEtKKsiNfviDoUJkiefVZyARIYZ9UnIkJcYeyyVH7yZlhWPQEmK8vd/FEuWFzsskWFBSUKGvKC6jtLqOhLjT8ACU4e1SB4pSciwkajVTHki+aY+CRERiVXQJGFmJ5nZmqxXg5l9ocM2l5nZumj9SjN7b9a6dFbdxwoZq4iIdFbQy03u/gowC8DMEsBW4JEOmz0BPObubmYzgAeAk6N1Te4+q5AxiohIvIHsk5gPbHT3zdmF7r4/a7ES8AGMSUREujGQfRJXA/d3tcLMFpvZBuAXwCezVpVFl6CeM7PLY+peF22zcufOnfmPWkRkBDP3wn9xN7NSYBtwmrtv72a7s4Fb3H1BtHyMu28zs+OB3wDz3X1jXP25c+f6ypUr8xy9iMjwZmar3H1uV+sG6kziImB1dwkCwN2XA1PNrC5a3hb9fAN4Cji9wHGKiEiWgUoSHyb+UtMJZmbR+9lAKbDbzEabWSoqrwPOAl4aoHhFRIQB6Lg2swpgIfCZrLLrAdz9LuAK4GNm1gY0AR+K7nQ6BbjbzDKEyewb7q4kISIygAakT2KgqE9CRCR3g6FPQkREhiAlCRERiaUkISIisTQKrAw77S0HCFoaaXvz91hpOYnxU0nUaPhwkb5QkpBhxw400HDvF/CmfQAEYydQ/eGvEShRiORMl5tkWMm0NNG84meHEgRAZvcW2jatLWJUIkOXkoQML+k2vGlvp2I/sKcIwYgMfUoSMqwEFTWk5nzgyMJEkuRJZxUnIJEhTn0SMuwEo4+m6uqv0rziZ1iyjLL3fQRLlRc7LJEhSUlChp1E9djwVT8ZNyNRNabYIYkMWUoSMmwF1WOLHYLIkKc+CRERiaUkISIisZQkREQklpKEiIjEUpIQEZFYShIiIhJLSUJERGIpSYiISCwlCRERiaUkISIisZQkREQklpKEiIjEUpIQEZFYShIiIhJLSUJERGIpSYiISCwlCRERiWXuXuwY8sbMdgKbix1HkdUBu4odxCCltomntunecG+fye5e39WKYZUkBMxspbvPLXYcg5HaJp7apnsjuX10uUlERGIpSYiISCwlieHnnmIHMIipbeKpbbo3YttHfRIiIhJLZxIiIhJLSUJERGIpSQxiZrbJzF40szVmtjIqu9LMfm9mGTPr9pY8M0uY2QtmtjSrbL6ZrY72+YyZnVDo4yiU/rRPV3Wj8jFmtszMXot+jh6IY8m3ArXNt8xsg5mtM7NHzGzUQBxLvhWibbLWf8nM3MzqCnkMA0lJYvA7191nZd2jvR74M2B5L+p+Hni5Q9m/Ate4+yzgx8DNeYu0OPrTPh3rAvwd8IS7TwOeiJaHqny3zTJgurvPAF4FbspvuAMq322DmU0EFgJ/zG+oxaUkMcS4+8vu/kpP25nZBOAS4N877gKoid7XAtvyG2Fx9bZ9unEZcF/0/j7g8v5HNTj0t23c/dfu3h4tPgdMyE9kxZeHvxuA7wB/S/g/NmwoSQxuDvzazFaZ2XU51r2T8A8206H8U8DjZrYF+HPgG/0Ps2j60z5xdce7+1sA0c9xeYp1oBWibbJ9EviffkVYPHlvGzO7FNjq7mvzGehgUFLsAKRbZ7n7NjMbBywzsw3u3uPpsJktAna4+yozO6fD6huAi919hZl9Gfg2YeIYivrUPnmoOxQUrG3M7CtAO/CjAsQ9EPLaNsBK4CvA+YUKuJh0JjGIufu26OcO4BHgXb2sehZwqZltAn4CnGdmPzSzemCmu6+ItvspcGZ+ox44/Wif7upuN7OjAaKfO/IZ80ApUNtgZtcCiwj7tYbkZZUCtM1U4DhgbfQ/NwFYbWZH5Tfy4lCSGKTMrNLMqg++J/yWsr43dd39Jnef4O5TgKuB37j7R4E9QK2ZnRhtupDOHdtDQn/ap4e6jwHXRu+vBR7NZ9wDoVBtY2YXAjcCl7r7gULEXmiFaBt3f9Hdx7n7lOh/bgsw293/VJCDGGjurtcgfAHHA2uj1++Br0Tliwn/CFuA7cCvovJjgMe72M85wNKs5cXAi9F+nwKOL/axDnT7xNWN1o0lvKvptejnmGIf6yBqm9eBN4E10euuYh/rYGmbDr9jE1BX7GPN10vDcoiISCxdbhIRkVhKEiIiEktJQkREYilJiIhILCUJERGJpSQhIiKxlCRkxDCz/T2sH2Vmn8taPsbMHorezzKzi/vwO281sy/lHm2X++prDFPM7CP5iEFGHiUJkcNGAYeShLtvc/cPRouzgJw/oPMs5xjMrASYAihJSJ/oYToZMcxsv7tXmVkV4XAbo4EkcLO7P2pmPyEcKvwVwrkT/gVYCswmfNq4HNgK3A6cAux39zuifa8HFrn7pmgAvI8RPp28E1jl7neY2dRon/XAAeDT7r4hJtYrgX8A0sBeYEEXMfyBcLTfcqAJ+IS7v2JmHyccJr4MqAQqonj/ANzn7t/pb1vKyKFRYGUkagYWu3tDNIPYc2b2GOEEQ9M9nJAJM5sC4O6tZnYLMNfd/zJad2tXOzazOYTjZZ1O+P+1GlgVrb4HuN7dXzOzecD3gfNiYrwFuMDdt5rZqJgYaoCz3b3dzBYAXweuiOq/B5jh7m9HIwF/yd0X5dxSMuIpSchIZMDXzexswvk2jgXG52nf7wMe8WgAvCj5EJ29nAk8aGYHt011s59ngXvN7AHgZzHb1AL3mdk0wnkOklnrlrn7230+CpGIkoSMRNcQXvKZ4+5t0fDOZTnuo50j+/Sy63d1DTcA3jl4ltITd78+Otu4BFhjZl3V+yrwpLsvjs56nspa19ib3yPSE3Vcy0hUSzgpU5uZnQtMjsr3AdUxdTqu20TYV4GZzSacTwDCOZIXm1l5NKz0BwDcvQH4Q9TXgIVmxgVoZlPdfYW73wLsAiZ2EUMtYf8EwMe7Od7ujkukW0oSMhL9CJhrZisJzyo2ALj7buBZM1tvZt/qUOdJ4FQzW2NmHwIeBsaY2Rrgs8Cr0T5WE07mtCba5umsfVwDLDGzg0NNX9ZNjN8ysxejDvHlhMNTd4zhH4HbzexZINHNvtYB7Wa21sxu6L5pRI6ku5tERCSWziRERCSWOq5Fiih6puLKDsUPuvvXihGPSEe63CQiIrF0uUlERGIpSYiISCwlCRERiaUkISIisf4fFwiE+mWDk28AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# due to the elbow method number of clusters are set to 4 \n",
    "km = KMeans(n_clusters = 4)\n",
    "km.fit(X_scaled)\n",
    "df[\"area_start\"] = km.predict(X_scaled)+1\n",
    "\n",
    "sns.scatterplot(x=\"latitude_start\", y=\"longitude_start\", data=df, hue=\"area_start\", palette=\"muted\")\n",
    "plt.title(\"Start positions clusterd to areas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_point(row):\n",
    "    return Point(row.longitude_start, row.latitude_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are currently the coordinates of TU Dortmund Hörsaalgebäude 2\n",
    "def calculate_distanceToUniversity(row):\n",
    "    university_center_lat = 51.492296\n",
    "    university_center_lon = 7.41273 \n",
    "    \n",
    "    distance = vincenty([row[\"latitude_start\"], row[\"longitude_start\"]], [university_center_lat, university_center_lon],)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kann später weg, im master ist dieses attribut bereits 0/1 (hier war es noch True/False)\n",
    "def convertweekend(row):\n",
    "    if(row['weekend']):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tripLabel(row):\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'awayFromUniveristy'\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'noUniversityRide'\n",
    "    \n",
    "    warnings.warn(\"Warning...........Message\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "\n",
    "    # Go through every row, and make a point out of its lat and lon\n",
    "    df[\"geometry\"] = df.apply(make_point, axis=1)\n",
    "    # It doesn't come with a CRS because it's a CSV, so it has to be set\n",
    "    df.crs = {'init': 'epsg:4326'}\n",
    "    \n",
    "    # get geodata of germany (postal codes and their areas/polygons)\n",
    "    districts_germany = gpd.read_file(\"../data/external/germany_postalcodes.geojson\")\n",
    "    # filter for districts of dortmund\n",
    "    districts_dortmund = districts_germany[districts_germany[\"note\"].str.contains(\"Dortmund\")]\n",
    "    \n",
    "    #convert dataset of trips to geodataframe (so it can be merged later with the geodataframe of dortmund)\n",
    "    geo_df = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'}, geometry=df.geometry)\n",
    "    \n",
    "    # join the data\n",
    "    # mrges data when POINT of trips is within POLYGON of a dortmund district\n",
    "    df_with_postalcode = gpd.sjoin(geo_df, districts_dortmund, how='left', op='within')\n",
    "    \n",
    "    # adding the distance between start position and the center of the university\n",
    "    df_with_postalcode[\"distanceToUniversity\"] = df_with_postalcode.apply(calculate_distanceToUniversity,axis=1)\n",
    "    \n",
    "    # convert weekend to binary (KANN IM MASTER WIEDER WEG; DORT IST WEEKEND BEREITS BINÄR)\n",
    "    df_with_postalcode['weekend'] = df_with_postalcode.apply(lambda row: convertweekend(row), axis=1)\n",
    "    \n",
    "    # add the attribute whether a trip was done towars/away from university\n",
    "    university_stations = [\"TU Dortmund Seminarraumgebäude 1\", \"TU Dortmund Hörsaalgebäude 2\", \"Universität/S-Bahnhof\", \"TU Dortmund Emil-Figge-Straße 50\", \"FH-Dortmund Emil-Figge-Straße 42\"]\n",
    "\n",
    "    df_with_postalcode['towardsUniversity'] = df_with_postalcode['p_name_end'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "    df_with_postalcode['awayFromUniversity'] = df_with_postalcode['p_name_start'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "    \n",
    "    df_with_postalcode['tripLabel'] = df_with_postalcode.apply(lambda row: get_tripLabel(row), axis=1)\n",
    "    \n",
    "    df_prepared = df_with_postalcode\n",
    "    \n",
    "    return df_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/processed/prediction_data_with_outliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/prediction_data_with_outliers.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>b_number_start</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>p_name_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>p_name_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>plz</th>\n",
       "      <th>note</th>\n",
       "      <th>qkm</th>\n",
       "      <th>einwohner</th>\n",
       "      <th>distanceToUniversity</th>\n",
       "      <th>towardsUniversity</th>\n",
       "      <th>awayFromUniversity</th>\n",
       "      <th>tripLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20 16:22:00</td>\n",
       "      <td>50641</td>\n",
       "      <td>51.506312</td>\n",
       "      <td>Hainallee / Südbad</td>\n",
       "      <td>7.470531</td>\n",
       "      <td>2019-01-20 17:00:00</td>\n",
       "      <td>51.493966</td>\n",
       "      <td>TU Dortmund Emil-Figge-Straße 50</td>\n",
       "      <td>7.418008</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.470531463623098 51.506311756219)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>4.306089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>towardsUniversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-20 02:31:00</td>\n",
       "      <td>50425</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>2019-01-20 02:43:00</td>\n",
       "      <td>51.513069</td>\n",
       "      <td>Unionstr.</td>\n",
       "      <td>7.448886</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.459931373596199 51.517155427985)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>4.288439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20 11:32:00</td>\n",
       "      <td>53006</td>\n",
       "      <td>51.509557</td>\n",
       "      <td>Ritterhausstr.</td>\n",
       "      <td>7.446949</td>\n",
       "      <td>2019-01-20 13:33:00</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.4469494819641 51.50955711581999)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>3.055201</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-20 14:38:00</td>\n",
       "      <td>53006</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>2019-01-20 14:53:00</td>\n",
       "      <td>51.500725</td>\n",
       "      <td>Polizeipräsidium</td>\n",
       "      <td>7.459819</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.459931373596199 51.517155427985)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>4.288439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-20 17:02:00</td>\n",
       "      <td>53006</td>\n",
       "      <td>51.500725</td>\n",
       "      <td>Polizeipräsidium</td>\n",
       "      <td>7.459819</td>\n",
       "      <td>2019-01-20 17:16:00</td>\n",
       "      <td>51.514029</td>\n",
       "      <td>Schwanenwall</td>\n",
       "      <td>7.472570</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.4598187208176 51.500725323279)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>3.401936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207471</th>\n",
       "      <td>2019-12-31 12:39:00</td>\n",
       "      <td>500019</td>\n",
       "      <td>51.500675</td>\n",
       "      <td>Kuithanstr.</td>\n",
       "      <td>7.440834</td>\n",
       "      <td>2019-12-31 12:54:00</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.440834045410155 51.50067523261729)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>2.162931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207472</th>\n",
       "      <td>2019-12-31 19:28:00</td>\n",
       "      <td>500019</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>2019-12-31 19:35:00</td>\n",
       "      <td>51.513069</td>\n",
       "      <td>Unionstr.</td>\n",
       "      <td>7.448886</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.459931373596191 51.5171554279852)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>4.288439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207473</th>\n",
       "      <td>2019-12-31 12:36:00</td>\n",
       "      <td>51287</td>\n",
       "      <td>51.482359</td>\n",
       "      <td>Barop Parkhaus</td>\n",
       "      <td>7.432326</td>\n",
       "      <td>2019-12-31 15:14:00</td>\n",
       "      <td>51.490505</td>\n",
       "      <td>An der Palmweide</td>\n",
       "      <td>7.438352</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.432326 51.482359)</td>\n",
       "      <td>3079</td>\n",
       "      <td>44225</td>\n",
       "      <td>44225 Dortmund</td>\n",
       "      <td>7.216678</td>\n",
       "      <td>21989</td>\n",
       "      <td>1.753557</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207474</th>\n",
       "      <td>2019-12-31 22:37:00</td>\n",
       "      <td>500113</td>\n",
       "      <td>51.510976</td>\n",
       "      <td>Stadtgarten</td>\n",
       "      <td>7.464534</td>\n",
       "      <td>2019-12-31 23:05:00</td>\n",
       "      <td>51.486747</td>\n",
       "      <td>Am Beilstück</td>\n",
       "      <td>7.435750</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.464534044265747 51.51097605329955)</td>\n",
       "      <td>3071</td>\n",
       "      <td>44135</td>\n",
       "      <td>44135 Dortmund</td>\n",
       "      <td>1.469342</td>\n",
       "      <td>11921</td>\n",
       "      <td>4.154393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207475</th>\n",
       "      <td>2019-12-31 23:38:00</td>\n",
       "      <td>500113</td>\n",
       "      <td>51.486747</td>\n",
       "      <td>Am Beilstück</td>\n",
       "      <td>7.435750</td>\n",
       "      <td>2019-12-31 23:52:00</td>\n",
       "      <td>51.502318</td>\n",
       "      <td>Kreuzstraße</td>\n",
       "      <td>7.450029</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.43575 51.48674699999999)</td>\n",
       "      <td>3079</td>\n",
       "      <td>44225</td>\n",
       "      <td>44225 Dortmund</td>\n",
       "      <td>7.216678</td>\n",
       "      <td>21989</td>\n",
       "      <td>1.713938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207476 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime_start  b_number_start  latitude_start  \\\n",
       "0       2019-01-20 16:22:00           50641       51.506312   \n",
       "1       2019-01-20 02:31:00           50425       51.517155   \n",
       "2       2019-01-20 11:32:00           53006       51.509557   \n",
       "3       2019-01-20 14:38:00           53006       51.517155   \n",
       "4       2019-01-20 17:02:00           53006       51.500725   \n",
       "...                     ...             ...             ...   \n",
       "207471  2019-12-31 12:39:00          500019       51.500675   \n",
       "207472  2019-12-31 19:28:00          500019       51.517155   \n",
       "207473  2019-12-31 12:36:00           51287       51.482359   \n",
       "207474  2019-12-31 22:37:00          500113       51.510976   \n",
       "207475  2019-12-31 23:38:00          500113       51.486747   \n",
       "\n",
       "                         p_name_start  longitude_start         datetime_end  \\\n",
       "0                  Hainallee / Südbad         7.470531  2019-01-20 17:00:00   \n",
       "1       Hauptbahnhof/Bahnhofsvorplatz         7.459931  2019-01-20 02:43:00   \n",
       "2                      Ritterhausstr.         7.446949  2019-01-20 13:33:00   \n",
       "3       Hauptbahnhof/Bahnhofsvorplatz         7.459931  2019-01-20 14:53:00   \n",
       "4                    Polizeipräsidium         7.459819  2019-01-20 17:16:00   \n",
       "...                               ...              ...                  ...   \n",
       "207471                    Kuithanstr.         7.440834  2019-12-31 12:54:00   \n",
       "207472  Hauptbahnhof/Bahnhofsvorplatz         7.459931  2019-12-31 19:35:00   \n",
       "207473                 Barop Parkhaus         7.432326  2019-12-31 15:14:00   \n",
       "207474                    Stadtgarten         7.464534  2019-12-31 23:05:00   \n",
       "207475                   Am Beilstück         7.435750  2019-12-31 23:52:00   \n",
       "\n",
       "        latitude_end                        p_name_end  longitude_end  \\\n",
       "0          51.493966  TU Dortmund Emil-Figge-Straße 50       7.418008   \n",
       "1          51.513069                         Unionstr.       7.448886   \n",
       "2          51.517155     Hauptbahnhof/Bahnhofsvorplatz       7.459931   \n",
       "3          51.500725                  Polizeipräsidium       7.459819   \n",
       "4          51.514029                      Schwanenwall       7.472570   \n",
       "...              ...                               ...            ...   \n",
       "207471     51.517155     Hauptbahnhof/Bahnhofsvorplatz       7.459931   \n",
       "207472     51.513069                         Unionstr.       7.448886   \n",
       "207473     51.490505                  An der Palmweide       7.438352   \n",
       "207474     51.486747                      Am Beilstück       7.435750   \n",
       "207475     51.502318                       Kreuzstraße       7.450029   \n",
       "\n",
       "        trip_duration  ...                                     geometry  \\\n",
       "0                  38  ...    POINT (7.470531463623098 51.506311756219)   \n",
       "1                  12  ...    POINT (7.459931373596199 51.517155427985)   \n",
       "2                 121  ...    POINT (7.4469494819641 51.50955711581999)   \n",
       "3                  15  ...    POINT (7.459931373596199 51.517155427985)   \n",
       "4                  14  ...      POINT (7.4598187208176 51.500725323279)   \n",
       "...               ...  ...                                          ...   \n",
       "207471             15  ...  POINT (7.440834045410155 51.50067523261729)   \n",
       "207472              7  ...   POINT (7.459931373596191 51.5171554279852)   \n",
       "207473            158  ...                   POINT (7.432326 51.482359)   \n",
       "207474             28  ...  POINT (7.464534044265747 51.51097605329955)   \n",
       "207475             14  ...            POINT (7.43575 51.48674699999999)   \n",
       "\n",
       "        index_right    plz            note       qkm  einwohner  \\\n",
       "0              3073  44139  44139 Dortmund  4.896154      19843   \n",
       "1              3072  44137  44137 Dortmund  3.281205      21573   \n",
       "2              3072  44137  44137 Dortmund  3.281205      21573   \n",
       "3              3072  44137  44137 Dortmund  3.281205      21573   \n",
       "4              3073  44139  44139 Dortmund  4.896154      19843   \n",
       "...             ...    ...             ...       ...        ...   \n",
       "207471         3072  44137  44137 Dortmund  3.281205      21573   \n",
       "207472         3072  44137  44137 Dortmund  3.281205      21573   \n",
       "207473         3079  44225  44225 Dortmund  7.216678      21989   \n",
       "207474         3071  44135  44135 Dortmund  1.469342      11921   \n",
       "207475         3079  44225  44225 Dortmund  7.216678      21989   \n",
       "\n",
       "        distanceToUniversity towardsUniversity  awayFromUniversity  \\\n",
       "0                   4.306089                 1                   0   \n",
       "1                   4.288439                 0                   0   \n",
       "2                   3.055201                 0                   0   \n",
       "3                   4.288439                 0                   0   \n",
       "4                   3.401936                 0                   0   \n",
       "...                      ...               ...                 ...   \n",
       "207471              2.162931                 0                   0   \n",
       "207472              4.288439                 0                   0   \n",
       "207473              1.753557                 0                   0   \n",
       "207474              4.154393                 0                   0   \n",
       "207475              1.713938                 0                   0   \n",
       "\n",
       "                tripLabel  \n",
       "0       towardsUniversity  \n",
       "1        noUniversityRide  \n",
       "2        noUniversityRide  \n",
       "3        noUniversityRide  \n",
       "4        noUniversityRide  \n",
       "...                   ...  \n",
       "207471   noUniversityRide  \n",
       "207472   noUniversityRide  \n",
       "207473   noUniversityRide  \n",
       "207474   noUniversityRide  \n",
       "207475   noUniversityRide  \n",
       "\n",
       "[207476 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to optimize hyper-parameters of a Logistic Regression model using Grid Search in Python\n",
    "def optimize_hyperparameters(X,y):\n",
    "\n",
    "    # Create an scaler object\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Create a pca object\n",
    "    pca = decomposition.PCA()\n",
    "\n",
    "    # Create a logistic regression object with an L2 penalty\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "\n",
    "    # Create a pipeline of three steps. First, standardize the data.\n",
    "    # Second, tranform the data with PCA.\n",
    "    # Third, train a logistic regression on the data.\n",
    "    pipe = Pipeline(steps=[('sc', sc),\n",
    "                           ('pca', pca),\n",
    "                           ('logistic', logistic)])\n",
    "\n",
    "    # Create Parameter Space\n",
    "    # Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "    # Create a list of values of the regularization parameter\n",
    "    C = np.logspace(-4, 4, 50)\n",
    "    # Create a list of options for the regularization penalty\n",
    "    penalty = ['l1', 'l2']\n",
    "    # Create a dictionary of all the parameter options \n",
    "    # Note has you can access the parameters of steps of a pipeline by using '__’\n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                      logistic__C=C,\n",
    "                      logistic__penalty=penalty)\n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    # View The Best Parameters\n",
    "    print('Best Penalty:', clf.best_estimator_.get_params()['logistic__penalty'])\n",
    "    print('Best C:', clf.best_estimator_.get_params()['logistic__C'])\n",
    "    print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf.best_estimator_.get_params()['logistic'])\n",
    "\n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    CV_Result = cross_val_score(clf, X, y, cv=4, n_jobs=-1)\n",
    "    print(); print(CV_Result)\n",
    "    print(); print(CV_Result.mean())\n",
    "    print(); print(CV_Result.std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']\n",
    "y_away = data['awayFromUniversity']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the best parameters for logistic regression for the attribute awayFromUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.12648552168552957\n",
      "Best Number Of Components: 4\n",
      "\n",
      "LogisticRegression(C=0.12648552168552957, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "[0.9854441  0.98681293 0.98557905 0.98640807]\n",
      "\n",
      "0.9860610383851627\n",
      "\n",
      "0.0005698014886013382\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the best parameters for logistic regression for the attribute towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.8286427728546842\n",
      "Best Number Of Components: 5\n",
      "\n",
      "LogisticRegression(C=0.8286427728546842, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "[0.91808209 0.91808209 0.91684821 0.91573001]\n",
      "\n",
      "0.9171856021901329\n",
      "\n",
      "0.0009797906933469204\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=4).fit(X)\n",
    "X_pca = pca_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     56941\n",
      "           1       0.87      0.99      0.93      5302\n",
      "\n",
      "    accuracy                           0.99     62243\n",
      "   macro avg       0.93      0.99      0.96     62243\n",
      "weighted avg       0.99      0.99      0.99     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create model based on the optimal parameters\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_away, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.12648552168552957, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     57109\n",
      "           1       0.53      0.08      0.14      5134\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.73      0.54      0.55     62243\n",
      "weighted avg       0.89      0.92      0.89     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.8286427728546842, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS DOES NOT WORK FOR OptimizeParameters because it has to be done on the training set (and not on the test set), but optimizeparameters processes both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OS Für towardsUNI\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "# os = SMOTE(random_state=0)\n",
    "\n",
    "# columns = X_train.columns\n",
    "# X_train_res,y_train_res =os.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "\n",
    "# print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "# print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "\n",
    "# st_scaler = StandardScaler()\n",
    "# X_train_res_scaled = st_scaler.fit_transform(X_train_res)\n",
    "\n",
    "\n",
    "# log = LogisticRegression(C=4.0, multi_class='multinomial', solver = 'newton-cg')\n",
    "# log.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "# X_test_scaled = st_scaler.transform(X_test)\n",
    "# y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "# print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_awayFromUniversity(X):\n",
    "    # set the model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "    st_scaler = StandardScaler()\n",
    "    X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "    # TODO: Modell anpassen\n",
    "    log = LogisticRegression(C=0.18420699693267145, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "    log.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # scale the input\n",
    "    X_scaled = st_scaler.fit_transform(X)\n",
    "    \n",
    "    # predict outcome\n",
    "    y_pred = log.predict(X_scaled)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize parameters for SVM\n",
    "\n",
    "However, I had to stop this function, because it lasted too long (stopped after about 1 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_svm(X,y, nfolds):\n",
    "    # defining parameter range \n",
    "    param_grid = [{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "                  {'C': [0.1, 1, 10, 100, 1000],  \n",
    "                  'gamma': [1, 0.5, 0.3, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['rbf']}]\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=nfolds) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X, y) \n",
    "    \n",
    "    # print best parameter after tuning \n",
    "    print(grid.best_params_) \n",
    "  \n",
    "    # print how our model looks after hyper-parameter tuning \n",
    "    print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.977, total=  49.2s\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   49.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.978, total= 3.1min\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.982, total= 1.5min\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV] ................ C=0.1, kernel=linear, score=0.982, total=  52.8s\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV] ................ C=0.1, kernel=linear, score=0.979, total= 1.3min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.977, total= 2.1min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.978, total= 2.3min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.976, total= 2.1min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.982, total= 1.9min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.979, total= 2.1min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.978, total= 4.8min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.978, total= 7.4min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.976, total= 5.8min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.982, total= 5.0min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.979, total= 5.1min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.979, total=23.5min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.981, total=17.3min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.981, total=10.4min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.982, total= 6.0min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.982, total=13.3min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.977, total= 1.7min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.981, total= 2.9min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.982, total= 2.1min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.984, total= 2.0min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.981, total= 3.9min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.922, total= 5.5min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.972, total= 8.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.950, total=12.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.971, total= 9.0min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.942, total= 5.1min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.943, total= 4.4min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.975, total= 4.5min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.965, total= 7.8min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.981, total= 9.0min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.972, total= 4.8min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.944, total= 2.9min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.976, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.974, total= 1.9min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.981, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.975, total= 2.8min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.976, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.978, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.980, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.981, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.975, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.977, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.978, total= 1.4min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.981, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.981, total= 1.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.976, total= 2.0min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.977, total= 4.8min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.975, total= 3.3min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.975, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.981, total= 2.0min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.973, total= 2.8min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.5min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.923, total= 9.1min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.979, total= 9.7min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.955, total= 9.6min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.979, total=11.3min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.946, total=11.3min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.946, total= 2.5min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.978, total= 6.2min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.974, total= 9.0min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.983, total= 9.0min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.977, total= 5.6min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] ......... C=1, gamma=0.3, kernel=rbf, score=0.944, total=255.2min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.978, total= 4.5min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.980, total= 3.9min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.983, total= 4.6min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.979, total= 4.0min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.977, total= 1.0min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.978, total= 1.2min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.982, total= 1.1min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.982, total= 1.1min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.979, total= 1.1min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.977, total=  57.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.978, total=  57.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.982, total= 1.0min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.982, total= 1.0min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.979, total=  59.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.977, total= 1.2min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.978, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.982, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.979, total= 1.2min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.977, total= 2.4min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.975, total= 2.9min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.978, total= 3.0min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.982, total= 2.9min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.979, total= 3.8min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.929, total=10.1min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.977, total=21.1min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.960, total=20.9min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.977, total=20.5min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.951, total=22.9min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.942, total= 4.1min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.978, total= 5.0min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.975, total= 5.3min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.983, total= 5.3min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.980, total=11.6min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.953, total= 8.2min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.980, total= 6.3min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.976, total= 4.3min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.981, total= 4.7min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.980, total= 4.3min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.976, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.981, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.4min\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.977, total=  48.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.978, total=  49.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.984, total=  49.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.984, total=  50.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.979, total=  51.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.977, total=  51.1s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.978, total=  54.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.982, total=  54.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.982, total=  55.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.979, total=  56.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.977, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.978, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.979, total= 1.2min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.930, total=14.6min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.977, total=13.2min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.960, total=14.7min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.978, total=13.4min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.949, total=15.1min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.944, total=11.8min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.978, total=10.3min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.973, total=11.9min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.979, total= 9.6min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.974, total=13.4min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.964, total= 6.1min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.977, total= 7.1min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.975, total= 6.7min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.981, total= 8.7min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_svm(X,y_away, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize parameters for RandomForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_randomforest(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # random forest model creation\n",
    "    rfc = RandomForestClassifier()\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    # Random search of parameters\n",
    "    rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the model\n",
    "    rfc_random.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['tripLabel']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 174.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 339.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 2527     1   527]\n",
      " [    6 53960   150]\n",
      " [ 1086  2670  1316]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniveristy       0.70      0.83      0.76      3055\n",
      "  noUniversityRide       0.95      1.00      0.97     54116\n",
      " towardsUniversity       0.66      0.26      0.37      5072\n",
      "\n",
      "          accuracy                           0.93     62243\n",
      "         macro avg       0.77      0.69      0.70     62243\n",
      "      weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.28142472 0.88143436 0.88167534 0.87516869 0.88018122 0.91517255\n",
      " 0.91256567 0.91169808 0.90596231 0.91748205]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8362764975327857\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=1000, min_samples_split = 2,min_samples_leaf=1, max_depth=10, max_features='auto', bootstrap= False)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# awayFromUniversity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_away = data['awayFromUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 303.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 340.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56975     0]\n",
      " [    0  5268]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56975\n",
      "           1       1.00      1.00      1.00      5268\n",
      "\n",
      "    accuracy                           1.00     62243\n",
      "   macro avg       1.00      1.00      1.00     62243\n",
      "weighted avg       1.00      1.00      1.00     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 5,min_samples_leaf=1, max_depth=30, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_away, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-442aa1b29c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mrfc_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrfc_cv_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_away\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=== Confusion Matrix ===\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[1;32m--> 154\u001b[1;33m                                            n_samples_bootstrap)\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0msample_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train_scaled,y_train)\n",
    "rfc_predict = rfc.predict(X_test_scaled)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_away, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 152.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 293.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56783   459]\n",
      " [ 3951  1050]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     57242\n",
      "           1       0.70      0.21      0.32      5001\n",
      "\n",
      "    accuracy                           0.93     62243\n",
      "   macro avg       0.82      0.60      0.64     62243\n",
      "weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.62230677 0.89718263 0.89805715 0.87987842 0.89694665 0.8827083\n",
      " 0.87964691 0.86347401 0.8492312  0.88101501]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8550447057307388\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=2000, min_samples_split = 5,min_samples_leaf=1, max_depth=10, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[48882   822]\n",
      " [ 2738  1522]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     49704\n",
      "           1       0.65      0.36      0.46      4260\n",
      "\n",
      "    accuracy                           0.93     53964\n",
      "   macro avg       0.80      0.67      0.71     53964\n",
      "weighted avg       0.92      0.93      0.93     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.93565743 0.89678107 0.8941965  0.8747515  0.89468118 0.87757435\n",
      " 0.85940205 0.86497195 0.86965635 0.87721417]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.884488655465079\n"
     ]
    }
   ],
   "source": [
    "# DAS HIER WAR SKALIERT VORHER\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: X is a dataset of trips that have to be predicted\n",
    "def cluster_area_start(X, km):\n",
    "    st_scaler = StandardScaler()\n",
    "    X_scaled = st_scaler.fit_transform(X)\n",
    "\n",
    "    X[\"area_start\"] = km.predict(X_scaled)+1\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    # TODO: calculate the relevant attributes (distanceToUniversty, weekend, hour, month, area start)\n",
    "    # these attributes are not in the dataset on default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set here Prediction Model \"awayFromUniversity\" \n",
    "# pred_model_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set here Prediction Model \"awayFromUniversity\" \n",
    "# pred_model_towards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: X is a dataset of trips that have to be predicted\n",
    "def predict_awayFromUniversity(X):\n",
    "    X_predictors = X[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]\n",
    "    \n",
    "    #maybe scale ?!?!\n",
    "    \n",
    "    X['towardsUniversityPrediction'] = pred_model_away.predict(X_predictors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_towardsUniversity(X):\n",
    "    X_predictors = X[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]\n",
    "    \n",
    "    #maybe scale ?!?!\n",
    "    \n",
    "     X['awayFromUniversityPrediction'] = pred_model_towards.predict(X_predictors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictedTripLabel(X):\n",
    "    towardsUniversity = X['towardsUniversityPrediction']\n",
    "    awayFromUniversity = X['awayFromUniversityPrediction']\n",
    "    \n",
    "    if ((towardsUniversity == 1) & (awayFromUniversity == 0)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((towardsUniversity == 0) & (awayFromUniversity == 1)):\n",
    "        return 'awayFromUniveristy'\n",
    "    if ((towardsUniversity == 1) & (awayFromUniversity == 1)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((towardsUniversity == 0) & (awayFromUniversity == 0)):\n",
    "        return 'noUniversityRide'\n",
    "    \n",
    "    warnings.warn(\"Warning...........Message\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Process:\n",
    "\n",
    "Assumption: We get a dataset/dataframe X with trips that have to be predicted\n",
    "\n",
    "1) Define the KMeans-clustering variable km\n",
    "\n",
    "2) Define the 2 models (pred_model_away, pred_model_towards)\n",
    "\n",
    "3) get the clustered start area : cluster_area_start(X, km)\n",
    "\n",
    "4) calculate the relevant attributes for the prediction: preprocess(X)\n",
    "\n",
    "5) Predict the attributes 'towardsUniversity' and 'awayFromUniversity': predict_towardsUniversity(X), predict_awayFromUniversity(X)\n",
    "\n",
    "6) Get the output-code. This means the predicted values 0/1 are mapped to the labels \"towardsUniversty\", \"awayFromUniversity\", \"noUniversityRide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
