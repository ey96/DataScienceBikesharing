{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nextbike.preprocessing.Preprocessing as prep\n",
    "\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "from vincenty import vincenty \n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Lasso,Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures,StandardScaler\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/processed/dortmund_trips.csv', index_col=0)\n",
    "#df = df.sample(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"month\",\"weekday\",\"day\",\"hour\",\"minute\",\"latitude_start\",\"longitude_start\",\"area_start\",\n",
    "        \"temperature Â°C\",\"precipitation\", \"distanceToCentralStation\",\"distanceToUniversity\"]]\n",
    "y = df[\"trip_duration\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression - RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 28.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 66.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'cholesky', 'max_iter': 40, 'fit_intercept': True, 'copy_X': False, 'alpha': 50}\n"
     ]
    }
   ],
   "source": [
    "# parameter tuning\n",
    "poly_reg = PolynomialFeatures(degree = 4)\n",
    "x_poly = poly_reg.fit_transform(X_train)\n",
    "\n",
    "ridge = Ridge()\n",
    "alpha = [1,2,3,4,5,8,10,15,20,30,50]\n",
    "copy = [True, False]\n",
    "fit_intercept = [True,False]\n",
    "max_iter = [10,20,30,40,50,60,70,80,90,100]\n",
    "solver = ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "\n",
    "random_grid = {'alpha': alpha,\n",
    "               'copy_X': copy,\n",
    "               'fit_intercept': fit_intercept,\n",
    "               'max_iter': max_iter,\n",
    "               'solver': solver}\n",
    "\n",
    "# Random search of parameters\n",
    "ridge_random = RandomizedSearchCV(estimator = ridge, param_distributions = random_grid, n_iter = 100,\n",
    "                                  cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "ridge_random.fit(x_poly, y_train)\n",
    "# print results\n",
    "print(ridge_random.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest Regressor - RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 70.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 132.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1155, 'min_samples_split': 10, 'min_samples_leaf': 8, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# random forest model creation\n",
    "rfc = RandomForestRegressor()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8,10,15,20,30]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# random forest model creation\n",
    "rfc = RandomForestRegressor()\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8,10,15,20,30]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
