{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "import time \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "    \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_colwidth = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../data/processed/dortmund_trips.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>b_number</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>p_name_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>p_name_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>towardsUniversity</th>\n",
       "      <th>awayFromUniversity</th>\n",
       "      <th>tripLabel</th>\n",
       "      <th>temperature °C</th>\n",
       "      <th>precipitation in mm</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>area_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20 16:22:00</td>\n",
       "      <td>50641</td>\n",
       "      <td>51.506312</td>\n",
       "      <td>Hainallee / Südbad</td>\n",
       "      <td>7.470531</td>\n",
       "      <td>2019-01-20 17:00:00</td>\n",
       "      <td>51.493966</td>\n",
       "      <td>TU Dortmund Emil-Figge-Straße 50</td>\n",
       "      <td>7.418008</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>towardsUniversity</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-20 16:42:00</td>\n",
       "      <td>53940</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>Möllerbrücke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2019-01-20 16:44:00</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>Möllerbrücke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20 16:53:00</td>\n",
       "      <td>50061</td>\n",
       "      <td>51.503293</td>\n",
       "      <td>Vinckeplatz</td>\n",
       "      <td>7.455822</td>\n",
       "      <td>2019-01-20 17:13:00</td>\n",
       "      <td>51.519332</td>\n",
       "      <td>Cinestar</td>\n",
       "      <td>7.460124</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-20 16:35:00</td>\n",
       "      <td>51138</td>\n",
       "      <td>51.499039</td>\n",
       "      <td>Steigenberger Hotel / Berswordtstr.</td>\n",
       "      <td>7.451472</td>\n",
       "      <td>2019-01-20 16:37:00</td>\n",
       "      <td>51.499039</td>\n",
       "      <td>Steigenberger Hotel / Berswordtstr.</td>\n",
       "      <td>7.451472</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-20 16:43:00</td>\n",
       "      <td>53120</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>Möllerbrücke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2019-01-20 17:02:00</td>\n",
       "      <td>51.512836</td>\n",
       "      <td>Am Kaiserbrunnen</td>\n",
       "      <td>7.482258</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207471</th>\n",
       "      <td>2019-12-31 09:10:00</td>\n",
       "      <td>500084</td>\n",
       "      <td>51.532685</td>\n",
       "      <td>Immermannstr./Klinikzentrum</td>\n",
       "      <td>7.454631</td>\n",
       "      <td>2019-12-31 09:21:00</td>\n",
       "      <td>51.516831</td>\n",
       "      <td>Kuckelke</td>\n",
       "      <td>7.469189</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207472</th>\n",
       "      <td>2019-12-31 09:07:00</td>\n",
       "      <td>500011</td>\n",
       "      <td>51.532685</td>\n",
       "      <td>Immermannstr./Klinikzentrum</td>\n",
       "      <td>7.454631</td>\n",
       "      <td>2019-12-31 09:21:00</td>\n",
       "      <td>51.516831</td>\n",
       "      <td>Kuckelke</td>\n",
       "      <td>7.469189</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207473</th>\n",
       "      <td>2019-12-31 09:11:00</td>\n",
       "      <td>500837</td>\n",
       "      <td>51.492690</td>\n",
       "      <td>Universität/S-Bahnhof</td>\n",
       "      <td>7.417633</td>\n",
       "      <td>2019-12-31 09:31:00</td>\n",
       "      <td>51.512609</td>\n",
       "      <td>Hansastr.</td>\n",
       "      <td>7.463483</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>awayFromUniversity</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207474</th>\n",
       "      <td>2019-12-31 09:57:00</td>\n",
       "      <td>500118</td>\n",
       "      <td>51.518297</td>\n",
       "      <td>Geschwister-Scholl-Str.</td>\n",
       "      <td>7.474962</td>\n",
       "      <td>2019-12-31 10:08:00</td>\n",
       "      <td>51.512609</td>\n",
       "      <td>Hansastr.</td>\n",
       "      <td>7.463483</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>57</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207475</th>\n",
       "      <td>2019-12-31 05:25:00</td>\n",
       "      <td>500176</td>\n",
       "      <td>51.500725</td>\n",
       "      <td>Polizeipräsidium</td>\n",
       "      <td>7.459819</td>\n",
       "      <td>2019-12-31 05:34:00</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>365</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207476 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime_start  b_number  latitude_start  \\\n",
       "0       2019-01-20 16:22:00     50641       51.506312   \n",
       "1       2019-01-20 16:42:00     53940       51.507457   \n",
       "2       2019-01-20 16:53:00     50061       51.503293   \n",
       "3       2019-01-20 16:35:00     51138       51.499039   \n",
       "4       2019-01-20 16:43:00     53120       51.507457   \n",
       "...                     ...       ...             ...   \n",
       "207471  2019-12-31 09:10:00    500084       51.532685   \n",
       "207472  2019-12-31 09:07:00    500011       51.532685   \n",
       "207473  2019-12-31 09:11:00    500837       51.492690   \n",
       "207474  2019-12-31 09:57:00    500118       51.518297   \n",
       "207475  2019-12-31 05:25:00    500176       51.500725   \n",
       "\n",
       "                               p_name_start  longitude_start  \\\n",
       "0                        Hainallee / Südbad         7.470531   \n",
       "1                              Möllerbrücke         7.451364   \n",
       "2                               Vinckeplatz         7.455822   \n",
       "3       Steigenberger Hotel / Berswordtstr.         7.451472   \n",
       "4                              Möllerbrücke         7.451364   \n",
       "...                                     ...              ...   \n",
       "207471          Immermannstr./Klinikzentrum         7.454631   \n",
       "207472          Immermannstr./Klinikzentrum         7.454631   \n",
       "207473                Universität/S-Bahnhof         7.417633   \n",
       "207474              Geschwister-Scholl-Str.         7.474962   \n",
       "207475                     Polizeipräsidium         7.459819   \n",
       "\n",
       "               datetime_end  latitude_end  \\\n",
       "0       2019-01-20 17:00:00     51.493966   \n",
       "1       2019-01-20 16:44:00     51.507457   \n",
       "2       2019-01-20 17:13:00     51.519332   \n",
       "3       2019-01-20 16:37:00     51.499039   \n",
       "4       2019-01-20 17:02:00     51.512836   \n",
       "...                     ...           ...   \n",
       "207471  2019-12-31 09:21:00     51.516831   \n",
       "207472  2019-12-31 09:21:00     51.516831   \n",
       "207473  2019-12-31 09:31:00     51.512609   \n",
       "207474  2019-12-31 10:08:00     51.512609   \n",
       "207475  2019-12-31 05:34:00     51.517155   \n",
       "\n",
       "                                 p_name_end  longitude_end  trip_duration  \\\n",
       "0          TU Dortmund Emil-Figge-Straße 50       7.418008             38   \n",
       "1                              Möllerbrücke       7.451364              2   \n",
       "2                                  Cinestar       7.460124             20   \n",
       "3       Steigenberger Hotel / Berswordtstr.       7.451472              2   \n",
       "4                          Am Kaiserbrunnen       7.482258             19   \n",
       "...                                     ...            ...            ...   \n",
       "207471                             Kuckelke       7.469189             11   \n",
       "207472                             Kuckelke       7.469189             14   \n",
       "207473                            Hansastr.       7.463483             20   \n",
       "207474                            Hansastr.       7.463483             11   \n",
       "207475        Hauptbahnhof/Bahnhofsvorplatz       7.459931              9   \n",
       "\n",
       "        ... hour minute  day_of_year  towardsUniversity  awayFromUniversity  \\\n",
       "0       ...   16     22           20                  1                   0   \n",
       "1       ...   16     42           20                  0                   0   \n",
       "2       ...   16     53           20                  0                   0   \n",
       "3       ...   16     35           20                  0                   0   \n",
       "4       ...   16     43           20                  0                   0   \n",
       "...     ...  ...    ...          ...                ...                 ...   \n",
       "207471  ...    9     10          365                  0                   0   \n",
       "207472  ...    9      7          365                  0                   0   \n",
       "207473  ...    9     11          365                  0                   1   \n",
       "207474  ...    9     57          365                  0                   0   \n",
       "207475  ...    5     25          365                  0                   0   \n",
       "\n",
       "                 tripLabel  temperature °C  precipitation in mm  \\\n",
       "0        towardsUniversity             0.5                  0.0   \n",
       "1         noUniversityRide             0.5                  0.0   \n",
       "2         noUniversityRide             0.5                  0.0   \n",
       "3         noUniversityRide             0.5                  0.0   \n",
       "4         noUniversityRide             0.5                  0.0   \n",
       "...                    ...             ...                  ...   \n",
       "207471    noUniversityRide             3.2                  0.0   \n",
       "207472    noUniversityRide             3.2                  0.0   \n",
       "207473  awayFromUniversity             3.2                  0.0   \n",
       "207474    noUniversityRide             3.2                  0.0   \n",
       "207475    noUniversityRide             4.5                  0.0   \n",
       "\n",
       "        precipitation  area_start  \n",
       "0                   0           1  \n",
       "1                   0           1  \n",
       "2                   0           1  \n",
       "3                   0           1  \n",
       "4                   0           1  \n",
       "...               ...         ...  \n",
       "207471              0           3  \n",
       "207472              0           3  \n",
       "207473              0           2  \n",
       "207474              0           3  \n",
       "207475              0           1  \n",
       "\n",
       "[207476 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['tripLabel']\n",
    "# use only start-information to classify the trip-class\n",
    "X = df[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "F1score = []\n",
    "Support = []\n",
    "exetime = [] \n",
    "desc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_away = df['awayFromUniversity']\n",
    "y_towards = df['towardsUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_away_train, y_away_test = train_test_split(X,y_away,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56972\n",
      "           1       0.99      1.00      1.00      5271\n",
      "\n",
      "    accuracy                           1.00     62243\n",
      "   macro avg       1.00      1.00      1.00     62243\n",
      "weighted avg       1.00      1.00      1.00     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Logistic Regression (awayFromUniversity) \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = linear_model.LogisticRegression()\n",
    "mod.fit(X_train_scaled,y_away_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_away_test,y_pred,average='weighted')\n",
    "print(classification_report(y_away_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"Binary Logistic Regression\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts awayFromUniversity (is complementary to 2nd model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_towards_train, y_towards_test = train_test_split(X,y_towards,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     57120\n",
      "           1       0.53      0.07      0.12      5123\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.73      0.53      0.54     62243\n",
      "weighted avg       0.89      0.92      0.89     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Logistic Regression (towardsUniversity) \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = linear_model.LogisticRegression()\n",
    "mod.fit(X_train_scaled,y_towards_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_towards_test,y_pred,average='weighted')\n",
    "print(classification_report(y_towards_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"Binary Logistic Regression\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts towardsUniversity (is complementary to 1st model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilinear Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniversity       0.63      0.86      0.73      3072\n",
      "  noUniversityRide       0.96      0.98      0.97     54007\n",
      " towardsUniversity       0.47      0.22      0.30      5164\n",
      "\n",
      "          accuracy                           0.91     62243\n",
      "         macro avg       0.68      0.69      0.67     62243\n",
      "      weighted avg       0.90      0.91      0.90     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multilinear Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = linear_model.LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')\n",
    "mod.fit(X_train_scaled,y_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,y_pred,average='weighted')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"Multinomial Logistic Regression\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts tripLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 is usually more useful than accuracy, especially if you have an uneven class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the Hyperparameters for (binary) LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to optimize hyper-parameters of a binary Logistic Regression model using Grid Search\n",
    "def optimize_hyperparameters(X,y):\n",
    "\n",
    "    # Create an scaler object\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Create a pca object\n",
    "    pca = decomposition.PCA()\n",
    "\n",
    "    # Create a logistic regression object with an L2 penalty\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "\n",
    "    # Create a pipeline of three steps. First, standardize the data.\n",
    "    # Second, tranform the data with PCA.\n",
    "    # Third, train a logistic regression on the data.\n",
    "    pipe = Pipeline(steps=[('sc', sc),\n",
    "                           ('pca', pca),\n",
    "                           ('logistic', logistic)])\n",
    "\n",
    "    # Create Parameter Space\n",
    "    # Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "    # Create a list of values of the regularization parameter\n",
    "    C = np.logspace(-4, 4, 50)\n",
    "    # Create a list of options for the regularization penalty\n",
    "    penalty = ['l1', 'l2']\n",
    "    # Create a dictionary of all the parameter options \n",
    "    # Note has you can access the parameters of steps of a pipeline by using '__’\n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                      logistic__C=C,\n",
    "                      logistic__penalty=penalty)\n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    # View The Best Parameters\n",
    "    print('Best Penalty:', clf.best_estimator_.get_params()['logistic__penalty'])\n",
    "    print('Best C:', clf.best_estimator_.get_params()['logistic__C'])\n",
    "    print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf.best_estimator_.get_params()['logistic'])\n",
    "\n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    CV_Result = cross_val_score(clf, X, y, cv=4, n_jobs=-1)\n",
    "    print(); print(CV_Result)\n",
    "    print(); print(CV_Result.mean())\n",
    "    print(); print(CV_Result.std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = df['towardsUniversity']\n",
    "y_away = df['awayFromUniversity']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = df[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the best parameters for logistic regression for the attribute awayFromUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.12648552168552957\n",
      "Best Number Of Components: 4\n",
      "\n",
      "LogisticRegression(C=0.12648552168552957, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "[0.9854441  0.98681293 0.98557905 0.98640807]\n",
      "\n",
      "0.9860610383851627\n",
      "\n",
      "0.0005698014886013382\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the best parameters for logistic regression for the attribute towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.8286427728546842\n",
      "Best Number Of Components: 5\n",
      "\n",
      "LogisticRegression(C=0.8286427728546842, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "[0.91808209 0.91808209 0.91684821 0.91573001]\n",
      "\n",
      "0.9171856021901329\n",
      "\n",
      "0.0009797906933469204\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_towards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=4).fit(X)\n",
    "X_pca = pca_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_away_train, y_away_test = train_test_split(X_pca, y_away, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     57052\n",
      "           1       0.96      1.00      0.98      5191\n",
      "\n",
      "    accuracy                           1.00     62243\n",
      "   macro avg       0.98      1.00      0.99     62243\n",
      "weighted avg       1.00      1.00      1.00     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Logistic Regression (awayFromUniversity) \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = linear_model.LogisticRegression(C=0.12648552168552957, class_weight=None, dual=False,\n",
    "                                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                                   warm_start=False)\n",
    "\n",
    "mod.fit(X_train_scaled,y_away_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_away_test,y_pred,average='weighted')\n",
    "print(classification_report(y_away_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"Binary Logistic Regression\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Optimized hyperparameters of model in index 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_towards_train, y_towards_test = train_test_split(X,y_towards,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     57170\n",
      "           1       0.53      0.07      0.12      5073\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.73      0.53      0.54     62243\n",
      "weighted avg       0.89      0.92      0.89     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Logistic Regression (towardsUniversity) \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = linear_model.LogisticRegression(C=0.8286427728546842, class_weight=None, dual=False,\n",
    "                                       fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                                       max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                                       random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                                       warm_start=False)\n",
    "mod.fit(X_train_scaled,y_towards_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_towards_test,y_pred,average='weighted')\n",
    "print(classification_report(y_towards_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"Binary Logistic Regression\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Optimized hyperparameters of model in index 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Execution time (sec)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Binary Logistic Regression</td>\n",
       "      <td>0.999299</td>\n",
       "      <td>0.999293</td>\n",
       "      <td>0.999294</td>\n",
       "      <td>0.752478</td>\n",
       "      <td>Predicts awayFromUniversity (is complementary to 2nd model)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Binary Logistic Regression</td>\n",
       "      <td>0.890065</td>\n",
       "      <td>0.918320</td>\n",
       "      <td>0.887933</td>\n",
       "      <td>0.250331</td>\n",
       "      <td>Predicts towardsUniversity (is complementary to 1st model)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multinomial Logistic Regression</td>\n",
       "      <td>0.898683</td>\n",
       "      <td>0.913886</td>\n",
       "      <td>0.901719</td>\n",
       "      <td>8.989423</td>\n",
       "      <td>Predicts tripLabel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Binary Logistic Regression</td>\n",
       "      <td>0.996802</td>\n",
       "      <td>0.996674</td>\n",
       "      <td>0.996704</td>\n",
       "      <td>0.537564</td>\n",
       "      <td>Optimized hyperparameters of model in index 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Binary Logistic Regression</td>\n",
       "      <td>0.891143</td>\n",
       "      <td>0.919107</td>\n",
       "      <td>0.889501</td>\n",
       "      <td>0.259306</td>\n",
       "      <td>Optimized hyperparameters of model in index 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Algorithm  Precision    Recall   F1score  \\\n",
       "0       Binary Logistic Regression   0.999299  0.999293  0.999294   \n",
       "1       Binary Logistic Regression   0.890065  0.918320  0.887933   \n",
       "2  Multinomial Logistic Regression   0.898683  0.913886  0.901719   \n",
       "3       Binary Logistic Regression   0.996802  0.996674  0.996704   \n",
       "4       Binary Logistic Regression   0.891143  0.919107  0.889501   \n",
       "\n",
       "   Execution time (sec)  \\\n",
       "0              0.752478   \n",
       "1              0.250331   \n",
       "2              8.989423   \n",
       "3              0.537564   \n",
       "4              0.259306   \n",
       "\n",
       "                                                   Description  \n",
       "0  Predicts awayFromUniversity (is complementary to 2nd model)  \n",
       "1   Predicts towardsUniversity (is complementary to 1st model)  \n",
       "2                                           Predicts tripLabel  \n",
       "3                Optimized hyperparameters of model in index 0  \n",
       "4                Optimized hyperparameters of model in index 1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {\"Algorithm\":Algorithm,\n",
    "              \"Precision\":Precision, \n",
    "              \"Recall\": Recall,\n",
    "              \"F1score\": F1score,\n",
    "              \"Execution time (sec)\":exetime,\n",
    "              \"Description\":desc}\n",
    "\n",
    "df_result = pd.DataFrame(result_dict)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "F1score = []\n",
    "Support = []\n",
    "exetime = [] \n",
    "desc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     57052\n",
      "           1       0.00      0.00      0.00      5191\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.46      0.50      0.48     62243\n",
      "weighted avg       0.84      0.92      0.88     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM for awayFromUniversity\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = SVC(kernel='linear')\n",
    "mod.fit(X_train_scaled,y_away_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_away_test,y_pred,average='weighted')\n",
    "print(classification_report(y_away_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"SVM with linear kernel\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts awayFromUniversity (is complementary to 2nd model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     57170\n",
      "           1       0.00      0.00      0.00      5073\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.46      0.50      0.48     62243\n",
      "weighted avg       0.84      0.92      0.88     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM for towardsUniversity\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = SVC(kernel='linear')\n",
    "mod.fit(X_train_scaled,y_towards_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_towards_test,y_pred,average='weighted')\n",
    "print(classification_report(y_towards_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"SVM with linear kernel\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts towardsUniversity (is complementary to 1st model)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     57052\n",
      "           1       0.00      0.00      0.00      5191\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.46      0.50      0.48     62243\n",
      "weighted avg       0.84      0.92      0.88     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM for awayFromUniversity\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = SVC(kernel='rbf')\n",
    "mod.fit(X_train_scaled,y_away_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_away_test,y_pred,average='weighted')\n",
    "print(classification_report(y_away_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"SVM with rbf kernel\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts awayFromUniversity (is complementary to 4th model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     57170\n",
      "           1       0.72      0.05      0.10      5073\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.82      0.53      0.53     62243\n",
      "weighted avg       0.91      0.92      0.89     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM for towardsUniversity \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "scaler.fit(X_test)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "start = time.time()\n",
    "mod = SVC(kernel='rbf')\n",
    "mod.fit(X_train_scaled,y_towards_train)\n",
    "y_pred = mod.predict(X_test_scaled)\n",
    "end = time.time()\n",
    "\n",
    "precision,recall,fscore,support=score(y_towards_test,y_pred,average='weighted')\n",
    "print(classification_report(y_towards_test, y_pred))\n",
    "\n",
    "Algorithm.append(\"SVM with rbf kernel\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts towardsUniversity (is complementary to 3rd model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_svm(X,y, nfolds):\n",
    "    # defining parameter range \n",
    "    param_grid = [{'C': [0.1, 1, 10, 300], 'kernel': ['linear']},\n",
    "                  {'C': [0.1, 1, 10, 300],  \n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['rbf']}]\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=nfolds) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X, y) \n",
    "    \n",
    "    # print best parameter after tuning \n",
    "    print(grid.best_params_) \n",
    "  \n",
    "    # print how our model looks after hyper-parameter tuning \n",
    "    print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Execution time (sec)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM with linear kernel</td>\n",
       "      <td>0.840158</td>\n",
       "      <td>0.916601</td>\n",
       "      <td>0.876716</td>\n",
       "      <td>105.369310</td>\n",
       "      <td>Predicts awayFromUniversity (is complementary to 2nd model)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM with linear kernel</td>\n",
       "      <td>0.843636</td>\n",
       "      <td>0.918497</td>\n",
       "      <td>0.879477</td>\n",
       "      <td>97.975079</td>\n",
       "      <td>Predicts towardsUniversity (is complementary to 1st model)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM with rbf kernel</td>\n",
       "      <td>0.840158</td>\n",
       "      <td>0.916601</td>\n",
       "      <td>0.876716</td>\n",
       "      <td>297.771291</td>\n",
       "      <td>Predicts awayFromUniversity (is complementary to 4th model)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM with rbf kernel</td>\n",
       "      <td>0.905629</td>\n",
       "      <td>0.921148</td>\n",
       "      <td>0.888784</td>\n",
       "      <td>592.105684</td>\n",
       "      <td>Predicts towardsUniversity (is complementary to 3rd model)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Algorithm  Precision    Recall   F1score  \\\n",
       "0  SVM with linear kernel   0.840158  0.916601  0.876716   \n",
       "1  SVM with linear kernel   0.843636  0.918497  0.879477   \n",
       "2     SVM with rbf kernel   0.840158  0.916601  0.876716   \n",
       "3     SVM with rbf kernel   0.905629  0.921148  0.888784   \n",
       "\n",
       "   Execution time (sec)  \\\n",
       "0            105.369310   \n",
       "1             97.975079   \n",
       "2            297.771291   \n",
       "3            592.105684   \n",
       "\n",
       "                                                   Description  \n",
       "0  Predicts awayFromUniversity (is complementary to 2nd model)  \n",
       "1   Predicts towardsUniversity (is complementary to 1st model)  \n",
       "2  Predicts awayFromUniversity (is complementary to 4th model)  \n",
       "3   Predicts towardsUniversity (is complementary to 3rd model)  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {\"Algorithm\":Algorithm,\n",
    "              \"Precision\":Precision, \n",
    "              \"Recall\": Recall,\n",
    "              \"F1score\": F1score,\n",
    "              \"Execution time (sec)\":exetime,\n",
    "              \"Description\":desc}\n",
    "\n",
    "df_result = pd.DataFrame(result_dict)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hyperparameters cannot be optimized (due to computation power)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forrest to predict tripLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Algorithm = []\n",
    "Precision = []\n",
    "Recall = []\n",
    "F1score = []\n",
    "Support = []\n",
    "exetime = [] \n",
    "desc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 2528     0   614]\n",
      " [    0 53273   691]\n",
      " [ 1048  2244  1845]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniversity       0.71      0.80      0.75      3142\n",
      "  noUniversityRide       0.96      0.99      0.97     53964\n",
      " towardsUniversity       0.59      0.36      0.45      5137\n",
      "\n",
      "          accuracy                           0.93     62243\n",
      "         macro avg       0.75      0.72      0.72     62243\n",
      "      weighted avg       0.92      0.93      0.92     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.33622518 0.87478311 0.87078273 0.86813187 0.87724118 0.8954598\n",
      " 0.8893334  0.87169229 0.78367957 0.91357787]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8180906992631833\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier()\n",
    "mod.fit(X_train,y_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,y_pred,average='weighted')\n",
    "\n",
    "Algorithm.append(\"Random Forrest\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts tripLabel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Parameters of RandomForrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_randomforest(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # random forest model creation\n",
    "    rfc = RandomForestClassifier()\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    # Random search of parameters\n",
    "    rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the model\n",
    "    rfc_random.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 174.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 339.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 2693     0   449]\n",
      " [    0 53815   149]\n",
      " [ 1140  2678  1319]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniversity       0.70      0.86      0.77      3142\n",
      "  noUniversityRide       0.95      1.00      0.97     53964\n",
      " towardsUniversity       0.69      0.26      0.37      5137\n",
      "\n",
      "          accuracy                           0.93     62243\n",
      "         macro avg       0.78      0.70      0.71     62243\n",
      "      weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.35420281 0.88133796 0.88220551 0.87651822 0.88018122 0.91493156\n",
      " 0.91401166 0.91025208 0.89709356 0.92263942]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8433374011794988\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier(n_estimators=1000, min_samples_split = 2,min_samples_leaf=1, max_depth=10, max_features='auto', bootstrap= False)\n",
    "mod.fit(X_train,y_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,y_pred,average='weighted')\n",
    "\n",
    "Algorithm.append(\"Random Forrest\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Optimized hyperparameters of model in index 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary RandomForest\n",
    "### Prediction model for both attributes separately\n",
    "\n",
    "\n",
    "#### AwayFromUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_away_train, y_away_test = train_test_split(X,y_away,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56886     0]\n",
      " [    0  5357]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56886\n",
      "           1       1.00      1.00      1.00      5357\n",
      "\n",
      "    accuracy                           1.00     62243\n",
      "   macro avg       1.00      1.00      1.00     62243\n",
      "weighted avg       1.00      1.00      1.00     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier()\n",
    "mod.fit(X_train,y_away_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y_away, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_away_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_away_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "precision,recall,fscore,support=score(y_away_test,y_pred,average='weighted')\n",
    "\n",
    "Algorithm.append(\"Random Forrest\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts awayFromUniversity (complement)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 303.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 340.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56886     0]\n",
      " [    0  5357]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56886\n",
      "           1       1.00      1.00      1.00      5357\n",
      "\n",
      "    accuracy                           1.00     62243\n",
      "   macro avg       1.00      1.00      1.00     62243\n",
      "weighted avg       1.00      1.00      1.00     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier(n_estimators=400, min_samples_split = 5,min_samples_leaf=1, max_depth=30, max_features='sqrt', bootstrap= True)\n",
    "mod.fit(X_train,y_away_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y_away, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_away_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_away_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "precision,recall,fscore,support=score(y_away_test,y_pred,average='weighted')\n",
    "\n",
    "Algorithm.append(\"Random Forrest\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Optimized hyperparameters of model in index 2\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_towards_train, y_towards_test = train_test_split(X,y_towards,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[55775  1426]\n",
      " [ 3221  1821]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     57201\n",
      "           1       0.56      0.36      0.44      5042\n",
      "\n",
      "    accuracy                           0.93     62243\n",
      "   macro avg       0.75      0.67      0.70     62243\n",
      "weighted avg       0.91      0.93      0.92     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier()\n",
    "mod.fit(X_train,y_towards_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y_away, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_towards_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_towards_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "precision,recall,fscore,support=score(y_towards_test,y_pred,average='weighted')\n",
    "\n",
    "Algorithm.append(\"Random Forrest\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Predicts towardsUniversity (complement)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 152.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 293.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56609   592]\n",
      " [ 3836  1206]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     57201\n",
      "           1       0.67      0.24      0.35      5042\n",
      "\n",
      "    accuracy                           0.93     62243\n",
      "   macro avg       0.80      0.61      0.66     62243\n",
      "weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier(n_estimators=2000, min_samples_split = 5,min_samples_leaf=1, max_depth=10, max_features='sqrt', bootstrap= True)\n",
    "mod.fit(X_train,y_towards_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y_away, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_towards_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_towards_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "precision,recall,fscore,support=score(y_towards_test,y_pred,average='weighted')\n",
    "\n",
    "Algorithm.append(\"Random Forrest\")\n",
    "Precision.append(precision)\n",
    "Recall.append(recall)\n",
    "F1score.append(fscore)\n",
    "Support.append(support)\n",
    "exetime.append((end-start))\n",
    "desc.append(\"Optimized hyperparameters of model in index 4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Execution time (sec)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>0.915971</td>\n",
       "      <td>0.926144</td>\n",
       "      <td>0.918487</td>\n",
       "      <td>16.526235</td>\n",
       "      <td>Predicts tripLabel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>0.918142</td>\n",
       "      <td>0.929052</td>\n",
       "      <td>0.914644</td>\n",
       "      <td>131.005115</td>\n",
       "      <td>Optimized hyperparameters of model in index 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.359210</td>\n",
       "      <td>Predicts awayFromUniversity (complement)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.891498</td>\n",
       "      <td>Optimized hyperparameters of model in index 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>0.914250</td>\n",
       "      <td>0.925341</td>\n",
       "      <td>0.917834</td>\n",
       "      <td>13.856886</td>\n",
       "      <td>Predicts towardsUniversity (complement)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forrest</td>\n",
       "      <td>0.915007</td>\n",
       "      <td>0.928859</td>\n",
       "      <td>0.912970</td>\n",
       "      <td>239.189682</td>\n",
       "      <td>Optimized hyperparameters of model in index 4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Algorithm  Precision    Recall   F1score  Execution time (sec)  \\\n",
       "0  Random Forrest   0.915971  0.926144  0.918487             16.526235   \n",
       "1  Random Forrest   0.918142  0.929052  0.914644            131.005115   \n",
       "2  Random Forrest   1.000000  1.000000  1.000000              5.359210   \n",
       "3  Random Forrest   1.000000  1.000000  1.000000             18.891498   \n",
       "4  Random Forrest   0.914250  0.925341  0.917834             13.856886   \n",
       "5  Random Forrest   0.915007  0.928859  0.912970            239.189682   \n",
       "\n",
       "                                     Description  \n",
       "0                             Predicts tripLabel  \n",
       "1  Optimized hyperparameters of model in index 0  \n",
       "2       Predicts awayFromUniversity (complement)  \n",
       "3  Optimized hyperparameters of model in index 2  \n",
       "4        Predicts towardsUniversity (complement)  \n",
       "5  Optimized hyperparameters of model in index 4  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = {\"Algorithm\":Algorithm,\n",
    "              \"Precision\":Precision, \n",
    "              \"Recall\": Recall,\n",
    "              \"F1score\": F1score,\n",
    "              \"Execution time (sec)\":exetime,\n",
    "              \"Description\":desc}\n",
    "\n",
    "df_result = pd.DataFrame(result_dict)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of finally chosen model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 2603     0   470]\n",
      " [    0 53986   111]\n",
      " [ 1118  2685  1270]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniversity       0.70      0.85      0.77      3073\n",
      "  noUniversityRide       0.95      1.00      0.97     54097\n",
      " towardsUniversity       0.69      0.25      0.37      5073\n",
      "\n",
      "          accuracy                           0.93     62243\n",
      "         macro avg       0.78      0.70      0.70     62243\n",
      "      weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.3582032  0.88133796 0.8823983  0.87651822 0.88018122 0.91507615\n",
      " 0.91396346 0.90948089 0.89781655 0.92263942]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8437615379811207\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mod = RandomForestClassifier(n_estimators=1000, min_samples_split = 2,min_samples_leaf=1, max_depth=10, max_features='auto', bootstrap= False)\n",
    "mod.fit(X_train,y_train)\n",
    "y_pred = mod.predict(X_test)\n",
    "end = time.time()\n",
    "\n",
    "rfc_cv_score = cross_val_score(mod, X, y, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('\\n')\n",
    "\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9280604153986042\n"
     ]
    }
   ],
   "source": [
    "# 10 fold cross validation\n",
    "print (np.mean(cross_val_score(mod, X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
