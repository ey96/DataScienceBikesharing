{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semester Project - Nextbike\n",
    "## Task 1 - Exploration and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libaries for data exploration \n",
    "from vincenty import vincenty\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the csv\n",
    "df = pd.read_csv(\"../../data/internal/dortmund.csv\", index_col=0)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) The data set shows columns with prefixes p and b. What do you think do they represent? Also try to find good assumptions for the meanings of the columns.\n",
    "\n",
    "The prefix \"p\" stands for the <i> positon </i> and the prefix \"b\" describes the features for the used <i> bike</i> . \n",
    "\n",
    "###### Meanings of the columns\n",
    "\n",
    "| Column      | Description          |\n",
    "|-------------|----------------------|\n",
    "|<i> p_spot </i>      |True, if it is an official station                   |\n",
    "|<i>p_place_type </i>|                      |\n",
    "|<i>datetime </i></i>    |Datetime of the start or end of a trip |\n",
    "|<i>b_number </i>    |Bike ID                   |\n",
    "|<i>trip   </i>      |Values = [\"first, last, start, end] <br> defines if a trip starts or ends|\n",
    "|<i>p_uid </i>       |ID of the bike station / position                      |\n",
    "|<i>p_bikes </i>     |Number of available bikes at the postion                      |\n",
    "|<i>p_lat   </i>     |Latitude coordinate of the position                      |\n",
    "|<i>b_bike_type</i>  |Type of the used bike                      |\n",
    "|<i>p_name  </i>     |Street or station name of the current position                      |\n",
    "|<i>p_number  </i>   |ID of the postion / bike station                      |\n",
    "|<i>p_lng </i>       |Longitude coordinate of the position                      |\n",
    "|<i>p_bike   </i>    |                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) The trip column in your data set shows different values. Explain why there are not only two. Are examples with certain values for trip more informative for the analysis of mobility patterns than others?\n",
    "\n",
    "\n",
    "#### Analyse the trip column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"trip\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are four different values in the trip column [first, last, start, end]. \n",
    "At least two values are required to define whether the dataset belongs to the starting point or the end of the trip. This means that <b> one trip is represented in two successively rows </b> in the dataframe. One of the rows contains the values at the startinging point (i.e. datetime, start position) and the other row contains the values at the ending point of the trip. \n",
    "\n",
    "Let's have a deeper look in the dataframe and the trip column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# there are much more datasets which have the values \"start\" and \"end\" in the trip column\n",
    "df[\"trip\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df[\"trip\"] == \"first\") | (df[\"trip\"] ==\"last\")].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this filtered dataframe above it gets clear that the examples with the values **first** and **last** in the trip column don't make much sense. Most of the trips in this dataframe have an unlikely long trip duration. The start time of a trip is almost always at 0 AM and the end time of a trip is at 23:59 PM. \n",
    "Furthermore the start and the end positions of one trip are the same. \n",
    "\n",
    "It could be measurement errors or other data recording errors. <br> \n",
    "These datasets can be disregarded for the next steps, because they aren't suitable for further analysis, especially for the preditction of trip durations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Based on the given data, create a new DataFrame that stores (at least) the following trip information (“trip format”):\n",
    "- Bike Number\n",
    "- Start Time (Either as appropriate data type or as several columns from “Start Month” down to “Start Minute”)\n",
    "- Weekend (binary)\n",
    "- Start Position (Either as appropriate data type or as two columns for Longitude and Latitude),\n",
    "- Duration\n",
    "- End Time \n",
    "- End Position "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df[((df[\"trip\"] == \"start\") | (df[\"trip\"]==\"end\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are more \"start\" than \"end\" datasets \n",
    "df[\"trip\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check, if the next dataset belongs to the current dataset \n",
    "# this means that they build a pair for one trip\n",
    "# if they have the same trip type, we want to delete them \n",
    "deletionFilter = df[\"trip\"] != df[\"trip\"].shift(-1)\n",
    "deletionFilter.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6659 datasets which have the same trip type as the previous dataset. That's exactly the difference between the number of datasets for trip type \"start\" and \"end\". (see above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the filter \n",
    "df = df[deletionFilter]\n",
    "df.groupby(\"trip\").count() # the number of datasets for each trip type is equal now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus on datasets whith values \"start\" and \"end\" in the trip column\n",
    "# store the starting and ending events of a trip in two different dataframes\n",
    "df_start = df[(df[\"trip\"] == \"start\")] \n",
    "df_end = df[(df[\"trip\"] == \"end\")] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_start.reset_index(inplace=True)\n",
    "df_end.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the column names to distinguish the columns after a merge of the dateframes\n",
    "df_start.rename(columns={\"index\":\"index_start\",\"datetime\":\"datetime_start\", \"p_lat\":\"latitude_start\",\"p_lng\":\"longitude_start\",\"p_name\":\"p_name_start\",\"b_number\":\"b_number_start\",\"p_number\":\"p_number_start\"},inplace=True)\n",
    "df_end.rename(columns={\"index\":\"index_end\",\"datetime\":\"datetime_end\", \"p_lat\":\"latitude_end\",\"p_lng\":\"longitude_end\",\"p_name\":\"p_name_end\",\"b_number\":\"b_number_end\",\"p_number\":\"p_number_end\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the columns, which aren't necessary for the final dataframe\n",
    "df_start.drop(['p_spot', 'p_place_type',  'trip',\n",
    "       'p_uid', 'p_bikes', 'b_bike_type',\n",
    "       'p_bike'],inplace=True,axis=1)\n",
    "\n",
    "df_end.drop(['p_spot', 'p_place_type', 'trip',\n",
    "       'p_uid', 'p_bikes', 'b_bike_type',\n",
    "       'p_bike'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the index_end to merge the dataframes by index_start and index_end\n",
    "df_end[\"index_end\"] = df_end[\"index_end\"]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the two sepearte dataframes to the final dataframe \n",
    "# the final dataframe consists of datasets which describe a trip with features for the start and the end of a trip\n",
    "df_final = pd.merge(df_start,df_end,left_on=\"index_start\", right_on=\"index_end\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check if there is a trip with different bike numbers at the start and the end of the trip \n",
    "#- if so this wouldn't make sense \n",
    "df_final[df_final[\"b_number_start\"] != df_final[\"b_number_start\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the start time is later than the end time\n",
    "# if so this wouldn't make sense \n",
    "df_final[df_final[\"datetime_start\"] > df_final[\"datetime_end\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after merging we get as many datasets as the number of datasets for each trip type\n",
    "# a trip with its start and end features is represented in one row now\n",
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_number != 0 --> just focus on the trips from and to an official bike station \n",
    "df_final = df_final[(df_final[\"p_number_start\"] != 0) & (df_final[\"p_number_end\"] != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the redundant columns\n",
    "df_final.drop([\"index_start\",\"index_end\",\"b_number_end\",\"p_number_start\",\"p_number_end\"],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.rename(columns={\"b_number_start\":\"b_number\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values \n",
    "df_final.isna().any(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting objects to datetimes\n",
    "df_final[\"datetime_start\"] = pd.to_datetime(df_final[\"datetime_start\"])\n",
    "df_final[\"datetime_end\"] = pd.to_datetime(df_final[\"datetime_end\"])\n",
    "\n",
    "# adding the trip duration with the difference of start and end time\n",
    "df_final[\"trip_duration\"] = df_final[\"datetime_end\"] -df_final[\"datetime_start\"]\n",
    "\n",
    "#converting timedelta to numeric and format in minutes \n",
    "df_final[\"trip_duration\"] = pd.to_numeric(df_final[\"trip_duration\"] / 60000000000)\n",
    "\n",
    "df_final[\"coordinates_start\"] = list(zip(df_final[\"latitude_start\"],df_final[\"longitude_start\"]))\n",
    "df_final[\"coordinates_end\"] = list(zip(df_final[\"latitude_end\"],df_final[\"longitude_end\"]))\n",
    "\n",
    "# adding the distance between start and end position\n",
    "df_final[\"distance\"] = df_final.apply(\n",
    "    lambda x: vincenty([x[\"latitude_start\"], x[\"longitude_start\"]],\n",
    "                       [x[\"latitude_end\"], x[\"longitude_end\"]],),axis=1)\n",
    "\n",
    "# adding another distances\n",
    "df_final[\"distanceToUniversity\"] = df_final.apply(lambda x: vincenty([x[\"latitude_start\"], x[\"longitude_start\"]],\n",
    "                       [51.4928736,7.415647],),axis=1)\n",
    "df_final[\"distanceToCentralStation\"] = df_final.apply(lambda x: vincenty([x[\"latitude_start\"], x[\"longitude_start\"]],\n",
    "                       [51.5175, 7.458889],),axis=1)\n",
    "\n",
    "## adding the weekday of the start time of a trip; stored in integers (0: monday, 6:sunday)\n",
    "df_final['weekday'] = df_final['datetime_start'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which returns True for saturday and sunday; otherwise it returns False\n",
    "def isWeekend(index_of_day): \n",
    "    if index_of_day > 4: \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "# adding new boolean column \"weekend\"    \n",
    "df_final[\"weekend\"] = df_final[\"weekday\"].apply(lambda x: isWeekend(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform column \"datatime_start\" into several columns \n",
    "df_final[\"day\"] = df_final[\"datetime_start\"].apply(lambda x: x.day)\n",
    "df_final[\"month\"] = df_final[\"datetime_start\"].apply(lambda x: x.month)\n",
    "df_final[\"hour\"] = df_final[\"datetime_start\"].apply(lambda x: x.hour)\n",
    "df_final[\"minute\"] = df_final[\"datetime_start\"].apply(lambda x : x.minute)\n",
    "df_final[\"day_of_year\"] = df_final[\"datetime_start\"].apply(lambda x: x.timetuple().tm_yday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __get_tripLabel(row):\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'awayFromUniveristy'\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'noUniversityRide'\n",
    "\n",
    "    warnings.warn(\"Warning...........Message\")\n",
    "    return None\n",
    "\n",
    "# add the attribute whether a trip was done towards/away from university (for prediction in task 3b)\n",
    "# array with university stations\n",
    "university_stations = [\"TU Dortmund Seminarraumgebäude 1\", \"TU Dortmund Hörsaalgebäude 2\", \"Universität/S-Bahnhof\",\n",
    "                        \"TU Dortmund Emil-Figge-Straße 50\", \"FH-Dortmund Emil-Figge-Straße 42\"]\n",
    "\n",
    "df_final['towardsUniversity'] = df_final['p_name_end'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "df_final['awayFromUniversity'] = df_final['p_name_start'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "\n",
    "df_final['tripLabel'] = df_final.apply(lambda row: __get_tripLabel(row), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding weather features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following steps add three weather features to the final trip DataFrame. The ressource for the weather data is \"Deutscher Wetterdienst\". [Here](https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/hourly/), you can download the hourly weather data for several cities in Germany. \n",
    "\n",
    "The reason why we take the weather data for Waltrop-City is because there is no official weather station directly in Dortmund. There is no data for Dortmund accessable. Waltrop is the closest city to Dortmund, where weather data can be accessed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temperature for each hour in 2019 \n",
    "temp = pd.read_csv(\"../../data/external/WaltropTemp.txt\", sep = \";\")\n",
    "temp.rename(columns = {\"TT_TU\":\"temperature °C\", \"MESS_DATUM\":\"datetime\"}, inplace=True)\n",
    "temp.drop(labels=[\"STATIONS_ID\", \"QN_9\", \"eor\",\"RF_TU\"], axis=1, inplace=True)\n",
    "temp = temp[(temp[\"datetime\"] >= 2019010100) & (temp[\"datetime\"] <= 2019123123)]\n",
    "temp.reset_index(drop=True, inplace=True)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two features (precipitation in mm & precipitaion y/n) for each hour in 2019 \n",
    "precipitation = pd.read_csv(\"../../data/external/WaltropPrecipitation.txt\", sep = \";\")\n",
    "precipitation.rename(columns = {\"  R1\":\"precipitation in mm\", \"MESS_DATUM\":\"datetime\", \"RS_IND\":\"precipitation\"}, inplace=True)\n",
    "precipitation = precipitation[(precipitation[\"datetime\"] >= 2019010100) & (precipitation[\"datetime\"] <= 2019123123)]\n",
    "precipitation.drop(labels=[\"STATIONS_ID\", \"QN_8\", \"eor\",\"WRTR\"], axis=1, inplace=True)\n",
    "precipitation.reset_index(drop=True, inplace=True)\n",
    "precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge DataFrames for temperature and precipitaion to one DataFrame \n",
    "weather = pd.merge(temp,precipitation, on=\"datetime\")\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatDatetimeForMerging(x):\n",
    "    # return as integer for merging \n",
    "    return int(x[:13].replace('-','').replace(' ',''))\n",
    "\n",
    "df_final[\"datetime_start_for_merge_with_weather\"] = df_final[\"datetime_start\"].apply(lambda x: formatDatetimeForMerging(str(x)))\n",
    "\n",
    "# merge with weather data \n",
    "df_final = pd.merge(df_final, weather, left_on=\"datetime_start_for_merge_with_weather\", right_on=\"datetime\")\n",
    "\n",
    "# drop redundant columns \n",
    "df_final.drop(labels=[\"datetime\", \"datetime_start_for_merge_with_weather\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.to_csv('../../data/processed/dortmund_trips.csv')\n",
    "df_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Calculate the aggregate statistics (i.e., mean and standard deviation) for the trip duration per month, per day of week, and per hour of day. Are there visible differences between weekdays and weekends?\n",
    "\n",
    "(The differences between weekdays and weekends will be shown in Task 2 by visualizing the data)\n",
    "\n",
    "#### Calculating aggregate statistic per month, per day of week and per hour of day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistic per month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this array \"July\" is missing \n",
    "month_by_name = np.array([\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"August\", \"September\", \"October\", \"November\", \"December\"])\n",
    "\n",
    "# Means per month\n",
    "df_final.groupby(['month']).mean()[[\"trip_duration\"]].set_index(keys=month_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means per month\n",
    "# distinguish between weekend and workday\n",
    "df_final.groupby(['weekend', 'month']).mean()[[\"trip_duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no data for july."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation per month\n",
    "df_final.groupby(['month']).std()[[\"trip_duration\"]].set_index(keys=month_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation per month\n",
    "# distinguish between weekend and workday\n",
    "df_final.groupby(['weekend','month']).std()[[\"trip_duration\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistics per day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means \n",
    "weekday_by_name= np.array([\"Monday\", \"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"])\n",
    "df_final.groupby(['weekday']).mean()[[\"trip_duration\"]].set_index(weekday_by_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation \n",
    "df_final[[\"weekday\", \"trip_duration\"]].groupby(\"weekday\").std().set_index(weekday_by_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Statistics per hour of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means per hour\n",
    "df_final.groupby(['hour']).mean()[[\"trip_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Means per hour \n",
    "# distinguish between weekend and workday\n",
    "df_final.groupby(['weekend','hour']).mean()[[\"trip_duration\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation per hour\n",
    "df_final[[\"hour\", \"trip_duration\"]].groupby(\"hour\").std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation per hour\n",
    "# distinguish between weekend and workday\n",
    "df_final.groupby(['weekend','month']).std()[[\"trip_duration\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
