{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erkin\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import geopy\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vincenty import vincenty\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "    \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/dortmund_trips.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b_number</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>distance</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>temperature Â°C</th>\n",
       "      <th>precipitation in mm</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>area_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "      <td>207476.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>206360.600031</td>\n",
       "      <td>51.507129</td>\n",
       "      <td>7.456074</td>\n",
       "      <td>51.507193</td>\n",
       "      <td>7.456184</td>\n",
       "      <td>33.376010</td>\n",
       "      <td>0.907952</td>\n",
       "      <td>2.758546</td>\n",
       "      <td>0.216011</td>\n",
       "      <td>16.015317</td>\n",
       "      <td>7.187882</td>\n",
       "      <td>12.556942</td>\n",
       "      <td>12.309225</td>\n",
       "      <td>0.055196</td>\n",
       "      <td>0.112066</td>\n",
       "      <td>2.915532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>213713.119581</td>\n",
       "      <td>0.011740</td>\n",
       "      <td>0.025233</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.025143</td>\n",
       "      <td>83.413993</td>\n",
       "      <td>1.160495</td>\n",
       "      <td>1.915539</td>\n",
       "      <td>0.411523</td>\n",
       "      <td>8.623309</td>\n",
       "      <td>3.286835</td>\n",
       "      <td>5.812148</td>\n",
       "      <td>7.284724</td>\n",
       "      <td>0.298039</td>\n",
       "      <td>0.315448</td>\n",
       "      <td>1.021359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>843.000000</td>\n",
       "      <td>51.476038</td>\n",
       "      <td>7.334661</td>\n",
       "      <td>51.476038</td>\n",
       "      <td>7.334661</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50846.000000</td>\n",
       "      <td>51.498563</td>\n",
       "      <td>7.444455</td>\n",
       "      <td>51.498845</td>\n",
       "      <td>7.444455</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>53006.000000</td>\n",
       "      <td>51.509557</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>51.509557</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.632603</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>500100.000000</td>\n",
       "      <td>51.516234</td>\n",
       "      <td>7.469189</td>\n",
       "      <td>51.516234</td>\n",
       "      <td>7.469189</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1.339151</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500864.000000</td>\n",
       "      <td>51.541818</td>\n",
       "      <td>7.557450</td>\n",
       "      <td>51.541818</td>\n",
       "      <td>7.557450</td>\n",
       "      <td>1399.000000</td>\n",
       "      <td>10.505409</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            b_number  latitude_start  longitude_start   latitude_end  \\\n",
       "count  207476.000000   207476.000000    207476.000000  207476.000000   \n",
       "mean   206360.600031       51.507129         7.456074      51.507193   \n",
       "std    213713.119581        0.011740         0.025233       0.011730   \n",
       "min       843.000000       51.476038         7.334661      51.476038   \n",
       "25%     50846.000000       51.498563         7.444455      51.498845   \n",
       "50%     53006.000000       51.509557         7.459931      51.509557   \n",
       "75%    500100.000000       51.516234         7.469189      51.516234   \n",
       "max    500864.000000       51.541818         7.557450      51.541818   \n",
       "\n",
       "       longitude_end  trip_duration       distance        weekday  \\\n",
       "count  207476.000000  207476.000000  207476.000000  207476.000000   \n",
       "mean        7.456184      33.376010       0.907952       2.758546   \n",
       "std         0.025143      83.413993       1.160495       1.915539   \n",
       "min         7.334661       2.000000       0.000000       0.000000   \n",
       "25%         7.444455       3.000000       0.000000       1.000000   \n",
       "50%         7.459931       9.000000       0.632603       3.000000   \n",
       "75%         7.469189      21.000000       1.339151       4.000000   \n",
       "max         7.557450    1399.000000      10.505409       6.000000   \n",
       "\n",
       "             weekend            day          month           hour  \\\n",
       "count  207476.000000  207476.000000  207476.000000  207476.000000   \n",
       "mean        0.216011      16.015317       7.187882      12.556942   \n",
       "std         0.411523       8.623309       3.286835       5.812148   \n",
       "min         0.000000       1.000000       1.000000       0.000000   \n",
       "25%         0.000000       9.000000       4.000000       8.000000   \n",
       "50%         0.000000      16.000000       8.000000      13.000000   \n",
       "75%         0.000000      24.000000      10.000000      17.000000   \n",
       "max         1.000000      31.000000      12.000000      23.000000   \n",
       "\n",
       "       temperature Â°C  precipitation in mm  precipitation     area_start  \n",
       "count   207476.000000        207476.000000  207476.000000  207476.000000  \n",
       "mean        12.309225             0.055196       0.112066       2.915532  \n",
       "std          7.284724             0.298039       0.315448       1.021359  \n",
       "min         -8.900000             0.000000       0.000000       1.000000  \n",
       "25%          6.700000             0.000000       0.000000       2.000000  \n",
       "50%         11.700000             0.000000       0.000000       3.000000  \n",
       "75%         17.200000             0.000000       0.000000       4.000000  \n",
       "max         35.000000             7.700000       1.000000       4.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_point(row):\n",
    "    return Point(row.longitude_start, row.latitude_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are currently the coordinates of TU Dortmund HÃ¶rsaalgebÃ¤ude 2\n",
    "def calculate_distanceToUniversity(row):\n",
    "    # mean of the university-station-coordinates\n",
    "    university_center_lat = (51.492296 + 51.491721 + 51.49269 + 51.493966 + 51.493695) / 5\n",
    "    university_center_lon = (7.41273 + 7.409468 + 7.417633 + 7.418008 + 7.420396) / 5\n",
    "    \n",
    "    # distance of the start station to the \"center\" of the university-area\n",
    "    distance = vincenty([row[\"latitude_start\"], row[\"longitude_start\"]], [university_center_lat, university_center_lon],)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tripLabel(row):\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'awayFromUniveristy'\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'noUniversityRide'\n",
    "    \n",
    "    warnings.warn(\"Warning...........Message\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "\n",
    "    # ToDo: Diesen geometry-step kÃ¶nnte man auch bei preprocessing reinpacken, dann mÃ¼ssen wir das nicht doppelt berechnen\n",
    "    \n",
    "    # Go through every row, and make a point out of its lat and lon\n",
    "    df[\"geometry\"] = df.apply(make_point, axis=1)\n",
    "    # It doesn't come with a CRS because it's a CSV, so it has to be set\n",
    "    df.crs = {'init': 'epsg:4326'}\n",
    "    \n",
    "    # get geodata of germany (postal codes and their areas/polygons)\n",
    "    districts_germany = gpd.read_file(\"../data/external/germany_postalcodes.geojson\")\n",
    "    # filter for districts of dortmund\n",
    "    districts_dortmund = districts_germany[districts_germany[\"note\"].str.contains(\"Dortmund\")]\n",
    "    \n",
    "    #convert dataset of trips to geodataframe (so it can be merged later with the geodataframe of dortmund)\n",
    "    geo_df = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'}, geometry=df.geometry)\n",
    "    \n",
    "    # join the data\n",
    "    # merges data when POINT of trips is within POLYGON of a dortmund district\n",
    "    df_merged = gpd.sjoin(geo_df, districts_dortmund, how='left', op='within')\n",
    "    \n",
    "    # adding the distance between start position and the center of the university\n",
    "    df_merged[\"distanceToUniversity\"] = df_merged.apply(calculate_distanceToUniversity,axis=1)\n",
    "\n",
    "    \n",
    "    # add the attribute whether a trip was done towars/away from university\n",
    "    university_stations = [\"TU Dortmund SeminarraumgebÃ¤ude 1\", \"TU Dortmund HÃ¶rsaalgebÃ¤ude 2\", \"UniversitÃ¤t/S-Bahnhof\", \"TU Dortmund Emil-Figge-StraÃe 50\", \"FH-Dortmund Emil-Figge-StraÃe 42\"]\n",
    "\n",
    "    df_merged['towardsUniversity'] = df_merged['p_name_end'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "    df_merged['awayFromUniversity'] = df_merged['p_name_start'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "    \n",
    "    df_merged['tripLabel'] = df_merged.apply(lambda row: get_tripLabel(row), axis=1)\n",
    "    \n",
    "    #df_merged['area_start'] = ... # if we receive input data we have to calculate the attribute 'area_start'\n",
    "    # here I don't do it, because it already exists\n",
    "\n",
    "    \n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this was done so I could access the data fast\n",
    "# data.to_csv('../data/processed/prediction_data_with_outliers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/prediction_data_with_outliers.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>b_number</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>p_name_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>p_name_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>plz</th>\n",
       "      <th>note</th>\n",
       "      <th>qkm</th>\n",
       "      <th>einwohner</th>\n",
       "      <th>distanceToUniversity</th>\n",
       "      <th>towardsUniversity</th>\n",
       "      <th>awayFromUniversity</th>\n",
       "      <th>tripLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20 16:22:00</td>\n",
       "      <td>50641</td>\n",
       "      <td>51.506312</td>\n",
       "      <td>Hainallee / SÃ¼dbad</td>\n",
       "      <td>7.470531</td>\n",
       "      <td>2019-01-20 17:00:00</td>\n",
       "      <td>51.493966</td>\n",
       "      <td>TU Dortmund Emil-Figge-StraÃe 50</td>\n",
       "      <td>7.418008</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.47053 51.50631)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>4.094004</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>towardsUniversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-20 16:42:00</td>\n",
       "      <td>53940</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>MÃ¶llerbrÃ¼cke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2019-01-20 16:44:00</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>MÃ¶llerbrÃ¼cke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45136 51.50746)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>2.963796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-20 16:53:00</td>\n",
       "      <td>50061</td>\n",
       "      <td>51.503293</td>\n",
       "      <td>Vinckeplatz</td>\n",
       "      <td>7.455822</td>\n",
       "      <td>2019-01-20 17:13:00</td>\n",
       "      <td>51.519332</td>\n",
       "      <td>Cinestar</td>\n",
       "      <td>7.460124</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45582 51.50329)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>3.021170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-20 16:35:00</td>\n",
       "      <td>51138</td>\n",
       "      <td>51.499039</td>\n",
       "      <td>Steigenberger Hotel / Berswordtstr.</td>\n",
       "      <td>7.451472</td>\n",
       "      <td>2019-01-20 16:37:00</td>\n",
       "      <td>51.499039</td>\n",
       "      <td>Steigenberger Hotel / Berswordtstr.</td>\n",
       "      <td>7.451472</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45147 51.49904)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>2.580733</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-20 16:43:00</td>\n",
       "      <td>53120</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>MÃ¶llerbrÃ¼cke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2019-01-20 17:02:00</td>\n",
       "      <td>51.512836</td>\n",
       "      <td>Am Kaiserbrunnen</td>\n",
       "      <td>7.482258</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45136 51.50746)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>2.963796</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207471</th>\n",
       "      <td>2019-12-31 09:10:00</td>\n",
       "      <td>500084</td>\n",
       "      <td>51.532685</td>\n",
       "      <td>Immermannstr./Klinikzentrum</td>\n",
       "      <td>7.454631</td>\n",
       "      <td>2019-12-31 09:21:00</td>\n",
       "      <td>51.516831</td>\n",
       "      <td>Kuckelke</td>\n",
       "      <td>7.469189</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45463 51.53269)</td>\n",
       "      <td>3077</td>\n",
       "      <td>44147</td>\n",
       "      <td>44147 Dortmund</td>\n",
       "      <td>8.196036</td>\n",
       "      <td>22692</td>\n",
       "      <td>5.190721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207472</th>\n",
       "      <td>2019-12-31 09:07:00</td>\n",
       "      <td>500011</td>\n",
       "      <td>51.532685</td>\n",
       "      <td>Immermannstr./Klinikzentrum</td>\n",
       "      <td>7.454631</td>\n",
       "      <td>2019-12-31 09:21:00</td>\n",
       "      <td>51.516831</td>\n",
       "      <td>Kuckelke</td>\n",
       "      <td>7.469189</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45463 51.53269)</td>\n",
       "      <td>3077</td>\n",
       "      <td>44147</td>\n",
       "      <td>44147 Dortmund</td>\n",
       "      <td>8.196036</td>\n",
       "      <td>22692</td>\n",
       "      <td>5.190721</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207473</th>\n",
       "      <td>2019-12-31 09:11:00</td>\n",
       "      <td>500837</td>\n",
       "      <td>51.492690</td>\n",
       "      <td>UniversitÃ¤t/S-Bahnhof</td>\n",
       "      <td>7.417633</td>\n",
       "      <td>2019-12-31 09:31:00</td>\n",
       "      <td>51.512609</td>\n",
       "      <td>Hansastr.</td>\n",
       "      <td>7.463483</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.41763 51.49269)</td>\n",
       "      <td>3080</td>\n",
       "      <td>44227</td>\n",
       "      <td>44227 Dortmund</td>\n",
       "      <td>19.106338</td>\n",
       "      <td>17922</td>\n",
       "      <td>0.139429</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>awayFromUniveristy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207474</th>\n",
       "      <td>2019-12-31 09:57:00</td>\n",
       "      <td>500118</td>\n",
       "      <td>51.518297</td>\n",
       "      <td>Geschwister-Scholl-Str.</td>\n",
       "      <td>7.474962</td>\n",
       "      <td>2019-12-31 10:08:00</td>\n",
       "      <td>51.512609</td>\n",
       "      <td>Hansastr.</td>\n",
       "      <td>7.463483</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.47496 51.51830)</td>\n",
       "      <td>3071</td>\n",
       "      <td>44135</td>\n",
       "      <td>44135 Dortmund</td>\n",
       "      <td>1.469342</td>\n",
       "      <td>11921</td>\n",
       "      <td>4.996192</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207475</th>\n",
       "      <td>2019-12-31 05:25:00</td>\n",
       "      <td>500176</td>\n",
       "      <td>51.500725</td>\n",
       "      <td>PolizeiprÃ¤sidium</td>\n",
       "      <td>7.459819</td>\n",
       "      <td>2019-12-31 05:34:00</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.45982 51.50073)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>3.189484</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207476 rows Ã 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime_start  b_number  latitude_start  \\\n",
       "0       2019-01-20 16:22:00     50641       51.506312   \n",
       "1       2019-01-20 16:42:00     53940       51.507457   \n",
       "2       2019-01-20 16:53:00     50061       51.503293   \n",
       "3       2019-01-20 16:35:00     51138       51.499039   \n",
       "4       2019-01-20 16:43:00     53120       51.507457   \n",
       "...                     ...       ...             ...   \n",
       "207471  2019-12-31 09:10:00    500084       51.532685   \n",
       "207472  2019-12-31 09:07:00    500011       51.532685   \n",
       "207473  2019-12-31 09:11:00    500837       51.492690   \n",
       "207474  2019-12-31 09:57:00    500118       51.518297   \n",
       "207475  2019-12-31 05:25:00    500176       51.500725   \n",
       "\n",
       "                               p_name_start  longitude_start  \\\n",
       "0                        Hainallee / SÃ¼dbad         7.470531   \n",
       "1                              MÃ¶llerbrÃ¼cke         7.451364   \n",
       "2                               Vinckeplatz         7.455822   \n",
       "3       Steigenberger Hotel / Berswordtstr.         7.451472   \n",
       "4                              MÃ¶llerbrÃ¼cke         7.451364   \n",
       "...                                     ...              ...   \n",
       "207471          Immermannstr./Klinikzentrum         7.454631   \n",
       "207472          Immermannstr./Klinikzentrum         7.454631   \n",
       "207473                UniversitÃ¤t/S-Bahnhof         7.417633   \n",
       "207474              Geschwister-Scholl-Str.         7.474962   \n",
       "207475                     PolizeiprÃ¤sidium         7.459819   \n",
       "\n",
       "               datetime_end  latitude_end  \\\n",
       "0       2019-01-20 17:00:00     51.493966   \n",
       "1       2019-01-20 16:44:00     51.507457   \n",
       "2       2019-01-20 17:13:00     51.519332   \n",
       "3       2019-01-20 16:37:00     51.499039   \n",
       "4       2019-01-20 17:02:00     51.512836   \n",
       "...                     ...           ...   \n",
       "207471  2019-12-31 09:21:00     51.516831   \n",
       "207472  2019-12-31 09:21:00     51.516831   \n",
       "207473  2019-12-31 09:31:00     51.512609   \n",
       "207474  2019-12-31 10:08:00     51.512609   \n",
       "207475  2019-12-31 05:34:00     51.517155   \n",
       "\n",
       "                                 p_name_end  longitude_end  trip_duration  \\\n",
       "0          TU Dortmund Emil-Figge-StraÃe 50       7.418008             38   \n",
       "1                              MÃ¶llerbrÃ¼cke       7.451364              2   \n",
       "2                                  Cinestar       7.460124             20   \n",
       "3       Steigenberger Hotel / Berswordtstr.       7.451472              2   \n",
       "4                          Am Kaiserbrunnen       7.482258             19   \n",
       "...                                     ...            ...            ...   \n",
       "207471                             Kuckelke       7.469189             11   \n",
       "207472                             Kuckelke       7.469189             14   \n",
       "207473                            Hansastr.       7.463483             20   \n",
       "207474                            Hansastr.       7.463483             11   \n",
       "207475        Hauptbahnhof/Bahnhofsvorplatz       7.459931              9   \n",
       "\n",
       "        ...                  geometry index_right    plz            note  \\\n",
       "0       ...  POINT (7.47053 51.50631)        3073  44139  44139 Dortmund   \n",
       "1       ...  POINT (7.45136 51.50746)        3072  44137  44137 Dortmund   \n",
       "2       ...  POINT (7.45582 51.50329)        3073  44139  44139 Dortmund   \n",
       "3       ...  POINT (7.45147 51.49904)        3073  44139  44139 Dortmund   \n",
       "4       ...  POINT (7.45136 51.50746)        3072  44137  44137 Dortmund   \n",
       "...     ...                       ...         ...    ...             ...   \n",
       "207471  ...  POINT (7.45463 51.53269)        3077  44147  44147 Dortmund   \n",
       "207472  ...  POINT (7.45463 51.53269)        3077  44147  44147 Dortmund   \n",
       "207473  ...  POINT (7.41763 51.49269)        3080  44227  44227 Dortmund   \n",
       "207474  ...  POINT (7.47496 51.51830)        3071  44135  44135 Dortmund   \n",
       "207475  ...  POINT (7.45982 51.50073)        3073  44139  44139 Dortmund   \n",
       "\n",
       "              qkm  einwohner  distanceToUniversity  towardsUniversity  \\\n",
       "0        4.896154      19843              4.094004                  1   \n",
       "1        3.281205      21573              2.963796                  0   \n",
       "2        4.896154      19843              3.021170                  0   \n",
       "3        4.896154      19843              2.580733                  0   \n",
       "4        3.281205      21573              2.963796                  0   \n",
       "...           ...        ...                   ...                ...   \n",
       "207471   8.196036      22692              5.190721                  0   \n",
       "207472   8.196036      22692              5.190721                  0   \n",
       "207473  19.106338      17922              0.139429                  0   \n",
       "207474   1.469342      11921              4.996192                  0   \n",
       "207475   4.896154      19843              3.189484                  0   \n",
       "\n",
       "        awayFromUniversity           tripLabel  \n",
       "0                        0   towardsUniversity  \n",
       "1                        0    noUniversityRide  \n",
       "2                        0    noUniversityRide  \n",
       "3                        0    noUniversityRide  \n",
       "4                        0    noUniversityRide  \n",
       "...                    ...                 ...  \n",
       "207471                   0    noUniversityRide  \n",
       "207472                   0    noUniversityRide  \n",
       "207473                   1  awayFromUniveristy  \n",
       "207474                   0    noUniversityRide  \n",
       "207475                   0    noUniversityRide  \n",
       "\n",
       "[207476 rows x 32 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression\n",
    "\n",
    "### In the following the prediction for the attributes towards- and awayFromUniversity was done separately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to optimize hyper-parameters of a Logistic Regression model using Grid Search in Python\n",
    "def optimize_hyperparameters(X,y):\n",
    "\n",
    "    # Create an scaler object\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Create a pca object\n",
    "    pca = decomposition.PCA()\n",
    "\n",
    "    # Create a logistic regression object with an L2 penalty\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "\n",
    "    # Create a pipeline of three steps. First, standardize the data.\n",
    "    # Second, tranform the data with PCA.\n",
    "    # Third, train a logistic regression on the data.\n",
    "    pipe = Pipeline(steps=[('sc', sc),\n",
    "                           ('pca', pca),\n",
    "                           ('logistic', logistic)])\n",
    "\n",
    "    # Create Parameter Space\n",
    "    # Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "    # Create a list of values of the regularization parameter\n",
    "    C = np.logspace(-4, 4, 50)\n",
    "    # Create a list of options for the regularization penalty\n",
    "    penalty = ['l1', 'l2']\n",
    "    # Create a dictionary of all the parameter options \n",
    "    # Note has you can access the parameters of steps of a pipeline by using '__â\n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                      logistic__C=C,\n",
    "                      logistic__penalty=penalty)\n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    # View The Best Parameters\n",
    "    print('Best Penalty:', clf.best_estimator_.get_params()['logistic__penalty'])\n",
    "    print('Best C:', clf.best_estimator_.get_params()['logistic__C'])\n",
    "    print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf.best_estimator_.get_params()['logistic'])\n",
    "\n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    CV_Result = cross_val_score(clf, X, y, cv=4, n_jobs=-1)\n",
    "    print(); print(CV_Result)\n",
    "    print(); print(CV_Result.mean())\n",
    "    print(); print(CV_Result.std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']\n",
    "y_away = data['awayFromUniversity']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the best parameters for logistic regression for the attribute awayFromUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.12648552168552957\n",
      "Best Number Of Components: 4\n",
      "\n",
      "LogisticRegression(C=0.12648552168552957, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "[0.9854441  0.98681293 0.98557905 0.98640807]\n",
      "\n",
      "0.9860610383851627\n",
      "\n",
      "0.0005698014886013382\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the best parameters for logistic regression for the attribute towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.8286427728546842\n",
      "Best Number Of Components: 5\n",
      "\n",
      "LogisticRegression(C=0.8286427728546842, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "[0.91808209 0.91808209 0.91684821 0.91573001]\n",
      "\n",
      "0.9171856021901329\n",
      "\n",
      "0.0009797906933469204\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_towards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=4).fit(X)\n",
    "X_pca = pca_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     56941\n",
      "           1       0.87      0.99      0.93      5302\n",
      "\n",
      "    accuracy                           0.99     62243\n",
      "   macro avg       0.93      0.99      0.96     62243\n",
      "weighted avg       0.99      0.99      0.99     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create model based on the optimal parameters\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_away, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.12648552168552957, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL PERFORMACE FOR AWAYFROMUNIVERSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96     57109\n",
      "           1       0.53      0.08      0.14      5134\n",
      "\n",
      "    accuracy                           0.92     62243\n",
      "   macro avg       0.73      0.54      0.55     62243\n",
      "weighted avg       0.89      0.92      0.89     62243\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.8286427728546842, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS DOES NOT WORK FOR OptimizeParameters because it has to be done on the training set (and not on the test set), but optimizeparameters processes both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OS FÃ¼r towardsUNI\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "# os = SMOTE(random_state=0)\n",
    "\n",
    "# columns = X_train.columns\n",
    "# X_train_res,y_train_res =os.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "\n",
    "# print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "# print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "\n",
    "# st_scaler = StandardScaler()\n",
    "# X_train_res_scaled = st_scaler.fit_transform(X_train_res)\n",
    "\n",
    "\n",
    "# log = LogisticRegression(C=4.0, multi_class='multinomial', solver = 'newton-cg')\n",
    "# log.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "# X_test_scaled = st_scaler.transform(X_test)\n",
    "# y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "# print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_awayFromUniversity(X):\n",
    "    # set the model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "    st_scaler = StandardScaler()\n",
    "    X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "    # TODO: Modell anpassen\n",
    "    log = LogisticRegression(C=0.18420699693267145, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "    log.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # scale the input\n",
    "    X_scaled = st_scaler.fit_transform(X)\n",
    "    \n",
    "    # predict outcome\n",
    "    y_pred = log.predict(X_scaled)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "I had to stop this function, because it lasted too long (stopped after about 1 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_svm(X,y, nfolds):\n",
    "    # defining parameter range \n",
    "    param_grid = [{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "                  {'C': [0.1, 1, 10, 100, 1000],  \n",
    "                  'gamma': [1, 0.5, 0.3, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['rbf']}]\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=nfolds) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X, y) \n",
    "    \n",
    "    # print best parameter after tuning \n",
    "    print(grid.best_params_) \n",
    "  \n",
    "    # print how our model looks after hyper-parameter tuning \n",
    "    print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.977, total=  49.2s\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   49.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.978, total= 3.1min\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.982, total= 1.5min\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV] ................ C=0.1, kernel=linear, score=0.982, total=  52.8s\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV] ................ C=0.1, kernel=linear, score=0.979, total= 1.3min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.977, total= 2.1min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.978, total= 2.3min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.976, total= 2.1min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.982, total= 1.9min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.979, total= 2.1min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.978, total= 4.8min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.978, total= 7.4min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.976, total= 5.8min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.982, total= 5.0min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.979, total= 5.1min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.979, total=23.5min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.981, total=17.3min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.981, total=10.4min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.982, total= 6.0min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.982, total=13.3min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.977, total= 1.7min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.981, total= 2.9min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.982, total= 2.1min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.984, total= 2.0min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.981, total= 3.9min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.922, total= 5.5min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.972, total= 8.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.950, total=12.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.971, total= 9.0min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.942, total= 5.1min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.943, total= 4.4min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.975, total= 4.5min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.965, total= 7.8min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.981, total= 9.0min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.972, total= 4.8min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.944, total= 2.9min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.976, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.974, total= 1.9min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.981, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.975, total= 2.8min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.976, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.978, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.980, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.981, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.975, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.977, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.978, total= 1.4min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.981, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.981, total= 1.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.976, total= 2.0min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.977, total= 4.8min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.975, total= 3.3min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.975, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.981, total= 2.0min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.973, total= 2.8min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.5min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.923, total= 9.1min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.979, total= 9.7min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.955, total= 9.6min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.979, total=11.3min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.946, total=11.3min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.946, total= 2.5min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.978, total= 6.2min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.974, total= 9.0min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.983, total= 9.0min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.977, total= 5.6min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] ......... C=1, gamma=0.3, kernel=rbf, score=0.944, total=255.2min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.978, total= 4.5min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.980, total= 3.9min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.983, total= 4.6min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.979, total= 4.0min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.977, total= 1.0min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.978, total= 1.2min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.982, total= 1.1min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.982, total= 1.1min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.979, total= 1.1min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.977, total=  57.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.978, total=  57.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.982, total= 1.0min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.982, total= 1.0min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.979, total=  59.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.977, total= 1.2min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.978, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.982, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.979, total= 1.2min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.977, total= 2.4min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.975, total= 2.9min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.978, total= 3.0min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.982, total= 2.9min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.979, total= 3.8min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.929, total=10.1min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.977, total=21.1min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.960, total=20.9min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.977, total=20.5min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.951, total=22.9min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.942, total= 4.1min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.978, total= 5.0min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.975, total= 5.3min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.983, total= 5.3min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.980, total=11.6min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.953, total= 8.2min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.980, total= 6.3min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.976, total= 4.3min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.981, total= 4.7min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.980, total= 4.3min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.976, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.981, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.4min\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.977, total=  48.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.978, total=  49.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.984, total=  49.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.984, total=  50.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.979, total=  51.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.977, total=  51.1s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.978, total=  54.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.982, total=  54.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.982, total=  55.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.979, total=  56.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.977, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.978, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.979, total= 1.2min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.930, total=14.6min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.977, total=13.2min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.960, total=14.7min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.978, total=13.4min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.949, total=15.1min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.944, total=11.8min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.978, total=10.3min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.973, total=11.9min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.979, total= 9.6min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.974, total=13.4min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.964, total= 6.1min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.977, total= 7.1min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.975, total= 6.7min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.981, total= 8.7min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_svm(X,y_away, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forrest which does not separate between the attributes\n",
    "## This model predict the categorical variable \"TripLabel\" which takes the values \"awayFromUniversity\", \"towardsUniversity\" and \"noUniversityRide\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_randomforest(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # random forest model creation\n",
    "    rfc = RandomForestClassifier()\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    # Random search of parameters\n",
    "    rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the model\n",
    "    rfc_random.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['tripLabel']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 174.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 339.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 2527     1   527]\n",
      " [    6 53960   150]\n",
      " [ 1086  2670  1316]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniveristy       0.70      0.83      0.76      3055\n",
      "  noUniversityRide       0.95      1.00      0.97     54116\n",
      " towardsUniversity       0.66      0.26      0.37      5072\n",
      "\n",
      "          accuracy                           0.93     62243\n",
      "         macro avg       0.77      0.69      0.70     62243\n",
      "      weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.28142472 0.88143436 0.88167534 0.87516869 0.88018122 0.91517255\n",
      " 0.91256567 0.91169808 0.90596231 0.91748205]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8362764975327857\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=1000, min_samples_split = 2,min_samples_leaf=1, max_depth=10, max_features='auto', bootstrap= False)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest\n",
    "### Prediction model for both attributes separately\n",
    "\n",
    "\n",
    "### AwayFromUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_away = data['awayFromUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 303.6min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 340.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56975     0]\n",
      " [    0  5268]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56975\n",
      "           1       1.00      1.00      1.00      5268\n",
      "\n",
      "    accuracy                           1.00     62243\n",
      "   macro avg       1.00      1.00      1.00     62243\n",
      "weighted avg       1.00      1.00      1.00     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 5,min_samples_leaf=1, max_depth=30, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_away, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 152.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 293.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 2000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[56783   459]\n",
      " [ 3951  1050]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     57242\n",
      "           1       0.70      0.21      0.32      5001\n",
      "\n",
      "    accuracy                           0.93     62243\n",
      "   macro avg       0.82      0.60      0.64     62243\n",
      "weighted avg       0.92      0.93      0.91     62243\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.62230677 0.89718263 0.89805715 0.87987842 0.89694665 0.8827083\n",
      " 0.87964691 0.86347401 0.8492312  0.88101501]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8550447057307388\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=2000, min_samples_split = 5,min_samples_leaf=1, max_depth=10, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Process:\n",
    "\n",
    "Assumption: We get a dataset/dataframe X with trips that have to be predicted\n",
    "\n",
    "1) Define the KMeans-clustering variable km\n",
    "\n",
    "2) Define the 2 models (pred_model_away, pred_model_towards)\n",
    "\n",
    "3) get the clustered start area : cluster_area_start(X, km)\n",
    "\n",
    "4) calculate the relevant attributes for the prediction: preprocess(X)\n",
    "\n",
    "5) Predict the attributes 'towardsUniversity' and 'awayFromUniversity': predict_towardsUniversity(X), predict_awayFromUniversity(X)\n",
    "\n",
    "6) Get the output-code. This means the predicted values 0/1 are mapped to the labels \"towardsUniversty\", \"awayFromUniversity\", \"noUniversityRide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
