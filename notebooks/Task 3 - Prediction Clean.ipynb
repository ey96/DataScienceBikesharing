{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erkin\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import linear_model, decomposition, datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import geopy\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from vincenty import vincenty\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "import sklearn.metrics\n",
    "    \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/dortmund_trips.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'trip duration in minutes')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check outliers\n",
    "#identifiy outlier record based on trip duration\n",
    "ax = plt.figure(figsize = (16,4))\n",
    "ax.suptitle(\"Boxplot of the trip duration distribution\", y=0.98)\n",
    "ax = sns.boxplot (x=df[\"trip_duration\"], color='cornflowerblue')\n",
    "ax.set_xticks(np.arange(0, 55),1)\n",
    "ax.set_xlim([0, 55]) \n",
    "ax.set_xlabel('trip duration in minutes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier: 2min<=trip<=48min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "st_scaler = StandardScaler()\n",
    "X_scaled = st_scaler.fit_transform(df[[\"latitude_start\",\"longitude_start\"]])\n",
    "\n",
    "k_max = 10\n",
    "clusters = []\n",
    "losses = []\n",
    "\n",
    "# elbow method to specify the appropriate number of cluster\n",
    "for k in range(k_max):\n",
    "    model = KMeans(n_clusters=k+1)\n",
    "    model.fit(X_scaled)\n",
    "    clusters.append(k+1)\n",
    "    losses.append(model.inertia_)\n",
    "    \n",
    "plt.plot(clusters, losses)\n",
    "plt.title(\"Elbow method - K-means++\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# due to the elbow method number of clusters are set to 4 \n",
    "km = KMeans(n_clusters = 4)\n",
    "km.fit(X_scaled)\n",
    "df[\"area_start\"] = km.predict(X_scaled)+1\n",
    "\n",
    "sns.scatterplot(x=\"latitude_start\", y=\"longitude_start\", data=df, hue=\"area_start\", palette=\"muted\")\n",
    "plt.title(\"Start positions clusterd to areas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_point(row):\n",
    "    return Point(row.longitude_start, row.latitude_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are currently the coordinates of TU Dortmund Hörsaalgebäude 2\n",
    "def calculate_distanceToUniversity(row):\n",
    "    university_center_lat = 51.492296\n",
    "    university_center_lon = 7.41273 \n",
    "    \n",
    "    distance = vincenty([row[\"latitude_start\"], row[\"longitude_start\"]], [university_center_lat, university_center_lon],)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kann später weg, im master ist dieses attribut bereits 0/1 (hier war es noch True/False)\n",
    "def convertweekend(row):\n",
    "    if(row['weekend']):\n",
    "        return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tripLabel(row):\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'awayFromUniveristy'\n",
    "    if ((row['towardsUniversity'] == 1) & (row['awayFromUniversity'] == 1)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((row['towardsUniversity'] == 0) & (row['awayFromUniversity'] == 0)):\n",
    "        return 'noUniversityRide'\n",
    "    \n",
    "    warnings.warn(\"Warning...........Message\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    #delete outliers\n",
    "    df_without_outliers = df[(df[\"trip_duration\"]>= 2) & (df[\"trip_duration\"]<= 48)]\n",
    "    amount_deleted_rows = len(df) - len(df_without_outliers)\n",
    "    print(amount_deleted_rows, \"of\", len(df) ,\"rows were deleted due outlier-handling\")\n",
    "    print(\"This equals\", amount_deleted_rows/len(df) * 100, \"%\")\n",
    "    \n",
    "    \n",
    "    # Go through every row, and make a point out of its lat and lon\n",
    "    df_without_outliers[\"geometry\"] = df_without_outliers.apply(make_point, axis=1)\n",
    "    # It doesn't come with a CRS because it's a CSV, so it has to be set\n",
    "    df_without_outliers.crs = {'init': 'epsg:4326'}\n",
    "    \n",
    "    # get geodata of germany (postal codes and their areas/polygons)\n",
    "    districts_germany = gpd.read_file(\"../data/external/germany_postalcodes.geojson\")\n",
    "    # filter for districts of dortmund\n",
    "    districts_dortmund = districts_germany[districts_germany[\"note\"].str.contains(\"Dortmund\")]\n",
    "    \n",
    "    #convert dataset of trips to geodataframe (so it can be merged later with the geodataframe of dortmund)\n",
    "    geo_df = gpd.GeoDataFrame(df_without_outliers, crs={'init': 'epsg:4326'}, geometry=df_without_outliers.geometry)\n",
    "    \n",
    "    # join the data\n",
    "    # mrges data when POINT of trips is within POLYGON of a dortmund district\n",
    "    df_with_postalcode = gpd.sjoin(geo_df, districts_dortmund, how='left', op='within')\n",
    "    \n",
    "    # adding the distance between start position and the center of the university\n",
    "    df_with_postalcode[\"distanceToUniversity\"] = df_with_postalcode.apply(calculate_distanceToUniversity,axis=1)\n",
    "    \n",
    "    # convert weekend to binary (KANN IM MASTER WIEDER WEG; DORT IST WEEKEND BEREITS BINÄR)\n",
    "    df_with_postalcode['weekend'] = df_with_postalcode.apply(lambda row: convertweekend(row), axis=1)\n",
    "    \n",
    "    # add the attribute whether a trip was done towars/away from university\n",
    "    university_stations = [\"TU Dortmund Seminarraumgebäude 1\", \"TU Dortmund Hörsaalgebäude 2\", \"Universität/S-Bahnhof\", \"TU Dortmund Emil-Figge-Straße 50\", \"FH-Dortmund Emil-Figge-Straße 42\"]\n",
    "\n",
    "    df_with_postalcode['towardsUniversity'] = df_with_postalcode['p_name_end'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "    df_with_postalcode['awayFromUniversity'] = df_with_postalcode['p_name_start'].apply(lambda x: 1 if x in university_stations else 0)\n",
    "    \n",
    "    df_with_postalcode['tripLabel'] = df_with_postalcode.apply(lambda row: get_tripLabel(row), axis=1)\n",
    "    \n",
    "    df_prepared = df_with_postalcode\n",
    "    \n",
    "    return df_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27599 of 207476 rows were deleted due outlier-handling\n",
      "This equals 13.302261466386472 %\n"
     ]
    }
   ],
   "source": [
    "data = prepare_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../data/processed/prediction_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/processed/prediction_data.csv', index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>b_number_start</th>\n",
       "      <th>latitude_start</th>\n",
       "      <th>p_name_start</th>\n",
       "      <th>longitude_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude_end</th>\n",
       "      <th>p_name_end</th>\n",
       "      <th>longitude_end</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>...</th>\n",
       "      <th>geometry</th>\n",
       "      <th>index_right</th>\n",
       "      <th>plz</th>\n",
       "      <th>note</th>\n",
       "      <th>qkm</th>\n",
       "      <th>einwohner</th>\n",
       "      <th>distanceToUniversity</th>\n",
       "      <th>towardsUniversity</th>\n",
       "      <th>awayFromUniversity</th>\n",
       "      <th>tripLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-20 16:22:00</td>\n",
       "      <td>50641</td>\n",
       "      <td>51.506312</td>\n",
       "      <td>Hainallee / Südbad</td>\n",
       "      <td>7.470531</td>\n",
       "      <td>2019-01-20 17:00:00</td>\n",
       "      <td>51.493966</td>\n",
       "      <td>TU Dortmund Emil-Figge-Straße 50</td>\n",
       "      <td>7.418008</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.470531463623098 51.506311756219)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>4.306089</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>towardsUniversity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-20 02:31:00</td>\n",
       "      <td>50425</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>2019-01-20 02:43:00</td>\n",
       "      <td>51.513069</td>\n",
       "      <td>Unionstr.</td>\n",
       "      <td>7.448886</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.459931373596199 51.517155427985)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>4.288439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-20 14:38:00</td>\n",
       "      <td>53006</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>2019-01-20 14:53:00</td>\n",
       "      <td>51.500725</td>\n",
       "      <td>Polizeipräsidium</td>\n",
       "      <td>7.459819</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.459931373596199 51.517155427985)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>4.288439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-20 17:02:00</td>\n",
       "      <td>53006</td>\n",
       "      <td>51.500725</td>\n",
       "      <td>Polizeipräsidium</td>\n",
       "      <td>7.459819</td>\n",
       "      <td>2019-01-20 17:16:00</td>\n",
       "      <td>51.514029</td>\n",
       "      <td>Schwanenwall</td>\n",
       "      <td>7.472570</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.4598187208176 51.500725323279)</td>\n",
       "      <td>3073</td>\n",
       "      <td>44139</td>\n",
       "      <td>44139 Dortmund</td>\n",
       "      <td>4.896154</td>\n",
       "      <td>19843</td>\n",
       "      <td>3.401936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-01-20 23:30:00</td>\n",
       "      <td>90345</td>\n",
       "      <td>51.513069</td>\n",
       "      <td>Unionstr.</td>\n",
       "      <td>7.448886</td>\n",
       "      <td>2019-01-20 23:39:00</td>\n",
       "      <td>51.512909</td>\n",
       "      <td>Wittener Str. / Wilhelmplatz</td>\n",
       "      <td>7.423314</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.448886036872902 51.513069322724)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>3.412399</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207470</th>\n",
       "      <td>2019-12-31 11:17:00</td>\n",
       "      <td>500019</td>\n",
       "      <td>51.507457</td>\n",
       "      <td>Möllerbrücke</td>\n",
       "      <td>7.451364</td>\n",
       "      <td>2019-12-31 11:26:00</td>\n",
       "      <td>51.500675</td>\n",
       "      <td>Kuithanstr.</td>\n",
       "      <td>7.440834</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.451364398002625 51.50745700724568)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>3.169013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207471</th>\n",
       "      <td>2019-12-31 12:39:00</td>\n",
       "      <td>500019</td>\n",
       "      <td>51.500675</td>\n",
       "      <td>Kuithanstr.</td>\n",
       "      <td>7.440834</td>\n",
       "      <td>2019-12-31 12:54:00</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.440834045410155 51.50067523261729)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>2.162931</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207472</th>\n",
       "      <td>2019-12-31 19:28:00</td>\n",
       "      <td>500019</td>\n",
       "      <td>51.517155</td>\n",
       "      <td>Hauptbahnhof/Bahnhofsvorplatz</td>\n",
       "      <td>7.459931</td>\n",
       "      <td>2019-12-31 19:35:00</td>\n",
       "      <td>51.513069</td>\n",
       "      <td>Unionstr.</td>\n",
       "      <td>7.448886</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.459931373596191 51.5171554279852)</td>\n",
       "      <td>3072</td>\n",
       "      <td>44137</td>\n",
       "      <td>44137 Dortmund</td>\n",
       "      <td>3.281205</td>\n",
       "      <td>21573</td>\n",
       "      <td>4.288439</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207474</th>\n",
       "      <td>2019-12-31 22:37:00</td>\n",
       "      <td>500113</td>\n",
       "      <td>51.510976</td>\n",
       "      <td>Stadtgarten</td>\n",
       "      <td>7.464534</td>\n",
       "      <td>2019-12-31 23:05:00</td>\n",
       "      <td>51.486747</td>\n",
       "      <td>Am Beilstück</td>\n",
       "      <td>7.435750</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.464534044265747 51.51097605329955)</td>\n",
       "      <td>3071</td>\n",
       "      <td>44135</td>\n",
       "      <td>44135 Dortmund</td>\n",
       "      <td>1.469342</td>\n",
       "      <td>11921</td>\n",
       "      <td>4.154393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207475</th>\n",
       "      <td>2019-12-31 23:38:00</td>\n",
       "      <td>500113</td>\n",
       "      <td>51.486747</td>\n",
       "      <td>Am Beilstück</td>\n",
       "      <td>7.435750</td>\n",
       "      <td>2019-12-31 23:52:00</td>\n",
       "      <td>51.502318</td>\n",
       "      <td>Kreuzstraße</td>\n",
       "      <td>7.450029</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>POINT (7.43575 51.48674699999999)</td>\n",
       "      <td>3079</td>\n",
       "      <td>44225</td>\n",
       "      <td>44225 Dortmund</td>\n",
       "      <td>7.216678</td>\n",
       "      <td>21989</td>\n",
       "      <td>1.713938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>noUniversityRide</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179877 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime_start  b_number_start  latitude_start  \\\n",
       "0       2019-01-20 16:22:00           50641       51.506312   \n",
       "1       2019-01-20 02:31:00           50425       51.517155   \n",
       "3       2019-01-20 14:38:00           53006       51.517155   \n",
       "4       2019-01-20 17:02:00           53006       51.500725   \n",
       "5       2019-01-20 23:30:00           90345       51.513069   \n",
       "...                     ...             ...             ...   \n",
       "207470  2019-12-31 11:17:00          500019       51.507457   \n",
       "207471  2019-12-31 12:39:00          500019       51.500675   \n",
       "207472  2019-12-31 19:28:00          500019       51.517155   \n",
       "207474  2019-12-31 22:37:00          500113       51.510976   \n",
       "207475  2019-12-31 23:38:00          500113       51.486747   \n",
       "\n",
       "                         p_name_start  longitude_start         datetime_end  \\\n",
       "0                  Hainallee / Südbad         7.470531  2019-01-20 17:00:00   \n",
       "1       Hauptbahnhof/Bahnhofsvorplatz         7.459931  2019-01-20 02:43:00   \n",
       "3       Hauptbahnhof/Bahnhofsvorplatz         7.459931  2019-01-20 14:53:00   \n",
       "4                    Polizeipräsidium         7.459819  2019-01-20 17:16:00   \n",
       "5                           Unionstr.         7.448886  2019-01-20 23:39:00   \n",
       "...                               ...              ...                  ...   \n",
       "207470                   Möllerbrücke         7.451364  2019-12-31 11:26:00   \n",
       "207471                    Kuithanstr.         7.440834  2019-12-31 12:54:00   \n",
       "207472  Hauptbahnhof/Bahnhofsvorplatz         7.459931  2019-12-31 19:35:00   \n",
       "207474                    Stadtgarten         7.464534  2019-12-31 23:05:00   \n",
       "207475                   Am Beilstück         7.435750  2019-12-31 23:52:00   \n",
       "\n",
       "        latitude_end                        p_name_end  longitude_end  \\\n",
       "0          51.493966  TU Dortmund Emil-Figge-Straße 50       7.418008   \n",
       "1          51.513069                         Unionstr.       7.448886   \n",
       "3          51.500725                  Polizeipräsidium       7.459819   \n",
       "4          51.514029                      Schwanenwall       7.472570   \n",
       "5          51.512909      Wittener Str. / Wilhelmplatz       7.423314   \n",
       "...              ...                               ...            ...   \n",
       "207470     51.500675                       Kuithanstr.       7.440834   \n",
       "207471     51.517155     Hauptbahnhof/Bahnhofsvorplatz       7.459931   \n",
       "207472     51.513069                         Unionstr.       7.448886   \n",
       "207474     51.486747                      Am Beilstück       7.435750   \n",
       "207475     51.502318                       Kreuzstraße       7.450029   \n",
       "\n",
       "        trip_duration  ...                                     geometry  \\\n",
       "0                  38  ...    POINT (7.470531463623098 51.506311756219)   \n",
       "1                  12  ...    POINT (7.459931373596199 51.517155427985)   \n",
       "3                  15  ...    POINT (7.459931373596199 51.517155427985)   \n",
       "4                  14  ...      POINT (7.4598187208176 51.500725323279)   \n",
       "5                   9  ...    POINT (7.448886036872902 51.513069322724)   \n",
       "...               ...  ...                                          ...   \n",
       "207470              9  ...  POINT (7.451364398002625 51.50745700724568)   \n",
       "207471             15  ...  POINT (7.440834045410155 51.50067523261729)   \n",
       "207472              7  ...   POINT (7.459931373596191 51.5171554279852)   \n",
       "207474             28  ...  POINT (7.464534044265747 51.51097605329955)   \n",
       "207475             14  ...            POINT (7.43575 51.48674699999999)   \n",
       "\n",
       "        index_right    plz            note       qkm  einwohner  \\\n",
       "0              3073  44139  44139 Dortmund  4.896154      19843   \n",
       "1              3072  44137  44137 Dortmund  3.281205      21573   \n",
       "3              3072  44137  44137 Dortmund  3.281205      21573   \n",
       "4              3073  44139  44139 Dortmund  4.896154      19843   \n",
       "5              3072  44137  44137 Dortmund  3.281205      21573   \n",
       "...             ...    ...             ...       ...        ...   \n",
       "207470         3072  44137  44137 Dortmund  3.281205      21573   \n",
       "207471         3072  44137  44137 Dortmund  3.281205      21573   \n",
       "207472         3072  44137  44137 Dortmund  3.281205      21573   \n",
       "207474         3071  44135  44135 Dortmund  1.469342      11921   \n",
       "207475         3079  44225  44225 Dortmund  7.216678      21989   \n",
       "\n",
       "        distanceToUniversity towardsUniversity  awayFromUniversity  \\\n",
       "0                   4.306089                 1                   0   \n",
       "1                   4.288439                 0                   0   \n",
       "3                   4.288439                 0                   0   \n",
       "4                   3.401936                 0                   0   \n",
       "5                   3.412399                 0                   0   \n",
       "...                      ...               ...                 ...   \n",
       "207470              3.169013                 0                   0   \n",
       "207471              2.162931                 0                   0   \n",
       "207472              4.288439                 0                   0   \n",
       "207474              4.154393                 0                   0   \n",
       "207475              1.713938                 0                   0   \n",
       "\n",
       "                tripLabel  \n",
       "0       towardsUniversity  \n",
       "1        noUniversityRide  \n",
       "3        noUniversityRide  \n",
       "4        noUniversityRide  \n",
       "5        noUniversityRide  \n",
       "...                   ...  \n",
       "207470   noUniversityRide  \n",
       "207471   noUniversityRide  \n",
       "207472   noUniversityRide  \n",
       "207474   noUniversityRide  \n",
       "207475   noUniversityRide  \n",
       "\n",
       "[179877 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to optimize hyper-parameters of a Logistic Regression model using Grid Search in Python\n",
    "def optimize_hyperparameters(X,y):\n",
    "\n",
    "    # Create an scaler object\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    # Create a pca object\n",
    "    pca = decomposition.PCA()\n",
    "\n",
    "    # Create a logistic regression object with an L2 penalty\n",
    "    logistic = linear_model.LogisticRegression()\n",
    "\n",
    "    # Create a pipeline of three steps. First, standardize the data.\n",
    "    # Second, tranform the data with PCA.\n",
    "    # Third, train a logistic regression on the data.\n",
    "    pipe = Pipeline(steps=[('sc', sc),\n",
    "                           ('pca', pca),\n",
    "                           ('logistic', logistic)])\n",
    "\n",
    "    # Create Parameter Space\n",
    "    # Create a list of a sequence of integers from 1 to 30 (the number of features in X + 1)\n",
    "    n_components = list(range(1,X.shape[1]+1,1))\n",
    "    # Create a list of values of the regularization parameter\n",
    "    C = np.logspace(-4, 4, 50)\n",
    "    # Create a list of options for the regularization penalty\n",
    "    penalty = ['l1', 'l2']\n",
    "    # Create a dictionary of all the parameter options \n",
    "    # Note has you can access the parameters of steps of a pipeline by using '__’\n",
    "    parameters = dict(pca__n_components=n_components,\n",
    "                      logistic__C=C,\n",
    "                      logistic__penalty=penalty)\n",
    "\n",
    "    # Conduct Parameter Optmization With Pipeline\n",
    "    # Create a grid search object\n",
    "    clf = GridSearchCV(pipe, parameters)\n",
    "\n",
    "    # Fit the grid search\n",
    "    clf.fit(X, y)\n",
    "    # View The Best Parameters\n",
    "    print('Best Penalty:', clf.best_estimator_.get_params()['logistic__penalty'])\n",
    "    print('Best C:', clf.best_estimator_.get_params()['logistic__C'])\n",
    "    print('Best Number Of Components:', clf.best_estimator_.get_params()['pca__n_components'])\n",
    "    print(); print(clf.best_estimator_.get_params()['logistic'])\n",
    "\n",
    "    # Use Cross Validation To Evaluate Model\n",
    "    CV_Result = cross_val_score(clf, X, y, cv=4, n_jobs=-1)\n",
    "    print(); print(CV_Result)\n",
    "    print(); print(CV_Result.mean())\n",
    "    print(); print(CV_Result.std())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']\n",
    "y_away = data['awayFromUniveristy']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the best parameters for logistic regression for the attribute awayFromUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.18420699693267145\n",
      "Best Number Of Components: 5\n",
      "\n",
      "LogisticRegression(C=0.18420699693267145, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_away)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## These are the best parameters for logistic regression for the attribute towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l2\n",
      "Best C: 0.08685113737513521\n",
      "Best Number Of Components: 4\n",
      "\n",
      "LogisticRegression(C=0.08685113737513521, class_weight=None, dual=False,\n",
      "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
      "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-7da85b051ea0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimize_hyperparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_towards\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-31-8224b76f4732>\u001b[0m in \u001b[0;36moptimize_hyperparameters\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m# Use Cross Validation To Evaluate Model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mCV_Result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCV_Result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCV_Result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters(X,y_towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     49269\n",
      "           1       0.86      0.99      0.92      4695\n",
      "\n",
      "    accuracy                           0.98     53964\n",
      "   macro avg       0.93      0.99      0.95     53964\n",
      "weighted avg       0.99      0.98      0.99     53964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create model based on the optimal parameters\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.18420699693267145, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pca "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_model = PCA(n_components=4).fit(X)\n",
    "X_pca = pca_model.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     49812\n",
      "           1       0.53      0.08      0.14      4152\n",
      "\n",
      "    accuracy                           0.92     53964\n",
      "   macro avg       0.73      0.54      0.55     53964\n",
      "weighted avg       0.90      0.92      0.90     53964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.08685113737513521, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     49760\n",
      "           1       0.55      0.09      0.16      4204\n",
      "\n",
      "    accuracy                           0.92     53964\n",
      "   macro avg       0.74      0.54      0.56     53964\n",
      "weighted avg       0.90      0.92      0.90     53964\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "log = LogisticRegression(C=0.08685113737513521, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "log.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_test_scaled = st_scaler.transform(X_test)\n",
    "y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_awayFromUniversity(X):\n",
    "#     # set the model\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "#     st_scaler = StandardScaler()\n",
    "#     X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "    \n",
    "#     log = LogisticRegression(C=0.18420699693267145, class_weight=None, dual=False,\n",
    "#                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "#                    max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "#                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "#                    warm_start=False)\n",
    "#     log.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     # scale the input\n",
    "#     X_scaled = st_scaler.fit_transform(X)\n",
    "    \n",
    "#     # predict outcome\n",
    "#     y_pred = log.predict(X_scaled)\n",
    "    \n",
    "#     return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OS DOES NOT WORK FOR OptimizeParameters because it has to be done on the training set (and not on the test set), but optimizeparameters processes both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OS Für towardsUNI\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "# os = SMOTE(random_state=0)\n",
    "\n",
    "# columns = X_train.columns\n",
    "# X_train_res,y_train_res =os.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "\n",
    "# print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))\n",
    "# print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "\n",
    "# st_scaler = StandardScaler()\n",
    "# X_train_res_scaled = st_scaler.fit_transform(X_train_res)\n",
    "\n",
    "\n",
    "# log = LogisticRegression(C=4.0, multi_class='multinomial', solver = 'newton-cg')\n",
    "# log.fit(X_train_res_scaled, y_train_res)\n",
    "\n",
    "# X_test_scaled = st_scaler.transform(X_test)\n",
    "# y_predict = log.predict(X_test_scaled)\n",
    "\n",
    "# print(classification_report(y_true=y_test, y_pred=y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_awayFromUniversity(X):\n",
    "    # set the model\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "    st_scaler = StandardScaler()\n",
    "    X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "\n",
    "\n",
    "    # TODO: Modell anpassen\n",
    "    log = LogisticRegression(C=0.18420699693267145, class_weight=None, dual=False,\n",
    "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
    "                   max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
    "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
    "                   warm_start=False)\n",
    "    log.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # scale the input\n",
    "    X_scaled = st_scaler.fit_transform(X)\n",
    "    \n",
    "    # predict outcome\n",
    "    y_pred = log.predict(X_scaled)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize parameters for SVM\n",
    "\n",
    "However, I had to stop this function, because it lasted too long (stopped after about 1 day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_svm(X,y, nfolds):\n",
    "    # defining parameter range \n",
    "    param_grid = [{'C': [0.1, 1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "                  {'C': [0.1, 1, 10, 100, 1000],  \n",
    "                  'gamma': [1, 0.5, 0.3, 0.1, 0.01, 0.001, 0.0001], \n",
    "                  'kernel': ['rbf']}]\n",
    "\n",
    "    grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3, cv=nfolds) \n",
    "\n",
    "    # fitting the model for grid search \n",
    "    grid.fit(X, y) \n",
    "    \n",
    "    # print best parameter after tuning \n",
    "    print(grid.best_params_) \n",
    "  \n",
    "    # print how our model looks after hyper-parameter tuning \n",
    "    print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.977, total=  49.2s\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   49.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.978, total= 3.1min\n",
      "[CV] C=0.1, kernel=linear ............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................ C=0.1, kernel=linear, score=0.982, total= 1.5min\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV] ................ C=0.1, kernel=linear, score=0.982, total=  52.8s\n",
      "[CV] C=0.1, kernel=linear ............................................\n",
      "[CV] ................ C=0.1, kernel=linear, score=0.979, total= 1.3min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.977, total= 2.1min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.978, total= 2.3min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.976, total= 2.1min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.982, total= 1.9min\n",
      "[CV] C=1, kernel=linear ..............................................\n",
      "[CV] .................. C=1, kernel=linear, score=0.979, total= 2.1min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.978, total= 4.8min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.978, total= 7.4min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.976, total= 5.8min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.982, total= 5.0min\n",
      "[CV] C=10, kernel=linear .............................................\n",
      "[CV] ................. C=10, kernel=linear, score=0.979, total= 5.1min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.979, total=23.5min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.981, total=17.3min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.981, total=10.4min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.982, total= 6.0min\n",
      "[CV] C=100, kernel=linear ............................................\n",
      "[CV] ................ C=100, kernel=linear, score=0.982, total=13.3min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.977, total= 1.7min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.981, total= 2.9min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.982, total= 2.1min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.984, total= 2.0min\n",
      "[CV] C=1000, kernel=linear ...........................................\n",
      "[CV] ............... C=1000, kernel=linear, score=0.981, total= 3.9min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.922, total= 5.5min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.972, total= 8.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.950, total=12.1min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.971, total= 9.0min\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.942, total= 5.1min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.943, total= 4.4min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.975, total= 4.5min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.965, total= 7.8min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.981, total= 9.0min\n",
      "[CV] C=0.1, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.5, kernel=rbf, score=0.972, total= 4.8min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.944, total= 2.9min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.976, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.974, total= 1.9min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.981, total= 3.4min\n",
      "[CV] C=0.1, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.3, kernel=rbf, score=0.975, total= 2.8min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.976, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.978, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.980, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.981, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.975, total= 1.1min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.977, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.978, total= 1.4min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.981, total= 2.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.981, total= 1.3min\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.976, total= 2.0min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.977, total= 4.8min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.975, total= 3.3min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.975, total= 2.1min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.981, total= 2.0min\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.973, total= 2.8min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.5min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.913, total= 2.4min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.923, total= 9.1min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.979, total= 9.7min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.955, total= 9.6min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.979, total=11.3min\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.946, total=11.3min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.946, total= 2.5min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.978, total= 6.2min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.974, total= 9.0min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.983, total= 9.0min\n",
      "[CV] C=1, gamma=0.5, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.5, kernel=rbf, score=0.977, total= 5.6min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] ......... C=1, gamma=0.3, kernel=rbf, score=0.944, total=255.2min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.978, total= 4.5min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.980, total= 3.9min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.983, total= 4.6min\n",
      "[CV] C=1, gamma=0.3, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.3, kernel=rbf, score=0.979, total= 4.0min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.977, total= 1.0min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.978, total= 1.2min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.982, total= 1.1min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.982, total= 1.1min\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.979, total= 1.1min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.977, total=  57.3s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.978, total=  57.5s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.982, total= 1.0min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.982, total= 1.0min\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.979, total=  59.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.977, total= 1.2min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.978, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.982, total= 2.0min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.979, total= 1.2min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.977, total= 2.4min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.975, total= 2.9min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.978, total= 3.0min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.982, total= 2.9min\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.979, total= 3.8min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.929, total=10.1min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.977, total=21.1min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.960, total=20.9min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.977, total=20.5min\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.951, total=22.9min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.942, total= 4.1min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.978, total= 5.0min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.975, total= 5.3min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.983, total= 5.3min\n",
      "[CV] C=10, gamma=0.5, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.5, kernel=rbf, score=0.980, total=11.6min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.953, total= 8.2min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.980, total= 6.3min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.976, total= 4.3min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.981, total= 4.7min\n",
      "[CV] C=10, gamma=0.3, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.3, kernel=rbf, score=0.980, total= 4.3min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.976, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.981, total= 1.2min\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.980, total= 1.4min\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.977, total=  48.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.978, total=  49.7s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.984, total=  49.4s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.984, total=  50.3s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.979, total=  51.4s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.977, total=  51.1s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.978, total=  54.8s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.982, total=  54.5s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.982, total=  55.2s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.979, total=  56.7s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.977, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.978, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.982, total= 1.2min\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.979, total= 1.2min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.930, total=14.6min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.977, total=13.2min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.960, total=14.7min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.978, total=13.4min\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.949, total=15.1min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.944, total=11.8min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.978, total=10.3min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.973, total=11.9min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.979, total= 9.6min\n",
      "[CV] C=100, gamma=0.5, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.5, kernel=rbf, score=0.974, total=13.4min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.964, total= 6.1min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.977, total= 7.1min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.975, total= 6.7min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.3, kernel=rbf, score=0.981, total= 8.7min\n",
      "[CV] C=100, gamma=0.3, kernel=rbf ....................................\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_svm(X,y_away, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize parameters for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']\n",
    "y_away = data['awayFromUniveristy']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWAY\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import model_selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 34.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 66.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train_scaled, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "X_test_scaled = st_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[49254     0]\n",
      " [    0  4710]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49254\n",
      "           1       1.00      1.00      1.00      4710\n",
      "\n",
      "    accuracy                           1.00     53964\n",
      "   macro avg       1.00      1.00      1.00     53964\n",
      "weighted avg       1.00      1.00      1.00     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split= 5, min_samples_leaf=1, max_depth=30, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train_scaled,y_train)\n",
    "rfc_predict = rfc.predict(X_test_scaled)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_away, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOWARDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 143.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 287.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Random search of parameters\n",
    "rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_random.fit(X_train_scaled, y_train)\n",
    "# print results\n",
    "print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "X_test_scaled = st_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[48857   876]\n",
      " [ 2768  1463]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     49733\n",
      "           1       0.63      0.35      0.45      4231\n",
      "\n",
      "    accuracy                           0.93     53964\n",
      "   macro avg       0.79      0.66      0.70     53964\n",
      "weighted avg       0.92      0.93      0.92     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.92017776 0.89471644 0.89408938 0.87226333 0.89397829 0.8748672\n",
      " 0.85923139 0.86391835 0.86999706 0.87894729]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8822186488072592\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train_scaled,y_train)\n",
    "rfc_predict = rfc.predict(X_test_scaled)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forrest after pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_towards, test_size=0.3)\n",
    "st_scaler = StandardScaler()\n",
    "X_train_scaled = st_scaler.fit_transform(X_train)\n",
    "X_test_scaled = st_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[49107   661]\n",
      " [ 3058  1138]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     49768\n",
      "           1       0.63      0.27      0.38      4196\n",
      "\n",
      "    accuracy                           0.93     53964\n",
      "   macro avg       0.79      0.63      0.67     53964\n",
      "weighted avg       0.92      0.93      0.92     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.91516878 0.8946972  0.89355641 0.87361975 0.89527985 0.87700027\n",
      " 0.85926535 0.863576   0.86985774 0.87871992]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8820741273237598\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train_scaled,y_train)\n",
    "rfc_predict = rfc.predict(X_test_scaled)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_hyperparameters_randomforest(X,y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # random forest model creation\n",
    "    rfc = RandomForestClassifier()\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    # Random search of parameters\n",
    "    rfc_random = RandomizedSearchCV(estimator = rfc, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the model\n",
    "    rfc_random.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(rfc_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['tripLabel']\n",
    "\n",
    "# use only start-information to classify the trip-class\n",
    "X = data[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 29.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 132.4min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 251.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 70, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[ 2235     1   545]\n",
      " [    0 46730   341]\n",
      " [  828  1815  1469]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "awayFromUniveristy       0.73      0.80      0.76      2781\n",
      "  noUniversityRide       0.96      0.99      0.98     47071\n",
      " towardsUniversity       0.62      0.36      0.45      4112\n",
      "\n",
      "          accuracy                           0.93     53964\n",
      "         macro avg       0.77      0.72      0.73     53964\n",
      "      weighted avg       0.92      0.93      0.93     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.91449855 0.88948188 0.90187903 0.90410274 0.90877252 0.91238604\n",
      " 0.91805648 0.90709957 0.90053928 0.91404904]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.9070865114959178\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=70, max_features='auto', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# awayFromUniversity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_away = data['awayFromUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 32.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 63.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_away)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[49221     0]\n",
      " [    0  4743]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     49221\n",
      "           1       1.00      1.00      1.00      4743\n",
      "\n",
      "    accuracy                           1.00     53964\n",
      "   macro avg       1.00      1.00      1.00     53964\n",
      "weighted avg       1.00      1.00      1.00     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 5,min_samples_leaf=1, max_depth=30, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_away, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-442aa1b29c33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mrfc_predict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mrfc_cv_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_away\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=== Confusion Matrix ===\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    388\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 390\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    391\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 236\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 515\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 383\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         indices = _generate_sample_indices(tree.random_state, n_samples,\n\u001b[1;32m--> 154\u001b[1;33m                                            n_samples_bootstrap)\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0msample_counts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msample_counts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\PDS20\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_generate_sample_indices\u001b[1;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mrandom_instance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0msample_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_instance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples_bootstrap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_away, test_size=0.3)\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train_scaled,y_train)\n",
    "rfc_predict = rfc.predict(X_test_scaled)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_away, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# towardsUniversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_towards = data['towardsUniversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 25.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 120.5min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 472.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "optimize_hyperparameters_randomforest(X,y_towards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[48894   929]\n",
      " [ 2639  1502]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     49823\n",
      "           1       0.62      0.36      0.46      4141\n",
      "\n",
      "    accuracy                           0.93     53964\n",
      "   macro avg       0.78      0.67      0.71     53964\n",
      "weighted avg       0.92      0.93      0.93     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.93549568 0.89669128 0.89404137 0.87455176 0.89670745 0.87889019\n",
      " 0.85791221 0.86408895 0.87052862 0.87853211]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.8847439614123005\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[48882   822]\n",
      " [ 2738  1522]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96     49704\n",
      "           1       0.65      0.36      0.46      4260\n",
      "\n",
      "    accuracy                           0.93     53964\n",
      "   macro avg       0.80      0.67      0.71     53964\n",
      "weighted avg       0.92      0.93      0.93     53964\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores ===\n",
      "[0.93565743 0.89678107 0.8941965  0.8747515  0.89468118 0.87757435\n",
      " 0.85940205 0.86497195 0.86965635 0.87721417]\n",
      "\n",
      "\n",
      "=== Mean AUC Score ===\n",
      "Mean AUC Score - Random Forest:  0.884488655465079\n"
     ]
    }
   ],
   "source": [
    "# DAS HIER WAR SKALIERT VORHER\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_towards, test_size=0.3)\n",
    "\n",
    "\n",
    "# ANPASSEN !!!! basierend auf den Ergebnissen aus Zeile vorher\n",
    "rfc = RandomForestClassifier(n_estimators=400, min_samples_split = 10,min_samples_leaf=4, max_depth=90, max_features='sqrt', bootstrap= True)\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y_towards, cv=10, scoring='roc_auc')\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: X is a dataset of trips that have to be predicted\n",
    "def cluster_area_start(X, km):\n",
    "    st_scaler = StandardScaler()\n",
    "    X_scaled = st_scaler.fit_transform(X)\n",
    "\n",
    "    X[\"area_start\"] = km.predict(X_scaled)+1\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X):\n",
    "    # TODO: calculate the relevant attributes (distanceToUniversty, weekend, hour, month, area start)\n",
    "    # these attributes are not in the dataset on default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set here Prediction Model \"awayFromUniversity\" \n",
    "# pred_model_away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO set here Prediction Model \"awayFromUniversity\" \n",
    "# pred_model_towards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: X is a dataset of trips that have to be predicted\n",
    "def predict_awayFromUniversity(X):\n",
    "    X_predictors = X[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]\n",
    "    \n",
    "    #maybe scale ?!?!\n",
    "    \n",
    "    X['towardsUniversityPrediction'] = pred_model_away.predict(X_predictors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_towardsUniversity(X):\n",
    "    X_predictors = X[['weekend', 'hour', 'distanceToUniversity', 'month', 'area_start']]\n",
    "    \n",
    "    #maybe scale ?!?!\n",
    "    \n",
    "     X['awayFromUniversityPrediction'] = pred_model_towards.predict(X_predictors)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictedTripLabel(X):\n",
    "    towardsUniversity = X['towardsUniversityPrediction']\n",
    "    awayFromUniversity = X['awayFromUniversityPrediction']\n",
    "    \n",
    "    if ((towardsUniversity == 1) & (awayFromUniversity == 0)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((towardsUniversity == 0) & (awayFromUniversity == 1)):\n",
    "        return 'awayFromUniveristy'\n",
    "    if ((towardsUniversity == 1) & (awayFromUniversity == 1)):\n",
    "        return 'towardsUniversity'\n",
    "    if ((towardsUniversity == 0) & (awayFromUniversity == 0)):\n",
    "        return 'noUniversityRide'\n",
    "    \n",
    "    warnings.warn(\"Warning...........Message\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Process:\n",
    "\n",
    "Assumption: We get a dataset/dataframe X with trips that have to be predicted\n",
    "\n",
    "1) Define the KMeans-clustering variable km\n",
    "\n",
    "2) Define the 2 models (pred_model_away, pred_model_towards)\n",
    "\n",
    "3) get the clustered start area : cluster_area_start(X, km)\n",
    "\n",
    "4) calculate the relevant attributes for the prediction: preprocess(X)\n",
    "\n",
    "5) Predict the attributes 'towardsUniversity' and 'awayFromUniversity': predict_towardsUniversity(X), predict_awayFromUniversity(X)\n",
    "\n",
    "6) Get the output-code. This means the predicted values 0/1 are mapped to the labels \"towardsUniversty\", \"awayFromUniversity\", \"noUniversityRide\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
